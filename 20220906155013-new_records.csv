source,month,Key,Item Type,Publication Year,Author,Title,Publication Title,ISBN,ISSN,DOI,Url,Abstract Note,Date,Date Added,Date Modified,Access Date,Pages,Num Pages,Issue,Volume,Number Of Volumes,Journal Abbreviation,Short Title,Series,Series Number,Series Text,Series Title,Publisher,Place,Language,Rights,Type,Archive,Archive Location,Library Catalog,Call Number,Extra,Notes,File Attachments,Link Attachments,Manual Tags,Automatic Tags,Editor,Series Editor,Translator,Contributor,Attorney Agent,Book Author,Cast Member,Commenter,Composer,Cosponsor,Counsel,Interviewer,Producer,Recipient,Reviewed Author,Scriptwriter,Words By,Guest,Number,Edition,Running Time,Scale,Medium,Artwork Size,Filing Date,Application Number,Assignee,Issuing Authority,Country,Meeting Name,Conference Name,Court,References,Reporter,Legal Status,Priority Numbers,Programming Language,Version,System,Code,Code Number,Section,Session,Committee,History,Legislative Body
acm,marzo,CYVA5GNW,bookSection,2020,"Lockton, Dan; Zea-Wolfson, Tammar; Chou, Jackie; Song, Yuhan (Antonio); Ryan, Erin; Walsh, CJ",Sleep Ecologies: Tools for Snoozy Autoethnography,Proceedings of the 2020 ACM Designing Interactive Systems Conference,978-1-4503-6974-9,NA,NA,https://doi.org/10.1145/3357236.3395482,"Autoethnographic and other first-person research methods are a topic of increasing interest in design and HCI. This focus parallels the boom in self-tracking and personal informatics, perhaps most intriguingly in the intersection of quantitative and qualitative data and the noticing of patterns in one's own life and everyday wellbeing. But how can design support this? One opportunity is for research probes, or tools, which enable forms of self-inquiry, by design researchers themselves, or others. In this paper-with the broad scope of healthier student sleep as a domain-we present a series of artifacts designed by undergraduates as tools to enable autoethnographic exploration, and detail how they have been used to investigate bedtime routines, personal scheduling of time, focus, sleep data, and sleeping in non-traditional places. We also reflect on the notion of combination autoethnographic 'kits' as a way forward for forms of self-inquiry.",2020,2022-08-24T07:18:17Z,2022-08-24T07:18:17Z,NA,1579–1591,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,7GVTU4YB,conferencePaper,2013,"Sowe, Sulayman K.; Zettsu, Koji",Collaborative Development of Data Curation Profiles on a Wiki Platform: Experience from Free and Open Source Software Projects and Communities,Proceedings of the 9th International Symposium on Open Collaboration,978-1-4503-1852-5,NA,10.1145/2491055.2491071,https://doi.org/10.1145/2491055.2491071,"Wiki technologies have proven to be versatile and successful in aiding collaborative authoring of web content. Multitude of users can collaboratively add, edit, and revise wiki pages on the fly, with ease. This functionality makes wikis ideal platforms to support research communities curate data. However, without appropriate customization and a model to support collaborative editing of pages, wikis will fall sort in providing the functionalities needed to support collaborative work. In this paper, we present the architecture and design of a wiki platform, as well as a model that allow scientific communities, especially disaster response scientists, collaborative edit and append data to their wiki pages. Our experience in the implementation of the platform on MediaWiki demonstrates how wiki technologies can be used to support data curation, and how the dynamics of the FLOSS development process, its user and developer communities are increasingly informing our understanding about supporting collaboration and coordination on wikis.",2013,2022-08-24T07:18:17Z,2022-08-24T07:18:17Z,NA,NA,NA,NA,NA,NA,NA,NA,WikiSym '13,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Hong Kong, China",NA,NA,NA,cloud computing; data curation; data curation profiles; FLOSS communities; MediaWiki; open collaboration; Wiki,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,UHMEAGJH,conferencePaper,2017,"Li, Cheng; Ma, Jiaqi; Guo, Xiaoxiao; Mei, Qiaozhu",DeepCas: An End-to-End Predictor of Information Cascades,Proceedings of the 26th International Conference on World Wide Web,978-1-4503-4913-0,NA,10.1145/3038912.3052643,https://doi.org/10.1145/3038912.3052643,"Information cascades, effectively facilitated by most social network platforms, are recognized as a major factor in almost every social success and disaster in these networks. Can cascades be predicted? While many believe that they are inherently unpredictable, recent work has shown that some key properties of information cascades, such as size, growth, and shape, can be predicted by a machine learning algorithm that combines many features. These predictors all depend on a bag of hand-crafting features to represent the cascade network and the global network structures. Such features, always carefully and sometimes mysteriously designed, are not easy to extend or to generalize to a different platform or domain.Inspired by the recent successes of deep learning in multiple data mining tasks, we investigate whether an end-to-end deep learning approach could effectively predict the future size of cascades. Such a method automatically learns the representation of individual cascade graphs in the context of the global network structure, without hand-crafted features or heuristics. We find that node embeddings fall short of predictive power, and it is critical to learn the representation of a cascade graph as a whole. We present algorithms that learn the representation of cascade graphs in an end-to-end manner, which significantly improve the performance of cascade prediction over strong baselines including feature based methods, node embedding methods, and graph kernel methods. Our results also provide interesting implications for cascade prediction in general.",2017,2022-08-24T07:18:17Z,2022-08-24T07:18:17Z,NA,577–586,NA,NA,NA,NA,NA,NA,WWW '17,NA,NA,NA,International World Wide Web Conferences Steering Committee,"Republic and Canton of Geneva, CHE",NA,NA,NA,NA,NA,NA,NA,"event-place: Perth, Australia",NA,NA,NA,cascade prediction; deep learning; graph representation,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,NDGMBA2U,conferencePaper,2018,"Onose, Ryosuke; Harasawa, Yuko; Enokibori, Yu; Mase, Kenji",Textile Sensor-Based Visualization to Enhance Skills to Understand the Body-Pressure Distribution for Pressure Ulcer Prevention,Proceedings of the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers,978-1-4503-5966-5,NA,10.1145/3267305.3267644,https://doi.org/10.1145/3267305.3267644,"This study proposes a system to visualize the body-pressures applied to body parts in a bed, with textile pressure sensors to support caregivers to learn posture change skill for pressure ulcer prevention. As the result of an evaluation with 21 nursing students, the comparison group using our system for learning showed better scores than ones of the control group with skill to understand the body-pressure distribution of sub-body parts: head (6/6, 100%) and right leg (3/6, 50%).",2018,2022-08-24T07:18:17Z,2022-08-24T07:18:17Z,NA,194–197,NA,NA,NA,NA,NA,NA,UbiComp '18,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Singapore, Singapore",NA,NA,NA,education support; nursing skill; textile pressure sensor; ulcer pressure prevention; visualization,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,W9DF74Y7,conferencePaper,2002,"Almeida, Francisco; Andonov, Rumen; Gonzalez, Daniel; Moreno, Luz M.; Poirriez, Vincent; Rodriguez, Casiano",Optimal Tiling for the RNA Base Pairing Problem,Proceedings of the Fourteenth Annual ACM Symposium on Parallel Algorithms and Architectures,1-58113-529-7,NA,10.1145/564870.564901,https://doi.org/10.1145/564870.564901,"Dynamic programming is an important combinatorial optimization technique that has been widely used in various fields such as control theory, operations research, computational biology and computer science. Many authors have described parallel dynamic programming algorithms for the family of multistage problems. More scarce is the literature for the more general class of problems where dependences appear between non-consecutive stages. Among the important problems falling in this class is the RNA base pairing problem. In this study we propose a new parallel scheme for a large class of recurrences with triangular iteration space and nonuniform dependences that includes the RNA base pairing problem. We derive two different instances of this scheme that correspond to an horizontal and a vertical traverse of the iteration domain. We develop and extend the tiling approach for this particular class. We formulate and analytically solve the optimization problem determining the tile size that minimizes the total execution time of the tiled program on a distributed memory parallel machine. Our analyze is based on the BSP model, which assures the portability of the obtained results. The computational experiments carried out on the CRAY T3E behave according to the predictions of our theoretical model.",2002,2022-08-24T07:18:18Z,2022-08-24T07:18:18Z,NA,173–182,NA,NA,NA,NA,NA,NA,SPAA '02,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Winnipeg, Manitoba, Canada",NA,NA,NA,BSP model; dynamic programming; granularity on distributed memory machines; loop partitioning; MPI; RNA secondary structure prediction; SPMD,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,FPGDJYSX,bookSection,2020,"Enayati, Moein; Farahani, Nasibeh Zanjirani; Skubic, Marjorie",Machine Learning Approach for Motion Artifact Detection in Ballistocardiogram Signals,Proceedings of the 14th EAI International Conference on Pervasive Computing Technologies for Healthcare,978-1-4503-7532-0,NA,NA,https://doi.org/10.1145/3421937.3421970,"With the current increase in cardiovascular disease and the complexities they create, especially for aging seniors, we are working on in-home and non-invasive techniques to monitor vital signs for early detection of health conditions. Ballistocardiography has shown to be useful for long-term evaluation of myocardial strength. We have previously reported the successful utilization of our hydraulic bed sensor in the estimation of heart rate, sleep posture, and blood pressure. However, bed sensors used in naturalistic settings such as the home are known to be highly susceptible to motion artifacts.In this paper, the state-of-the-art methods for motion artifact detection and reduction are reviewed, and a new sequential machine learning approach is proposed. The proposed method is based on 53 novel features extracted jointly from time and frequency domains for noise detection. Our experiments show detection accuracy and sensitivities as high as 99%. Data were collected in two separate IRB approved data collections, one with 16-minute sequences from 25 subjects in the lab and the other with 5 sets of overnight data collected at a sleep center.",2020,2022-08-24T07:18:18Z,2022-08-24T07:18:18Z,NA,406–410,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,XKMHEBWV,bookSection,2021,"Kato, Hiroki; Enokibori, Yu; Yoshida, Naoto; Mase, Kenji",Toward Fine-Grained Sleeping Activity Recognition: 3d Extension and an Estimation Try on Joint Position of SLP Dataset,Adjunct Proceedings of the 2021 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2021 ACM International Symposium on Wearable Computers,978-1-4503-8461-2,NA,NA,https://doi.org/10.1145/3460418.3479349,"Sleeping posture estimation including joint positions is important for identifying pressure ulcer risk. Since there are occlusion and privacy problems with camera images, we have been studying 2D joint position estimation from sleeping posture pressure images. However, the 2D joint position does not reveal 3d relationships among body parts, such as crossing legs. Thus, toward fine-grained sleeping activity recognition, 3D joint position estimation is required. To study it, we extend the 2D joint-position data of SLP dataset for 3D and then tried to estimate them with high accuracy. In this paper, described the details of the 3D extension and an estimation result. With one network and two loss extensions for a 2D to 3D joint position estimation network, we achieved 6.909 ± 0.278 cm accuracy assuming the average skeleton of Japanese, with about 42.5% error reduction by the extensions.",2021,2022-08-24T07:18:18Z,2022-08-24T07:18:18Z,NA,322–327,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,W74BUM3U,journalArticle,2015,"Chen, Shimin; Jin, Qin",Persistent B<sup>+</sup>-Trees in Non-Volatile Main Memory,Proc. VLDB Endow.,NA,2150-8097,10.14778/2752939.2752947,https://doi.org/10.14778/2752939.2752947,"Computer systems in the near future are expected to have <u>N</u>on-<u>V</u>olatile <u>M</u>ain <u>M</u>emory (NVMM), enabled by a new generation of <u>N</u>on-<u>V</u>olatile <u>M</u>emory (NVM) technologies, such as Phase Change Memory (PCM), STT-MRAM, and Memristor. The non-volatility property has the promise to persist in-memory data structures for instantaneous failure recovery. However, realizing such promise requires a careful design to ensure that in-memory data structures are in known consistent states after failures.This paper studies persistent in-memory B+-Trees as B+-Trees are widely used in database and data-intensive systems. While traditional techniques, such as undo-redo logging and shadowing, support persistent B+-Trees, we find that they incur drastic performance overhead because of extensive NVM writes and CPU cache flush operations. PCM-friendly B+-Trees with unsorted leaf nodes help mediate this issue, but the remaining overhead is still large. In this paper, we propose write atomic B+-Trees (wB+-Trees), a new type of main-memory B+-Trees, that aim to reduce such overhead as much as possible. wB+-Tree nodes employ a small indirect slot array and/or a bitmap so that most insertions and deletions do not require the movement of index entries. In this way, wB+-Trees can achieve node consistency either through atomic writes in the nodes or by redo-only logging. We model fast NVM using DRAM on a real machine and model PCM using a cycle-accurate simulator. Experimental results show that compared with previous persistent B+-Tree solutions, wB+-Trees achieve up to 8.8x speedups on DRAM-like fast NVM and up to 27.1x speedups on PCM for insertions and deletions while maintaining good search performance. Moreover, we replaced Memcached's internal hash index with tree indices. Our real machine Memcached experiments show that wB+-Trees achieve up to 3.8X improvements over previous persistent tree structures with undo-redo logging or shadowing.",2015-02,2022-08-24T07:18:18Z,2022-08-24T07:18:18Z,NA,786–797,NA,7,8,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Publisher: VLDB Endowment,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,8ER9RJSC,conferencePaper,2013,"Enokibori, Yu; Suzuki, Akihisa; Mizuno, Hirotaka; Shimakami, Yuuki; Mase, Kenji",E-Textile Pressure Sensor Based on Conductive Fiber and Its Structure,Proceedings of the 2013 ACM Conference on Pervasive and Ubiquitous Computing Adjunct Publication,978-1-4503-2215-7,NA,10.1145/2494091.2494158,https://doi.org/10.1145/2494091.2494158,"This paper proposes a novel e-textile-based pressure sensor. Textile is a common material in our life, used in such items as sheets, seats, and clothing. If these items are equipped with sensor functions, they can invisibly assist humans without significant lifestyle changes. Our sensor is suitable for mass production and durable in daily hard use cases. The sensor is woven with common weaving machines with a special manner and its material is a common low-cost conductive fiber that does not use special and costly materials, such as optical fiber. The sensor mechanism is supported by the textile structure; thus our sensor has durability for frictional force and scratch occurring sometime in daily context. In this paper, we also introduce two example usages of our textile sensor: a bed-size body pressure sensor for anti-pressure-ulcer treatment and a wearable foot-pressure sensor for walk and skill analyses.",2013,2022-08-24T07:18:18Z,2022-08-24T07:18:18Z,NA,207–210,NA,NA,NA,NA,NA,NA,UbiComp '13 Adjunct,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Zurich, Switzerland",NA,NA,NA,bedsore; e-textile; foot pressure; pressure sensor; wearable,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,B9WHYR8V,conferencePaper,2019,"Abranches, Débora; O'Sullivan, Dympna; Bird, Jon",Nurse-Led Design and Development of an Expert System for Pressure Ulcer Management,Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems,978-1-4503-5971-9,NA,10.1145/3290607.3312958,https://doi.org/10.1145/3290607.3312958,"The use of Clinical Practice Guidelines (CPGs) is known to enable better care outcomes by promoting a consistent way of treating patients. This paper describes a user-centered design approach involving nurses, to develop a prototype expert system for modelling CPGs for Pressure Ulcer management. The system was developed using Visirule, a software tool that uses a graphical approach to modeling knowledge. The system was evaluated by 5 staff nurses and compared nurses' time and accuracy to assess a wound using CPGs accessed via the Intranet of an NHS Trust and the expert system. A post task qualitative evaluation revealed that nurses found the system useable with a systematic design, that it increased access to CPGs by reducing time and effort required by other usual methods of access, that it provided opportunities for learning due to its interactive nature, and that its recommendations were more actionable that those provided by usual static CPG documents.",2019,2022-08-24T07:18:18Z,2022-08-24T07:18:18Z,NA,1–6,NA,NA,NA,NA,NA,NA,CHI EA '19,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Glasgow, Scotland Uk",NA,NA,NA,clinical decision support; expert system; user centered design,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,MHA9LNIL,conferencePaper,2019,"Selbst, Andrew D.; Boyd, Danah; Friedler, Sorelle A.; Venkatasubramanian, Suresh; Vertesi, Janet",Fairness and Abstraction in Sociotechnical Systems,"Proceedings of the Conference on Fairness, Accountability, and Transparency",978-1-4503-6125-5,NA,10.1145/3287560.3287598,https://doi.org/10.1145/3287560.3287598,"A key goal of the fair-ML community is to develop machine-learning based systems that, once introduced into a social context, can achieve social and legal outcomes such as fairness, justice, and due process. Bedrock concepts in computer science—such as abstraction and modular design—are used to define notions of fairness and discrimination, to produce fairness-aware learning algorithms, and to intervene at different stages of a decision-making pipeline to produce ""fair"" outcomes. In this paper, however, we contend that these concepts render technical interventions ineffective, inaccurate, and sometimes dangerously misguided when they enter the societal context that surrounds decision-making systems. We outline this mismatch with five ""traps"" that fair-ML work can fall into even as it attempts to be more context-aware in comparison to traditional data science. We draw on studies of sociotechnical systems in Science and Technology Studies to explain why such traps occur and how to avoid them. Finally, we suggest ways in which technical designers can mitigate the traps through a refocusing of design in terms of process rather than solutions, and by drawing abstraction boundaries to include social actors rather than purely technical ones.",2019,2022-08-24T07:18:18Z,2022-08-24T07:18:18Z,NA,59–68,NA,NA,NA,NA,NA,NA,FAT* '19,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Atlanta, GA, USA",NA,NA,NA,Fairness-aware Machine Learning; Interdisciplinary; Sociotechnical Systems,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,TX5QF5BC,book,2015,NA,CHANTS '15: Proceedings of the 10th ACM MobiCom Workshop on Challenged Networks,NA,978-1-4503-3543-0,NA,NA,NA,"It is our great pleasure to welcome you to the Tenth ACM MobiCom Workshop on Challenged Networks (CHANTS'15). Motivated by the need to provide connectivity in situations where communication is desired but traditional Internet technologies fail to provide it effectively, challenged networks continue to attract considerable attention from the networking community. Building on the tradition of previous editions, CHANTS 2015 provides a premier forum for networking researchers from academia and industry to discuss advances and new directions in challenged networks.The workshop features papers dealing with a variety of topics related to challenged network environments, ranging from system issues raised by disconnected operation, content distribution and data muling in device-to-device communication, performance studies, as well as analysis of social encounters and spatio-temporal features of challenged networks. Further, indoor localization as an enabling technology for mobile networks and applications such as disaster relief and emergency services are included.The call for papers attracted 23 full paper submissions and four demo submissions. Out of these submissions we accepted seven full papers ( 30% of full paper submissions), three work-in-progress papers, and five demo papers. The program consists of one inspiring keynote presentation by Kevin Fall entitled ""Coping with Communications Challenges,"" followed by a work-in-progress session, two full paper sessions, and a demonstration session.",2015,2022-08-24T07:18:19Z,2022-08-24T07:18:19Z,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,CEWIQTPP,conferencePaper,2017,"Sheriff, Aviv; Sadan, Rona; Keats, Yasmin; Zuckerman, Oren",From Smart Homes to Smart Kids: Design Research for CataKit,Proceedings of the 2017 Conference on Interaction Design and Children,978-1-4503-4921-5,NA,10.1145/3078072.3079729,https://doi.org/10.1145/3078072.3079729,"This paper presents the design research process of CataKit, a construction kit for children inspired by catapults, Rube-Goldberg chain reaction machines, and mechanical automata. We set out to promote children's initiative, positive risk-taking, and procedural thinking, all in the context of their bedrooms. Our motivation is to contrast the rising smart home movement in industry, which we fear may decrease children's initiative if children's bedrooms become too automated. We describe our design research process with six children followed by a low fidelity prototype design and evaluation. We present the qualitative analysis of children's reactions to the prototype and show support for our initial goals: encourage systematic exploration of mechanical concepts and initiative over automation. We hope that construction kits like Catakit will empower children to develop curiosity about the mechanical world around them, to think about risk taking as a potentially positive experience, and to think more critically about initiative in the smart home era.",2017,2022-08-24T07:18:19Z,2022-08-24T07:18:19Z,NA,159–169,NA,NA,NA,NA,NA,NA,IDC '17,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Stanford, California, USA",NA,NA,NA,children computational thinking; construction kit; learning; positive risk-taking,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,MFM4VJ5W,conferencePaper,2008,"Novoselsky, Maxim; Kiperman, Einav; Kosti, Shahar",Using Open Source Software in Simulation: The IDF GF Battle Lab Experience,Proceedings of the 2008 Summer Computer Simulation Conference,NA,NA,NA,NA,"One of the major challenges the Israel Defense Forces (IDF) Ground Forces (GF) Battle Lab (BL) has been facing in recent years is the introduction of new simulation technologies and methods, under tight development schedule constraints. Introducing new technologies requires a ""proof of concept"" process in order to decide on the profitability of further development. Using Open Source software solutions in the BL helped make this process quicker and more efficient.The BL has been developing its proprietary Computer Generated Forces (CGF) for approximately 10 years. This CGF is mainly intended for simulating ground entities and has various capabilities for autonomous movement. Over the years, as the visual systems have improved and due to the introduction of urban environments simulation, the need for realistic movement characteristics, especially human, became important. An in-house solution, developed by the CGF team, appeared to consume too much development effort and was not extendable enough. After analyzing the problem and reviewing various third-party solutions, the CGF team decided on using an Open Source (OS) library called OpenSteer.Until recently, ground vehicle simulations in the BL used a low fidelity non-physical movement mode, based on ground clamping. In 2006 the BL got involved in research areas related to Unmanned Ground Vehicles (UGVs) and human-robotics interactions. During early research stages it became clear that it would be necessary to simulate the UGV dynamics in higher fidelity than was done before. The development team decided to initiate the ""proof of concept"" process before full scale development. Therefore a quick solution for a high-fidelity vehicle simulation was searched for. After a brief review of third party solutions, an OS library, Open Dynamics Engine (ODE) was chosen. Developing a UGV simulation required an autonomous movement model which appeared to have similar characteristics to the one developed by the CGF team based on OpenSteer. Since OpenSteer was not originally intended for simulating rigid-body vehicles, the development team faced the challenge of integrating both products, OpenSteer and ODE. This paper will describe the steps taken in order to assimilate OS products in the BL simulation test-bed and lessons learned.",2008,2022-08-24T07:18:19Z,2022-08-24T07:18:19Z,NA,NA,NA,NA,NA,NA,NA,NA,SCSC '08,NA,NA,NA,Society for Modeling &amp; Simulation International,"Vista, CA",NA,NA,NA,NA,NA,NA,NA,"event-place: Edinburgh, Scotland",NA,NA,NA,BSD; CGF; copyleft; feasibility study; GPL; ground vehicle modeling; IDF Battle Lab; licenses; movement modeling; ODE; open source software; OpenSteer; test-bed; wrappers,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,R2KVK5QT,conferencePaper,2019,"Dissanayake, Vipula; Elvitigala, Don Samitha; Zhang, Haimo; Weerasinghe, Chamod; Nanayakkara, Suranga",CompRate: Power Efficient Heart Rate and Heart Rate Variability Monitoring on Smart Wearables,25th ACM Symposium on Virtual Reality Software and Technology,978-1-4503-7001-1,NA,10.1145/3359996.3364239,https://doi.org/10.1145/3359996.3364239,"Currently, smartwatches are equipped with Photoplethysmography (PPG) sensors to measure Heart Rate (HR) and Heart Rate Variability (HRV). However, PPG sensors consume considerably high energy, making it impractical to monitor HR &amp; HRV continuously for an extended period. Utilising low power accelerometers to estimate HR has been broadly discussed in previous decades. Inspired by prior work, we introduce CompRate, an alternative method to measure HR continuously for an extended period in low-intensity physical activities. CompRate model calibrated for individual users only has an average performance of Root Mean Squared Error (RMSE) 1.58 Beats Per Minute (BPM). Further, CompRate used 3.75 times less energy compared to the built-in PPG sensor. We also demonstrate that CompRate model can be extended to predict HRV. We will demonstrate CompRate in several application scenarios: self-awareness of fatigue and just-in-time interruption while driving; enabling teachers to be aware of students’ mental effort during a learning activity; and the broadcasting of the location of live victims in a disaster situation.",2019,2022-08-24T07:18:19Z,2022-08-24T07:18:19Z,NA,NA,NA,NA,NA,NA,NA,NA,VRST '19,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Parramatta, NSW, Australia",NA,NA,NA,Accelerometer; Heart Rate; Heart Rate Variability; Inferring Stress; Low Power; Photoplethysmography,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,8JB9LEMS,conferencePaper,2020,"Xu, Hongzhen; Shen, Manlin; Duan, Yulong",A Passive Controlled Hand Rehabilitation Instrument,Proceedings of the 2020 2nd International Conference on Big Data and Artificial Intelligence,978-1-4503-7645-7,NA,10.1145/3436286.3436432,https://doi.org/10.1145/3436286.3436432,"The number of people with upper and lower limb disabilities is very large in our country. Many patients with upper and lower limb motor dysfunction due to various natural or man-made disasters, in addition to the use of traditional physical therapy in hospitals, also has applied in the rehabilitation treatment limb training to the rehabilitation robot technology. Rehabilitation robot can help patients to restore limb flexibility and self-control, thus speeding up the process of rehabilitation. Therefore, research and development of more advanced functional rehabilitation machine than the market for patients with Limb Movement disorders is of great significance, but also for the health of the elderly and help the development of public welfare disability is very useful.",2020,2022-08-24T07:18:19Z,2022-08-24T07:18:19Z,NA,433–436,NA,NA,NA,NA,NA,NA,ISBDAI '20,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Johannesburg, South Africa",NA,NA,NA,Disability; Rehabilitation; speech control; Steering Gear,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,M2ZLMSDR,conferencePaper,2021,"Khaday, Samsiya; Li, Kai Way; Li, Nailiang; Chen, Yunxiu","A Survey on the Risk Perception of Slips, Trips, and Falls of Coal Mine Workers in China",2021 3rd International Conference on Management Science and Industrial Engineering,978-1-4503-8888-7,NA,10.1145/3460824.3460843,https://doi.org/10.1145/3460824.3460843,"Coal mine industry has been one of the most risky industries in terms of occupational safety and health in China. Slip, trip, and fall (STF) has been one of the most common occupational accidents globally which can lead to fatal and non-fatal accidents. This study investigated coal mine worker risk perception of occupational STF hazard. A survey was administered on 300 coal mine workers. The results showed that the age group has significant effect. The perceived risk of STF on the ramp and on the track were high. Rail track lanes on the roadway had the highest risk ratings. Moreover, underground crossing tracks and ramps were locations with frequent accidents. Workers’ perception of the risky locations underground provides targets for safety promotions for coal mine authorities.",2021,2022-08-24T07:18:20Z,2022-08-24T07:18:20Z,NA,120–125,NA,NA,NA,NA,NA,NA,MSIE 2021,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Osaka, Japan",NA,NA,NA,and fall; coal mine worker perception; occupational accident; Slip; trip,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,C8ERPNFQ,bookSection,2021,"Zhao, Yijun; Shen, Yong; Wang, Xiaoqing; Cao, Jiacheng; Xia, Shang; Ying, Fangtian; Wang, Guanyun",PneuMat: Pneumatic Interaction System for Infant Sleep Safety Using Shape-Changing Interfaces,Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems,978-1-4503-8095-9,NA,NA,https://doi.org/10.1145/3411763.3451597,"Sleep plays an integral role in human health and is vitally important for neurological development in infants. In this study, we propose the PneuMat, an interactive shape-changing system integrating sensors and pneumatic drives, to help ensure sleep safety through novel human-computer interaction. This system comprises sensor units, control units and inflatable units. The sensor units utilize information exchange between infants and the system, and detect the infant's sleeping posture, sending raw data to control units. For better sleep experience, the inflatable units are divided into nine areas. The inflatable units are multi-mode, can be independently inflated in different areas, and can be inflated in different areas together. We aim to ensure sleep safety by ensuring that infants stay in a safe sleeping position while in bed, by autonomously actuating the PneuMat's shape-changing capability. In this article, we describe the division of PneuMat, the design of the control unit, integration of the sensors and our preliminary experiments to evaluate the feasibility of our interaction system. Finally, based on the results, we will discuss future work involving the PneuMat.",2021,2022-08-24T07:18:20Z,2022-08-24T07:18:20Z,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,LMGD7K23,conferencePaper,2014,"Iio, Takamasa; Shiomi, Masahiro; Kamei, Koji; Sharma, Chandraprakash; Hagita, Norihiro",Social Acceptance by Elderly People of a Fall-Detection System with Range Sensors in a Nursing Home,Proceedings of the Second International Conference on Human-Agent Interaction,978-1-4503-3035-0,NA,10.1145/2658861.2658910,https://doi.org/10.1145/2658861.2658910,"This study developed a fall detection system for elderly people in a nursing home and investigated their acceptance of it. The system obtained their positions and heights from range sensors and used that information to correctly detect 89.5% of the falls based on data where the elderly crouched in a mockup room of a nursing home. We investigated the social acceptance with elderly people by comparing three conditions: (1) only detecting out-of-bed, (2) detecting falls in a room and always showing the human position, and (3) detecting falls in a room and only showing the human position when a fall happened. The results showed that intention to use were significantly higher in the second and third conditions than the first condition.",2014,2022-08-24T07:18:20Z,2022-08-24T07:18:20Z,NA,153–156,NA,NA,NA,NA,NA,NA,HAI '14,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Tsukuba, Japan",NA,NA,NA,fall detection; safety system for elderly persons; smart care home,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,IVX7VDV7,conferencePaper,2016,"Kato, Ryuga; Izumida, Kento; Shigeno, Hiroshi; Okada, Ken-ichi",Individual Learning Support about First Aid with a Human-Shaped Input Device,Proceedings of the 15th International Conference on Mobile and Ubiquitous Multimedia,978-1-4503-4860-7,NA,10.1145/3012709.3012720,https://doi.org/10.1145/3012709.3012720,"When a large-scale disaster occurs, it is necessary for citizens to take the lead and do rescue operations. People train and prepare for disasters in advance, but training sessions cannot be held easily, and the learning pace of each individual is not considered. In this study, we propose a first aid training system for citizens using a human-shaped input device, QUMARION. This system provides first aid skills training through human-computer interaction. By using a human-shaped input device instead of human bodies, people can carry out the training of posture management individually and learn at their own pace. In addition, since our system provides advice and feedback depending on the knowledge level of the user, not only can they perform the learning, but they can also confirm whether they acquire knowledge and skills correctly. We conducted an experiment to see whether the trainee can learn accurately by using our system. The results showed that our system enables easy and effective learning about first aid.",2016,2022-08-24T07:18:20Z,2022-08-24T07:18:20Z,NA,181–189,NA,NA,NA,NA,NA,NA,MUM '16,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Rovaniemi, Finland",NA,NA,NA,first aid; human-shaped input device; individual learning; posture management; training system; triage,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,LY2J5G82,conferencePaper,2008,"Weisenberg, Jenny; Cuddihy, Paul; Rajiv, Vrinda",Augmenting Motion Sensing to Improve Detection of Periods of Unusual Inactivity,Proceedings of the 2nd International Workshop on Systems and Networking Support for Health Care and Assisted Living Environments,978-1-60558-199-6,NA,10.1145/1515747.1515751,https://doi.org/10.1145/1515747.1515751,"Two sensing options are examined for their potential to improve the sensitivity of a system that detects periods of inactivity in the homes of elderly persons. A previous prototype used passive infrared motion sensors and door sensors combined with a learning algorithm to detect periods of unusual inactivity such as late wake-ups or the aftermath of a fall. This system worked as intended but suffered from low sensitivity, especially at nighttime, since the motion sensors were not able to distinguish a fall in the bedroom from a person getting into bed. Experiments with a worn accelerometer and with bed and chair occupancy sensors suggest that both can dramatically improve system sensitivity. The optimal solution may depend on the users' activity level, living area size, and willingness to wear a device.",2008,2022-08-24T07:18:21Z,2022-08-24T07:18:21Z,NA,NA,NA,NA,NA,NA,NA,NA,HealthNet '08,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Breckenridge, Colorado",NA,NA,NA,accelerometer; actigraph; activity detection; bed pad; chair pad; elder monitoring; motion sensing; occupancy sensor,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,QP47NDI3,bookSection,2019,"Muttillo, Mirco; Barile, Gianluca; Leoni, Alfiero; Ferri, Giuseppe",Wired Sensors System for Monitoring of Landslide Events,"Proceedings of the 3rd International Conference on Vision, Image and Signal Processing",978-1-4503-7625-9,NA,NA,https://doi.org/10.1145/3387168.3387229,"Landslides are catastrophic events that change the territory making these events dangerous for buildings and people. Monitoring and alerting on a possible landslide can avoid disasters and can save lives. Thanks to a monitoring system it is possible to prevent and intervene in time before the situation gets worse. The aim of this work is the design of a wired sensor monitoring system for landslide events. The system is composed by one datalogger and many nodes, which measure the inclination, and communicate between each other through RS485. The datalogger is based on a microcontroller ATmega2560 which has the task of retrieving data from nodes and sending them to an FTP server. The nodes have an ATmega328p microcontroller that reads data from a digital accelerometer MMA8451 that is able to detect inclination variations up to 0.1 degrees. Furthermore, the nodes are able to go into sleep mode reducing power consumption. The system includes a calibration phase for the first installation on site to be monitored. The proposed system was tested in a real case and same preliminary data, obtained after a post processing done with Matlab, are here reported.",2019,2022-08-24T07:18:21Z,2022-08-24T07:18:21Z,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,M4BHZIMJ,conferencePaper,1989,"Mayer, P. J.",Entering the Ada Systems Design and Coding Market,Proceedings of the Conference on TRI-Ada '88,0-89791-285-3,NA,10.1145/76619.76644,https://doi.org/10.1145/76619.76644,"Advice is cheap, and we all know that you get what you pay for. There are many books, courses, and seminars on how to start a business. They have been written or are presented by professionals usually with far greater experience than I. While my general management background has been invaluable, the thing that best qualifies me to address this subject is the fact that we at Strictly Business Computer Systems have recently established an Ada programming shop.I'll share with you our experiences, from inception to the present. I must preface my remarks with the comment that they represent only our single effort in this area. I was fortunate in that my primary associates had successfully established and were operating a profitable business in the computer field, and it was their proven philosophy of adding value that became the keynote of our Ada effort.Additionally, we had the good fortune to make some valuable acquaintances early on in the process — relationships which enabled us to avoid some potentially costly pitfalls. Perhaps we can do the same for some of you.Now, to the subject at hand.What would seem to be the obvious first step in establishing any business is worth stating and that is the conscious act of making a commitment to the project. In our experience, the commitment was initially made about three years ago — two full years before the project was actually initiated. The delay occurred because the computer system integration business in which Strictly Business was totally immersed was growing at a pace that precluded devoting the time required to explore the Ada market.Then, a file less than a year ago, I joined Strictly Business with the sole responsibility of researching the Ada shop possibilities, and then managing the shop if the research was positive — which it obviously was. The fact that Strictly Business was willing to add me to the staff, as pure overhead from the business standpoint, clearly demonstrates that a true commitment existed. That commitment is really three-fold because undertaking such a project requires a dedication of, and money. Beyond that, you must assume the posture that characterizes the entrepreneur, and that is a total immersion in the business. You must identify with it and make it the focus of all that you do.If you and your organization are unwilling to pledge a full-fledged effort, your chances of success substantially diminish.Secondly, since the first phase of this project should be a marketing study, you must select an underlying theme that will provide a framework and give specific direction to your research. From the outset, we were convinced that within the Ada market a definite need existed for additional systems design and coding capacity. The corollary is that this appeared to provide a significant business opportunity. Our research was active — not passive or neutral. We saw an opportunity, and our purpose was to objectively and concretely confirm our perceptions.At each step in the process we were looking at what value was being added by the person, business or agency that we were exploring. Strictly Business was founded and has flourished on two basic concepts — namely, adding value through our involvement in each transaction and providing quality products and service to our clients. We scrupulously avoid being hardware and software “brokers” collecting fees for merely placing products with customers. We consider ourselves as partners with our clients and work to enhance their businesses with the products and services we provide.Having made the commitment and articulated your role and objectives, you must now begin the real work. This part of my message may be preaching to the choir. The fact that you are involved in the Ada community indicates that you have or are beginning to acquire a knowledge of the Ada marketplace. That's essential.Gather as much information as possible about every aspect of Ada. If you know the language, great. If not, that should not deter you from learning as much as you can exclusive of Ada per se. No one in our organization knew Ada before we began hiring our staff, yet several of us became knowledgeable and conversant enough to find our way around Ada circles — and in the Ada community, that's essential.Regardless of how much you learn in your explorations, the input of people active in Ada is indispensable. One of the most gratifying things our research revealed was the generosity and willingness of Ada experts to share their knowledge. We knocked on a lot of doors and did not find one that was not opened wide for us.Let me share with you some of the avenues we explored in trying to determine whet her or not a real Ada opportunity existed. We first had the advantage of coming from West Virginia whose senior U.S. Senator is Robert C. Byrd who has seen the potential of Ada and has for some years been one of its strongest advocates. With the assistance of two of his staff members, we were directed to the Software Valley Corporation which has been very much involved in bringing the advantages of Ada and Ada-related ventures to our Mountain State.Bob Verhotz, the Executive Director of Software Valley Corporation, in addition to other helpful suggestions, recommended that we contact Mr. Ralph Crafts. Bob had worked with Ralph on a number of occasions and spoke highly of his credentials and performance. We have not been disappointed.Ralph knows his way around the Ada community as well as anyone, and better than most. Almost a year ago, we employed Ralph as our consultant to define the state of the Ada market and give initial direction to our study. During intensive meetings with him, we received a great deal of background information and recommendations of additional areas into which we should extend our Ada network.These three initial contacts — Ralph, Software Valley, and Senator Byrd — confirmed that quality-conscious and professional systems developers could definitely find a place in the Ada market.At this point I think you can begin to see two things. The more obvious is the snowball effect of Ada contacts. Your first contact leads to two others which each lead to two or three more, and so on. The second thing is that we were strongly encouraged by each of these contacts, and our perceptions that excellent opportunities existed in Ada were reinforced. If anything, the potential began to look even greater than we had at first anticipated.Our tentacles, at that point, began to extend into additional areas of the Ada community. We have come to share Ralph's belief that the more people you know in this still relatively small group, the better off you are.We traveled to Washington to visit again with Senator Byrd's office. While there, with an introduction from the senator's staff, we also met with a number of people at the Ada Joint Programming Office, including the then-Air Force Deputy Director Major Al Kopp. More support and encouragement. On the same trip we cultivated an acquaintance at the Ada Information Clearinghouse. More support, encouragement, and a wealth of published information. We also briefly visited the STARS office and met with someone who was encouraging and informative about that extensive Ada project. Each of these organizations and individuals had a specific mission designed to enhance and increase the value of the Ada contribution.At that point we had begun to look at equipment and it was here that we found one of our more valuable allies and associates. From our initial contact with the personnel at RATIONAL we found them to be most helpful and open. Our sales representative made it possible for us to meet with two large firms handling major project work in Ada for the Defense Department.I don't need to tell you how valuable it can be to speak with someone who is engaged in the type of work you are contemplating and who has no ax to grind or hidden agendas as far as discussing things with you. Other vendors may have been equally helpful, but I doubt that any could have been more so. We met people doing actual project work in Ada for the government, extending our network and also making some contacts we would later pursue as we sought to put together our Ada staff.In March of this year, we attended the SlGAda conference in Phoenix where we researched a number of vendors, but more importantly, met others in the Ada community — on the commercial as well as the governmental side. We, admittedly, understood very little of the technical content of the meeting, but our purpose in attending was not technical in nature. We were networking, and our network was rapidly expanding.This might be a good point at which to remind you of the three-fold commitment required in this undertaking — time, energy, and money. By March our exploratory had gotten into its fifth month and had occupied practically all of my time and a substantial portion of the time of two of my colleagues at Strictly Business. Our travels had included a couple of trips to Washington and the trip to Phoenix as well as visits to Morgantown, WV (where the Software Valley Corporation is located) and Pittsburgh where we met with an active Ada development firm and some folks at the Software Engineering Institute of Carnegie-Mellon University. For a small firm such as ours, the budget for this venture was becoming substantial, but we were making valuable progress toward our objective.Speaking of budgets, probably the largest single start-up expenditure will be the development system you select. Spend sufficient time in making this decision. In equipment, you have a myriad of choices. With the recent validation of a large number of compilers, Ada development can be done, in one form or another, on anything from PC's to the much more sophisticated full-blown systems requiring major financial expenditures — and cost, at least in our case, was a significant consideration. But cost was only one factor.We also were concerned with other areas. Our initial plans called for a system to support ten (10) developers designing systems and/or writing code. Most hardware suppliers could accommodate that in one way or another. With our lack of experience in Ada, we were also looking for ease of familiarization and operation. And we were very much concerned with the level of support a supplier could provide. Who seemed most qualified and willing to “hold our hand,” as it were, until we gained some experience?The last major consideration was credibility. We knew that as a start-up operation gaining entree and establishing our credentials with potential contractors was critical. Our development system could say a lot about our commitment and dedication. Technical capabilities being a given, we were willing to pay some premium to project the most professional image. Bottom Line: find the system that will best enable us to efficiently and effectively develop software — to give our future clients value for their programming expenditures.We investigated three major suppliers — DEC and DG, both of whom seemed quite capable; and RATIONAL, whose development environment was written in and expressly for Ada.Weighing all the factors — system capabilities, support, ease of integration and use, reputation, cost, efficiency, etc. — we came down on the side of RATIONAL, and later decided that we would supplement them with SUN Microsystems work stations.We're happy with our decision and believe, as I said at the outset about the cost of advice, that you get what you pay for. At this time, we are confident that our system configuration will satisfy our objectives and meet our expectations. Something similar mayor may not be right for you. Your situation and needs, not our experience, should dictate your direction on equipment selection. We can only recommend that you thoroughly explore the alternatives.So where were we? We had done a lot of reading and travelling; met a lot of people with whom we'd like to be professionally associated: gotten a tremendous amount of encouragement that had been tempered with some pragmatic cautions; and made some preliminary system selections. Now we were getting down to the nitty-gritty — putting our plans and a proposal down on paper so that we could launch a sales effort to put together the financing needed to make it go.In formalizing your proposal or business plan, be prepared to spend a lot of hours at a desk with all of your background notes, a dictionary, a thesaurus, calculator, plenty of paper and pencils with generous erasers. With access to a word processor and a good spreadsheet program, you are facing a formidable task; without these two tools, it will seem, and may actually be, virtually “undoable.”Your proposal or business plan can take any of several forms, and no one is necessarily more or less appropriate or effective than any other. The plan should reflect your corporate style and philosophy. But regardless of the form, there are some elements which are indispensable.Your presentation must inspire confidence in a potential investor, assuming that you, like we, have to seek outside capital to launch your effort. The plan must clearly demonstrate that you have done your homework and thoroughly researched the subject and the market. It should deal with the principal players in your scenario, their credentials, and what they can contribute to the success of the venture — what value can each add? If yours is to be an extension of an existing business, the proposal must provide business and financial history in a realistic light, yet do so as favorably as possible. Finally, the plan must provide business forecasts in the form of projected financial statements and balance sheets. Have your accountant or someone with a strong financial background assist with the financials if that is not an area in which you have experience and confidence.Ultimately, the plan must convince its readers that you have (a) identified a need in the market and (b) that you are prepared and positioned to meet it. Experienced business pros will be reviewing the plan, so make the effort, and do it right. In preparing all of this information, keep in mind that an investor who decides to participate based on the plan will view it as your commitment. He very likely will measure your success, or lack of it, by using the plan as his yardstick. So, be conservative or at least realistic. Don't put anything into your plan that you might regret. if it were referenced some time later.One of our new acquaintances offered to review our proposal. He was doing Ada work so he could evaluate the presentation from that perspective. He was also very much involved with a managing board composed of experienced venture capitalists, so he could also take a look from that viewpoint. He gave us sound advice.My point is that you should have some disinterested parties whose opinions you value and respect, and who can freely and dispassionately critique your work, review it before you run with it. And, believe me, unless you are superhuman, you will go through several drafts and revisions before you submit the plan for outsider review. Our final plan was the sixth major revision, excluding the many internal changes and edits. Preparing an acceptable and effective plan is a humbling experience that will teach you the value of patience.One final note regarding your proposal — don't overlook its appearance. A copy of the plan and an introductory letter may be your only exposure as you try to get personal appointments to market your idea. Prepare them with care and attention to detail. Ensure that they reflect the high degree of professionalism that went into their re-search and preparation and which will characterize your business efforts. The content of the plan may not even be considered if the plan itself is not attractively presented.Now that you have what you believe is a good marketing piece, where do you go with it?Our objective was to secure local financing (within our community or at least within the state of West Virginia). We drew on personal contacts, a list of local venture capitalists that we obtained from the chamber of commerce, and suggestions offered by the CEO of one of the banks with whom we had an on-going personal and business relationship.We thoroughly explored various loan, grant, and incentive programs offered by municipal, county and state governments to attract business. If you have a university near you, they may have an office that assists with business start-ups. They may be very helpful if you choose to apply for loans or grants since this is an art form in itself. Don't overlook these potentially attractive sources of advice or capital; they could make the difference.Be prepared to make phone calls, personal visits and send written correspondence in cultivating potential investors. And be sure to have your ducks in line because most of these people did not accumulate their wealth or acquire their positions because they are fiscally naive or stupid. They are, by and large, very good business people who ask direct and probing questions and expect direct, succinct, supportable answers — and a wrong answer can quickly kill an opportunity.If local capital is not available, you will have to look farther afield. That's an area in which we can't offer much advice as we did not have to pursue it. We anticipated that if we had had to look elsewhere we would have to be even more on our toes, since we would give up the advantage of common ground. We would be negotiating on their turf rather than being from the same community as the people we were soliciting.One of the biggest difficulties we encountered was in selling something intangible. As sophisticated as many lenders and investors are, some are still uncomfortable with the computer field, and especially software, as an area of opportunity.Unless high tech businesses are already an established and accepted investment arena in your area, lenders may have difficulty grasping the concept of investing in intellectual property. Loans or investments for plant and equipment are a piece of cake — you can survey, touch, walk around or kick the tires of the collateral. In dealing with software, you lose that advantage, and many people are still wary of getting financially involved with something they can't see, touch, taste, or smell.Anticipate some initial skepticism and prepare to overcome it. BEGIN NOW. This is one area where you can't start sowing seeds and nurturing them too soon. Look for or create occasions to discuss with the financial powers in your community the role and advantages and success stories and opportunities in software development. When you come across a good article — one that's not too technical — that supports your point, send copies to appropriate people. Most will be read, and you'll be strengthening your case and laying a foundation you can build on later.Aside from the “intangibility factor,” we found that the key concern of potential investors is the make-up of your staff. If you have on board people with strong credentials and proven track records in Ada, your job will be much easier. We didn't. In fact, we had the chicken-and-egg situation of having financiers citing staff as a prerequisite on the one hand; and our inability to recruit and hire a staff until we had secured financing on the other. It was one of the most frustrating aspects of the whole process.We leaned heavily on the proven track records of those of us who were organizing the venture, even though they included no Ada experience. Special expertise has to be addressed, but good basic management skills and experience are highly regarded, well-respected, and carry a lot of weight. We also capitalized on the credentials of our consultant with whom we had reached an agreement for his continuing services after our start-up, making him a legitimate member of our team. It was true that we had considerable background in computer sales, and had on our staff experienced programmers doing custom work for clients, though not in Ada. Many people perceive experience in one area of the computer field as qualification to perform in what we knew to be largely unrelated areas. Since it worked to our advantage, we did not discourage that perception.While we were putting together our financing, we did some preliminary recruiting. We secured resumes and expressions of interest from programmers by contacting the colleges and universities that were graduating students from computer science programs in our area. From the outset, our objective had been to get our programmers locally, if possible. We believe that local residents, particularly in an area like ours, are more easily attracted to job opportunities near home and are more likely to remain with us because of their ties to the area.We recognized, however, that it was critical for us to attract at least one highly experienced Ada professional to direct the programming effort. We drew on the contacts we had made and also secured the services of two firms specializing in Ada placements. Use every tool you can muster, because this is a difficult area with the explosive growth that Ada is enjoying. Experienced people are hard to find, and you must be prepared for a difficult search and the possibility that you may not have adequately budgeted for this position. This person is key, however, and if you find the right one: the time, effort, and money expended in the search will have been well worth it.Look into training, particularly if you do as we did and recruit most of your staff with little or no practical Ada experience. Budget the time and money to allow for proper training of your people and recognize that they will be unproductive for some period of time after they come on board. We completed the hiring of our staff in early Fall. Theirs is a ten-week-long training program. We anticipate beginning work on our first contract no earlier than the first of the year. Our staff will have been on the payroll for more than three months before they take their first steps toward providing a return on the investment in them.So things have finally come together. With financing secured, you have ordered and scheduled installation of your system; hired and are training your staff; and are ready to undertake some work!Getting that first contract may be a challenge. Use every means at your disposal. If you can hire a professional who can bring contracts with him, so to speak, great! If the contacts you have made in your investigations can't help open doors for you, then you haven't been contacting the right people. If you have a Senator Byrd to lend support, bravo! Get all the help you can. Don't be bashful — most people are more than willing to lend as much help as they're able. Don't leave any stone unturned. And don't wait too late to begin looking.If, somehow, you can get a contract before you configure your shop it will certainly make it easier to attract financing. We were unable to do that. Few people will let a contract to a non-existent shop. We began to actively seek a contract as soon as we had our financing in place and our hiring underway.Use every advantage to secure that first contract, but recognize that future work will be contingent on your performance and the reputation for quality that you establish. Personal relationships will become much less a factor. Don't bite off more than you can chew on that first contract. Find something manageable that will give you some experience, allow you to establish some credibility, and is small enough to be completed in a reasonable length of time. And go all out to deliver the best product possible on or ahead of schedule. Then you're on our own, and relying on your performance record — and that's as it should be. The ball will be in your court and how you handle it will determine the flow of the game for the future.I've covered a lot of ground, and again I emphasize that this has been a review of our experience - a case study in which the last chapters are just now being written - and not a “how to” course, per se. In retrospect, I don't believe that there is much that we would do differently if we were to do it again. We approached the project as a marketing problem and treated it accordingly, drawing on the expertise of others in technical and financial areas. Some of the things we learned would enable us to compress the timeframe to establish a new venture if we were to do it again, but we are relatively well satisfied with how things went.Let me close by just saying that you can become discouraged if you allow it to happen. If you are like we were, the potential of the opportunity is so enormous and so obvious that you won't be able to easily accept the reluctance and skepticism of others. Why can't they see what's as plain as day to us? Why are things taking so long? Be patient and persist. If you're committed, do your homework, lay the groundwork, and do a good selling job, things will ultimately work out. Don't lose your sense of urgency; don't allow your interest to flag; and be patient…be patient…be patient.If we have been able to give you any ideas, then we've accomplished our objective. We wish you well. Thank you.",1989,2022-08-24T07:18:21Z,2022-08-24T07:18:21Z,NA,567–580,NA,NA,NA,NA,NA,NA,TRI-Ada '88,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Charleston, West Virginia, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,PAS2DMCL,journalArticle,1986,"Iseki, Osamu; Shneiderman, Ben",Applying Direct Manipulation Concepts: Direct Manipulation Dik Operating System (DMDOS),SIGSOFT Softw. Eng. Notes,NA,0163-5948,10.1145/382248.382815,https://doi.org/10.1145/382248.382815,"Software engineers are often called upon to design user interfaces, but strategies and guidelines are only beginning to emerge. Shneiderman (1983) introduced the term ""Direct Manipulation"" to describe user interfaces which have:1) continuous representation of the objects of interest.2) physical actions (movement and selection by mouse, joystick, touch screen, etc.) or labeled button presses instead of complex Syntax.3) rapid, incremental, reversible operations whose impact on the object of interest is immediately visible.4) layered or spiral approach to learning that permits usage with minimal knowledge.The concepts of direct manipulation has been applied in some distinctive systems such as XEROX STAR and APPLE Macintosh, and many application software products such as spread sheets, word processors, drawing tools, desk-top managers, etc.However, the basic software of personal computers, the operating system, is still often based on command language concepts. This paper describes DMDOS (Direct Manipulation Disk Operating System), that we designed by applying the concepts of direct manipulation. to MS-DOS on the IBM PC.",1986-04,2022-08-24T07:18:21Z,2022-08-24T07:18:21Z,NA,22–26,NA,2,11,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,33K4TANK,journalArticle,2015,"Naveen, K. P.; Kumar, Anurag",Relay Selection with Channel Probing in Sleep-Wake Cycling Wireless Sensor Networks,ACM Trans. Sen. Netw.,NA,1550-4859,10.1145/2757280,https://doi.org/10.1145/2757280,"In geographical forwarding of packets in a large wireless sensor network (WSN) with sleep-wake cycling nodes, we are interested in the local decision problem faced by a node that has “custody” of a packet and has to choose one among a set of next-hop relay nodes to forward the packet toward the sink. Each relay is associated with a “reward” that summarizes the benefit of forwarding the packet through that relay. We seek a solution to this local problem, the idea being that such a solution, if adopted by every node, could provide a reasonable heuristic for the end-to-end forwarding problem. Toward this end, we propose a local <i>relay selection problem</i> consisting of a forwarding node and a collection of relay nodes, with the relays waking up sequentially at random times. At each relay wake-up instant, the forwarder can choose to <i>probe</i> a relay to learn its reward value, based on which the forwarder can then decide whether to <i>stop</i> (and forward its packet to the chosen relay) or to <i>continue</i> to wait for further relays to wake up. The forwarder’s objective is to select a relay so as to minimize a combination of waiting delay, reward, and probing cost. The local decision problem can be considered as a variant of the asset selling problem studied in the operations research literature. We formulate the local problem as a Markov decision process (MDP) and characterize the solution in terms of <i>stopping sets</i> and <i>probing sets</i>. We provide results illustrating the structure of the stopping sets, namely, the (lower bound) threshold and the stage independence properties. Regarding the probing sets, we make an interesting conjecture that these sets are characterized by upper bounds. Through simulation experiments, we provide valuable insights into the performance of the optimal local forwarding and its use as an end-to-end forwarding heuristic.",2015-05,2022-08-24T07:18:21Z,2022-08-24T07:18:21Z,NA,NA,NA,3,11,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,asset selling problem; geographical forwarding; Markov decision processes; sleep-wake cycling; stochastic ordering; Wireless sensor networks,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,MICHTV9Q,conferencePaper,2019,"Gaide, Brian; Gaitonde, Dinesh; Ravishankar, Chirag; Bauer, Trevor",Xilinx Adaptive Compute Acceleration Platform: Versal<sup>TM</sup> Architecture,Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays,978-1-4503-6137-8,NA,10.1145/3289602.3293906,https://doi.org/10.1145/3289602.3293906,"In this paper we describe Xilinx's Versal-Adaptive Compute Acceleration Platform (ACAP). ACAP is a hybrid compute platform that tightly integrates traditional FPGA programmable fabric, software programmable processors and software programmable accelerator engines. ACAP improves over the programmability of traditional reconfigurable platforms by introducing newer compute models in the form of software programmable accelerators and by separating out the data movement architecture from the compute architecture. The Versal architecture includes a host of new capabilities, including a chip-pervasive programmable Network-on-Chip (NoC), Imux Registers, compute shell, more advanced SSIT, adaptive deskew of global clocks, faster configuration, and other new programmable elements as well as enhancements to the CLB and interconnect. We discuss these architectural developments and highlight their key motivations and differences in relation to traditional FPGA architectures.",2019,2022-08-24T07:18:22Z,2022-08-24T07:18:22Z,NA,84–93,NA,NA,NA,NA,NA,NA,FPGA '19,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Seaside, CA, USA",NA,NA,NA,acap; adaptable compute acceleration platform; fpga; fpga architecture; fpga cad; math engine; noc; ssit; stacked silicon; versal; xilinx,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,QRB4IGTF,conferencePaper,2017,"Ekuase-Anwansedo, Ajayi; Noguera, Jose; Dumas, Brandon",Transitioning from Blackboard to Moodle amidst Natural Disaster: Faculty and Students Perceptions,Proceedings of the 2017 ACM SIGUCCS Annual Conference,978-1-4503-4919-2,NA,10.1145/3123458.3123467,https://doi.org/10.1145/3123458.3123467,"Higher educational institutions continuously look for ways to improve the quality of their eLearning services and adapt learning solutions to suit the needs of the institution. During the 2016 Fall Semester, a university located in the Southern part of United States decided to transition from the Blackboard learning management system (LMS) to the Moodle learning management system. Typically such a transition presents a huge challenge for the University staff, faculty, and students. Additionally, on August 2016, what CNN themed ""the worst natural disaster, to strike the United States since Hurricane Sandy"" [47], occurred in Louisiana during the transition. This led to massive disruptions in activities throughout the state.This paper examines the perceptions of both faculty and student on the transition from one LMS to another and also what impact, if any, the natural disaster had on the process. Faculty and students were surveyed to gain understanding of how they perceived the transitioning process, their perception of both systems, their preferences, and why. Furthermore, we identified issues peculiar to transitioning during a natural disaster. The results of this study can be used to anticipate issues that may be associated with transitioning from one LMS to the other and issues peculiar to transitioning amidst a natural disaster. It can also be used to identify areas for improvement.",2017,2022-08-24T07:18:22Z,2022-08-24T07:18:22Z,NA,19–22,NA,NA,NA,NA,NA,NA,SIGUCCS '17,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Seattle, Washington, USA",NA,NA,NA,anxiety; blackboard; depression; e-learning; flood; moodle; natural disaster; ptsd; technology acceptance model,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,6MPMBRRB,journalArticle,2010,"Marin-Perianu, Mihai; Bosch, Stephan; Marin-Perianu, Raluca; Scholten, Hans; Havinga, Paul",Autonomous Vehicle Coordination with Wireless Sensor and Actuator Networks,ACM Trans. Auton. Adapt. Syst.,NA,1556-4665,10.1145/1867713.1867714,https://doi.org/10.1145/1867713.1867714,"A coordinated team of mobile wireless sensor and actuator nodes can bring numerous benefits for various applications in the field of cooperative surveillance, mapping unknown areas, disaster management, automated highway and space exploration. This article explores the idea of mobile nodes using vehicles on wheels, augmented with wireless, sensing, and control capabilities. One of the vehicles acts as a leader, being remotely driven by the user, the others represent the followers. Each vehicle has a low-power wireless sensor node attached, featuring a 3D accelerometer and a magnetic compass. Speed and orientation are computed in real time using inertial navigation techniques. The leader periodically transmits these measures to the followers, which implement a lightweight fuzzy logic controller for imitating the leader's movement pattern. We report in detail on all development phases, covering design, simulation, controller tuning, inertial sensor evaluation, calibration, scheduling, fixed-point computation, debugging, benchmarking, field experiments, and lessons learned.",2010-11,2022-08-24T07:18:22Z,2022-08-24T07:18:22Z,NA,NA,NA,4,5,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,fuzzy control; movement coordination; vehicular networks; Wireless sensor and actuator networks,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,N24ITRMM,conferencePaper,2015,"Ismair, Simon; Wagner, Julie; Selker, Ted; Butz, Andreas",MIME: Teaching Mid-Air Pose-Command Mappings,Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services,978-1-4503-3652-9,NA,10.1145/2785830.2785854,https://doi.org/10.1145/2785830.2785854,"Mid-air gestures are initial hand poses with a subsequent movement. Existing gesture guides reveal this dynamic part of a gesture. Initial poses, however, are either revealed by space-consuming cheat sheets or time-consuming demonstration videos. Mime is a novel interaction concept that (1) reveals how to form complex hand poses and (2) teaches pose-command mappings: Mime reduces hand poses to space-efficient line figures that users mime with their hands; these abstract lines are embedded into command icons or names to create a mnemonic. We present several applications of the Mime concept, and implemented a prototype based on mid-air back-of-device interaction on off-the-shelf mobile phones. We compared both mnemonics, iconic and textual, to a baseline without embedding to test learnability and memorability of a 12-item vocabulary. Users in the iconic condition required significantly less training than both other conditions and recalled significantly more items after one week compared to the no-cue baseline.",2015,2022-08-24T07:18:23Z,2022-08-24T07:18:23Z,NA,199–206,NA,NA,NA,NA,NA,NA,MobileHCI '15,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Copenhagen, Denmark",NA,NA,NA,back-of-device interaction; feedforward; hand pose; Mid-air gesture; mnemonic; pose-command mapping,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,FQVL3Q8R,bookSection,2020,"Bolsens, Ivo",Scalable System and Silicon Architectures to Handle the Workloads of the Post-Moore Era,Proceedings of the 2020 International Symposium on Physical Design,978-1-4503-7091-2,NA,NA,https://doi.org/10.1145/3372780.3378166,"The end of Moore's law has been proclaimed on many occasions and it's probably safe to say that we are now working in the post-Moore era. But no one is ready to slow down just yet. We can view Gordon Moore's observation on transistor densification as just one aspect of a longer-term underlying technological trend - the Law of Accelerating Returns articulated by Kurzweil. Arguably, companies became somewhat complacent in the Moore era, happy to settle for the gains brought by each new process node. Although we can expect scaling to continue, albeit at a slower pace, the end of Moore's Law delivers a stronger incentive to push other trends of technology progress harder. Some exciting new technologies are now emerging such as multi-chip 3D integration and the introduction of new technologies such as storage-class memory and silicon photonics. Moreover, we are also entering a golden age of computer architecture innovation. One of the key drivers is the pursuit of domain-specific architectures as proclaimed by Turing award winners John Hennessy and David Patterson. A good example is the Xilinx's AI Engine, one of the important features of the Versal? ACAP (adaptive compute acceleration platform) [1]. Today, the explosion of AI workloads is one of the most powerful drivers shifting our attention to find faster ways of moving data into, across, and out of accelerators. Features such as massive parallel processing elements, the use of domain specific accelerators, the dense interconnect between distributed on-chip memories and processing elements, are examples of the ways chip makers are looking beyond scaling to achieve next-generation performance gains. Next, the growing demands of scaling-out hyperscale datacenter applications drive much of the new architecture developments. Given a high diversification of workloads that invoke massive compute and data movement, datacenter architectures are moving away from rigid CPU-centric structures and instead prioritize adaptability and configurability to optimize resources such as memory and connectivity of accelerators assigned to individual workloads. There is no longer a single figure of merit. It's not all about Tera-OPS. Other metrics such as transfers-per-second and latency come to the fore as demands become more real-time; autonomous vehicles being an obvious and important example. Moreover, the transition to 5G will result in solutions that operate across the traditional boundaries between the cloud and edge and embedded platforms that are obviously power-conscious and cost-sensitive. Future workloads will require agile software flows that accommodate the spread of functions across edge and cloud. Another industry megatrend that will drive technology requirements especially in encryption, data storage and communication, is Blockchain. To some, it may already have a bad reputation, tarnished by association with the anarchy of cryptocurrency, but it will be more widely relevant than many of us realize. Who could have foreseen the development of today's Internet when ARPANET first appeared as a simple platform for distributed computing and sending email? Through projects such as the open-source Hyperledger, Blockchain technology could be game-changing as a platform for building trust in transactions executed over the Internet. We may soon be talking in terms of the Trusted Internet. The predictability of Moore's law may have become rather too comfortable and slow. The future requires maximizing the flexibility, agility, and efficiency of new technologies. With Moore's Law now mostly behind us, new adaptable and scalable architectures will allow us to further provide exponential return from technology in order to create a more adaptable and intelligent world.",2020,2022-08-24T07:18:23Z,2022-08-24T07:18:23Z,NA,1–2,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,JDF95R59,conferencePaper,2021,"Chang, Dun-Hao; Chu, Po-Jui; Li, Yi-Jhen; Ning, Chun-Kai; Chien, Ting-Ying",A Clinical Decision Support System of Pressure Ulcers Tissue Classification,2021 5th International Conference on Medical and Health Informatics,978-1-4503-8984-6,NA,10.1145/3472813.3473215,https://doi.org/10.1145/3472813.3473215,"Pressure ulcers (PUs) are a common problem associated with great morbidity and cost. Because of the lack of professional personnel in the institutions or home care system, the diagnosis and treatment of PUs were sometimes delayed. We aim to develop an automatic tissue classification and severity evaluation system of PUs using AI technology. All PU images were collected from patients in the Far Eastern Memorial Hospital (FEMH) in recent 3 years and labeled according to different tissue types. The labeled images were used to train the tissue segmentation model with U-net convolutional neural network (CNN). The percentage of the different tissue can be calculated automatically and would be compared with the manually labeled one. The output of tissue classification was transformed to a clinical decision support system (CDSS) with a rule-base formula. Our study showed that proposed system can classify each tissue automatically and reach an accuracy about 93.6%. However, the CDSS's accuracy rate was only 64% for the referral suggestion and 62% for the care recommendation. Hence, the system should be modified with more data and information.",2021,2022-08-24T07:18:23Z,2022-08-24T07:18:23Z,NA,338–343,NA,NA,NA,NA,NA,NA,ICMHI 2021,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Kyoto, Japan",NA,NA,NA,AI assisted clinical decision support system (AI-CDSS); Artificial intelligence (AI); Pressure ulcers,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,2XEC6QTC,conferencePaper,2012,"Mapar, Bijan; Lam, Yeung; Mehrnia, Alireza; Bates-Jensen, Barbara; Sarrafzadeh, Majid; Kaiser, William J.",Wearable Sensor for Continuously Vigilant Spatial and Depth-Resolved Perfusion Imaging,Proceedings of the Conference on Wireless Health,978-1-4503-1760-3,NA,10.1145/2448096.2448111,https://doi.org/10.1145/2448096.2448111,"Direct characterization of blood perfusion in tissue is critical to a broad spectrum of applications in assessing circulatory disorders, wound conditions and ensuring outcomes of treatment. The rapid evolution of these conditions and their great risk for subjects require a continuously vigilant monitoring technology. This paper presents a wireless health platform providing the first wearable blood perfusion imager. This system, the Perfusion Oxygenation Monitor (POM), introduces sensing diversity by combining array methods and multispectral methods, as well as sensor and emitter distribution and operation scheduling. The principles of photoplethysmographic (PPG) sensing exploited by new methods will enable care providers to actively monitor blood perfusion at multiple anatomical sites for characterization and tracking of perfusion critical to tissue health, wound status and healing, formation of pressure ulcers, and circulation conditions. The POM system is described here along with its experimental validation. Experimental validation has been provided by a direct probing method based on physiological thermoregulatory response that induces perfusion change and is directly measured by POM. The demonstration of the POM system will also be supplemented by an analysis of the end to end system including sensor information processing, feature detection, Wireless Health data transport, and archive structure.",2012,2022-08-24T07:18:23Z,2022-08-24T07:18:23Z,NA,NA,NA,NA,NA,NA,NA,NA,WH '12,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: San Diego, California",NA,NA,NA,biomedical instrument; blood perfusion; wireless health; wound characterization,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,KAVTZSNG,conferencePaper,2021,"Oota, Subba Reddy; Rahman, Nafisur; Mohammed, Shahid Saleem; Galitz, Jeffrey; Liu, Minghsun",Wound and Episode Level Readmission Risk or Weeks to Readmit: Why Do Patients Get Readmitted? How Long Does It Take for a Patient to Get Readmitted?,8th ACM IKDD CODS and 26th COMAD,978-1-4503-8817-7,NA,10.1145/3430984.3431005,https://doi.org/10.1145/3430984.3431005,"The Affordable care Act of 2010 had introduced the readmission reduction program in 2012 to reduce avoidable readmissions to control rising healthcare costs. Wound care impacts 15%&nbsp;[16] of Medicare beneficiaries, making it one of the major contributors of medicare health care cost. Health plans have been exploring proactive health care services that can prevent wound recurrences and readmissions from controlling wound care costs. With the rising costs of the Wound care industry, it has become of paramount importance to reduce wound recurrences &amp; patient readmissions. What factors are responsible for a Wound to recur, which ultimately leads to hospitalization or readmission? Is there a way to identify the patients at risk of readmission before the occurrence using data-driven analysis? Patient readmission risk management has become critical for patients suffering from chronic wounds such as diabetic ulcers, pressure ulcers, and vascular ulcers. Understanding the risk &amp; the factors that cause patient readmission can help care providers and patients avoid wound recurrences. Our work focuses on identifying patients who are at high risk of readmission and determining the time period within which a patient might get readmitted. Frequent readmissions add financial stress to the patient &amp; Health plan and deteriorate the patient’s quality of life. Having this information can allow a provider to set up preventive measures that can delay, if not prevent, patients’ readmission. On a combined wound &amp; episode-level dataset of patient’s wound care information, our extended autoprognosis achieves a recall of 0.92 and a precision of 0.92 for predicting a patient’s readmission risk. For new patient class, precision and recall are as high as 0.91 and 0.98, respectively. We can also predict the amount of time (in weeks) it might take after a patient’s discharge event for a readmission event to occur through our model with a mean absolute error of 2.3 weeks.",2021,2022-08-24T07:18:23Z,2022-08-24T07:18:23Z,NA,359–365,NA,NA,NA,NA,NA,NA,CODS COMAD 2021,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Bangalore, India",NA,NA,NA,AutoPrognosis; Chronic Wound management; Cost Control; Health care; Machine Learning; Patient’s readmission risk; Readmission prevention; Wound care,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,marzo,HS2C7V5M,conferencePaper,1959,"Fein, Louis","The Role of the University in Computers, Data Processing, and Related Fields","Papers Presented at the the March 3-5, 1959, Western Joint Computer Conference",978-1-4503-7865-9,NA,10.1145/1457838.1457859,https://doi.org/10.1145/1457838.1457859,"Since the Fall of 1956, the author has been studying the genesis and operation of university programs in the fields of computers, data processing, operations research, and other relatively new and apparently closely related fields. The specific purposes were:1) To study and evaluate the organization, curriculum, research program, computing equipment, financing, and facilities of universities in the United States having computer and/or data processing and/or related programs.2) To identify those fields of study (some already accepted and identified as disciplines as well as those not yet so designated) that are unambiguously part of the computer and data processing fields and those closely related fields that might legitimately be part of a university program.3) To appraise the role of the universities in these fields and to determine what universities might do to build distinguished programs in these fields.",1959,2022-08-24T07:18:23Z,2022-08-24T07:18:23Z,NA,119–126,NA,NA,NA,NA,NA,NA,IRE-AIEE-ACM '59 (Western),NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: San Francisco, California",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,JZ2PL7NH,book,2011,NA,SensorKDD '11: Proceedings of the Fifth International Workshop on Knowledge Discovery from Sensor Data,NA,978-1-4503-0832-8,NA,NA,NA,"Wide-area sensor infrastructures, remote sensors, RFIDs, phasor measurements, and wireless sensor networks yield massive volumes of disparate, dynamic, and geographically distributed data. With the recent proliferation of smart-phones and similar GPS enabled mobile devices with several onboard sensors, collection of sensor data is no longer limited to scientific communities, but has reached general public. As such sensors are becoming ubiquitous, a set of broad requirements is beginning to emerge across high-priority applications including adaptability to national or homeland security, critical infrastructures monitoring, smart grids, disaster preparedness and management, greenhouse emissions and climate change, and transportation. The raw data from sensors need to be efficiently managed and transformed to usable information through data fusion, which in turn must be converted to predictive insights via knowledge discovery, ultimately facilitating automated or human-induced tactical decisions or strategic policy based on decision sciences and decision support systems.The challenges for the knowledge discovery community are expected to be immense. On the one hand are dynamic data streams or events that require real-time analysis methodologies and systems, while on the other hand are static data that require high end computing for generating offline predictive insights, which in turn can facilitate real-time analysis. The online and real-time knowledge discovery imply immediate opportunities as well as intriguing short- and long-term challenges for practitioners and researchers in knowledge discovery. The opportunities would be to develop new data mining approaches and adapt traditional and emerging knowledge discovery methodologies to the requirements of the emerging problems. In addition, emerging societal problems require knowledge discovery solutions that are designed to investigate anomalies, rare events, hotspots, changes, extremes and nonlinear processes, and departures from the normal.According to the data mining and domain experts present at the NSF-sponsored Next Generation Data Mining Summit (NGDM '09) held in October 2009, ""finding the next generation of solutions to these challenges is critical to sustain our world and civilization."" The SensorKDD series of workshops, held in conjunction with the prestigious ACM SIGKDD International Conference of Knowledge Discovery and Data Mining from 2007-2010, have aimed at bringing researchers, from different academic and applied communities, together to address these challenges and moving toward the development of the next generation data mining solutions require to address these challenges. The proposed 5th International Workshop on Knowledge Discovery from Sensor Data (SensorKDD-2011) is the next step in this successful series of workshops with the objective of providing a platform for researchers to present and discuss their research in the area of knowledge discovery from sensor data.",2011,2022-09-02T13:29:32Z,2022-09-02T13:29:32Z,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,AEFU5YVQ,conferencePaper,2012,"Kandel, Sean; Parikh, Ravi; Paepcke, Andreas; Hellerstein, Joseph M.; Heer, Jeffrey",Profiler: Integrated Statistical Analysis and Visualization for Data Quality Assessment,Proceedings of the International Working Conference on Advanced Visual Interfaces,978-1-4503-1287-5,NA,10.1145/2254556.2254659,https://doi.org/10.1145/2254556.2254659,"Data quality issues such as missing, erroneous, extreme and duplicate values undermine analysis and are time-consuming to find and fix. Automated methods can help identify anomalies, but determining what constitutes an error is context-dependent and so requires human judgment. While visualization tools can facilitate this process, analysts must often manually construct the necessary views, requiring significant expertise. We present Profiler, a visual analysis tool for assessing quality issues in tabular data. Profiler applies data mining methods to automatically flag problematic data and suggests coordinated summary visualizations for assessing the data in context. The system contributes novel methods for integrated statistical and visual analysis, automatic view suggestion, and scalable visual summaries that support real-time interaction with millions of data points. We present Profiler's architecture — including modular components for custom data types, anomaly detection routines and summary visualizations — and describe its application to motion picture, natural disaster and water quality data sets.",2012,2022-09-02T13:29:32Z,2022-09-02T13:29:32Z,NA,547–554,NA,NA,NA,NA,NA,NA,AVI '12,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Capri Island, Italy",NA,NA,NA,data analysis; anomaly detection; visualization; data quality,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,XD9B8EZS,book,2017,NA,DH '17: Proceedings of the 2017 International Conference on Digital Health,NA,978-1-4503-5249-9,NA,NA,NA,"Welcome to the 7th International Conference on Digital Health (www.acm-digitalhealth.org), supported by UCL Institute for Risk and Disaster Reduction and held in-cooperation with ACM Special Interest Group on Knowledge Discovery and Data Mining (SIGKDD) in London, UK on 2-5 July, 2017.Building on the growing success of previous editions (ehealth 2008 in London, 2009 in Istanbul, 2010 in Casablanca and ehealth 2011 in Malaga) and two editions of the International Workshop on Public Health in the Digital Age (1st PHDA 20113 and 2nd PHDA 2014), the 5th and 6th Digital Health conference was colocated with the World Wide Web conference in 2015 in Florence and in 2016 in Montreal. Digital Health has become a prime interdisciplinary international venue proudly bringing together frontline public health professionals, global health experts and computer science researchers in data mining, crowdsourcing and Big Data analysis for public health surveillance. Following the successful publication strategy, DH 2017 proceedings are included in the ACM Digital Library.This year DH 2017 is a standalone event in London, sponsored by the UCL Institute for Risk and Disaster Reduction. The move has worked out superbly - DH 2017 attracted the highest number of paper submissions, ensuring growing scientific quality of the event and growing interest from NGOs, industry, start-up innovators and charitable sector. As we also expanded the remit to cover digital solutions for emergencies and humanitarian health, the seventh DH 2017 promises to deliver the highest quality and diversity programme since its foundation.We are excited about the great keynotes in store this year, including Dr Oliver Morgan from the WHO who will deliver a talk on public health emergencies and data to save lives, Dr Tina Comes of the University of Delft speaking about designing Humanitarian Technology and Dr Paul Chong of IBM Watson discussing a joint project with Alder Hey Children's NHS Foundation Trust - the 'cognitive hospital'. Three strategic panels chaired by leading international experts in the domain will discuss the role of funding (chaired by Prof Michael Arthur, UCL provost), the future of digital imaging and microscopy (chaired by Dr Isaac Bogoch) and the role of data sharing for emergencies (chaired by Dr Michael Edelstein).We have a great academic programme including 13 full papers, 18 short papers, 6 extended medical abstracts, 29 posters and 7 demonstrators, and 11 abstracts from PhD students - plus a confirmed line-up of industry and healthcare speakers. We have also introduced a bespoke session for the SME and start-up sector bringing world class innovators together to discuss the path to success, challenges and lessons learned to inspire the new generation of innovators. The Digital Health Innovation Award - offering recognition to companies in several categories - was launched in collaboration with the Digital Catapult, UK.For more up-to-date information, 'follow' and 'like' DH 2017 on social media: Twitter: @digihealthconf (hashtag: #DH2017) Facebook: www.facebook.com/ACMDigitalHealth",2017,2022-09-02T13:29:32Z,2022-09-02T13:29:32Z,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,AEQIVCBU,conferencePaper,2021,"Kato, Hiroki; Enokibori, Yu; Yoshida, Naoto; Mase, Kenji",Toward Fine-Grained Sleeping Activity Recognition: 3d Extension and an Estimation Try on Joint Position of SLP Dataset,Adjunct Proceedings of the 2021 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2021 ACM International Symposium on Wearable Computers,978-1-4503-8461-2,NA,10.1145/3460418.3479349,https://doi.org/10.1145/3460418.3479349,"Sleeping posture estimation including joint positions is important for identifying pressure ulcer risk. Since there are occlusion and privacy problems with camera images, we have been studying 2D joint position estimation from sleeping posture pressure images. However, the 2D joint position does not reveal 3d relationships among body parts, such as crossing legs. Thus, toward fine-grained sleeping activity recognition, 3D joint position estimation is required. To study it, we extend the 2D joint-position data of SLP dataset for 3D and then tried to estimate them with high accuracy. In this paper, described the details of the 3D extension and an estimation result. With one network and two loss extensions for a 2D to 3D joint position estimation network, we achieved 6.909 ± 0.278 cm accuracy assuming the average skeleton of Japanese, with about 42.5% error reduction by the extensions.",2021,2022-09-02T13:29:33Z,2022-09-02T13:29:33Z,NA,322–327,NA,NA,NA,NA,NA,NA,UbiComp '21,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Virtual, USA",NA,NA,NA,sleeping posture; 3D annotation; 3D estimation; 3D joint position estimation; body pressure image,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,8XDFC8N6,conferencePaper,2020,"Enayati, Moein; Farahani, Nasibeh Zanjirani; Skubic, Marjorie",Machine Learning Approach for Motion Artifact Detection in Ballistocardiogram Signals,Proceedings of the 14th EAI International Conference on Pervasive Computing Technologies for Healthcare,978-1-4503-7532-0,NA,10.1145/3421937.3421970,https://doi.org/10.1145/3421937.3421970,"With the current increase in cardiovascular disease and the complexities they create, especially for aging seniors, we are working on in-home and non-invasive techniques to monitor vital signs for early detection of health conditions. Ballistocardiography has shown to be useful for long-term evaluation of myocardial strength. We have previously reported the successful utilization of our hydraulic bed sensor in the estimation of heart rate, sleep posture, and blood pressure. However, bed sensors used in naturalistic settings such as the home are known to be highly susceptible to motion artifacts.In this paper, the state-of-the-art methods for motion artifact detection and reduction are reviewed, and a new sequential machine learning approach is proposed. The proposed method is based on 53 novel features extracted jointly from time and frequency domains for noise detection. Our experiments show detection accuracy and sensitivities as high as 99%. Data were collected in two separate IRB approved data collections, one with 16-minute sequences from 25 subjects in the lab and the other with 5 sets of overnight data collected at a sleep center.",2020,2022-09-02T13:29:33Z,2022-09-02T13:29:33Z,NA,406–410,NA,NA,NA,NA,NA,NA,PervasiveHealth '20,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Atlanta, GA, USA",NA,NA,NA,Machine Learning; Ballistocardiography; Feature Engineering; Motion Artifact Detection,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,CHN7VCEL,journalArticle,2017,"Crews, Thaddens R; Boone, Ryan S.",Learning about Machine Learning through Tic-Tac-Toe Competition Scenarios,J. Comput. Sci. Coll.,NA,1937-4771,NA,NA,"In the movie ""War Games"", a global thermonuclear disaster was avoided because a computer program learned that tic-tac-toe has no winning move. But what assumptions about machine learning are necessary to get that result? This paper describes an experiment involving machine learning agents playing tic-tac-toe against each other using a variety of learning algorithms. The results indicate that the game tic-tac-toe has a distinct first mover advantage that influences the learning outcomes. The results also show that different learning strategies produce different learning results. These findings may be valuable to the discussion of machine learning in more complex environments.",2017-12,2022-09-02T13:29:33Z,2022-09-02T13:29:33Z,NA,205–212,NA,2,33,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: Evansville, IN, USA Publisher: Consortium for Computing Sciences in Colleges",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,H7ATDB46,conferencePaper,2022,"Minh Truong, Khoa; Cong Dinh, Minh; Minh Huynh, Triet; Tuan Nguyen, Duc; Hong Nguyen, Phuc; Tho Anh Nguyen, Khoa",Music Sheet Understanding and Tone Transposition,2022 The 6th International Conference on Machine Learning and Soft Computing,978-1-4503-8747-7,NA,10.1145/3523150.3523161,https://doi.org/10.1145/3523150.3523161,"Optical Music Recognition (OMR) is a sub-field in Artificial Intelligence. Automation of the translation, or understanding music sheets are the main goals of OMR. The application of this field includes the documentation of music sheets for storage or transcribing the music sheet to machine-readable formats [1]. However, on the more applied aspect of OMR, there lacks a practical application for musical Tone Transposition.Tone Transposition is the process of moving a collection of notes up or down in pitch by a constant interval. Traditionally this was a labor-intensive manual process, often impossible during a live performance. Our work proposes a method in which musicians can perform tone transposition by scanning a music sheet, inputting the number of shift tones or semitones required. Finally, the algorithm will output an audio file or a new music sheet with all notes shifted to the required pitch.",2022,2022-09-02T13:29:33Z,2022-09-02T13:29:33Z,NA,66–71,NA,NA,NA,NA,NA,NA,ICMLSC 2022,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Haikou, China",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,WU5Y7ITQ,conferencePaper,2013,"Song, Xuan; Zhang, Quanshi; Sekimoto, Yoshihide; Horanont, Teerayut; Ueyama, Satoshi; Shibasaki, Ryosuke",Modeling and Probabilistic Reasoning of Population Evacuation during Large-Scale Disaster,Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,978-1-4503-2174-7,NA,10.1145/2487575.2488189,https://doi.org/10.1145/2487575.2488189,"The Great East Japan Earthquake and the Fukushima nuclear accident cause large human population movements and evacuations. Understanding and predicting these movements is critical for planning effective humanitarian relief, disaster management, and long-term societal reconstruction. In this paper, we construct a large human mobility database that stores and manages GPS records from mobile devices used by approximately 1.6 million people throughout Japan from 1 August 2010 to 31 July 2011. By mining this enormous set of Auto-GPS mobile sensor data, the short-term and long-term evacuation behaviors for individuals throughout Japan during this disaster are able to be automatically discovered. To better understand and simulate human mobility during the disasters, we develop a probabilistic model that is able to be effectively trained by the discovered evacuations via machine learning technique. Based on our training model, population mobility in various cities impacted by the disasters throughout the country is able to be automatically simulated or predicted. On the basis of the whole database, developed model, and experimental results, it is easy for us to find some new features or population mobility patterns after the recent severe earthquake, tsunami and release of radioactivity in Japan, which are likely to play a vital role in future disaster relief and management worldwide.",2013,2022-09-02T13:29:33Z,2022-09-02T13:29:33Z,NA,1231–1239,NA,NA,NA,NA,NA,NA,KDD '13,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Chicago, Illinois, USA",NA,NA,NA,data mining; disaster informatics; human mobility,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,3MAFV4V2,conferencePaper,2016,"Lee, Sukhoon; Park, JaeYeon; Kim, Doyeop; Kim, Tae Young; Park, Rae Woong; Yoon, Dukyong; Ko, JeongGil",Constructing a Bio-Signal Repository from an Intensive Care Unit for Effective Big-Data Analysis: Poster Abstract,Proceedings of the 14th ACM Conference on Embedded Network Sensor Systems CD-ROM,978-1-4503-4263-6,NA,10.1145/2994551.2996712,https://doi.org/10.1145/2994551.2996712,"Analyzing large quantities of bio-signal data can lead to new findings in patient status diagnosis and medical emergency event prediction. Specifically, improvements in machine learning schemes suggest that by inputting clinical waveforms, designing mechanisms to predict medical emergencies, such as ventricular arrhythmia or sepsis, can soon be possible. However, we are still lacking the data-vaults that provide such clinically useful bio-signal data. With the goal of providing such an environment, this work focuses on developing a data repository for bio-signals collected from a hospital's intensive care init (ICU). Specifically, we design our data collection system to effectively store data from at-bed patient monitors and also integrate sensing information from bed-embedded sensing platforms, which allow filtering of noisy bio-signal samples caused by motion artifacts.",2016,2022-09-02T13:29:33Z,2022-09-02T13:29:33Z,NA,372–373,NA,NA,NA,NA,NA,NA,SenSys '16,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Stanford, CA, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,ZN6IHUUR,conferencePaper,2009,"Hees, Frank; Jeschke, Sabina; Natho, Nicole; Pfeiffer, Olivier",Developing a PBL-Based Rescue Robotics Course,Proceedings of the First Kuwait Conference on E-Services and e-Systems,978-1-60558-797-4,NA,10.1145/1836029.1836039,https://doi.org/10.1145/1836029.1836039,"Problem-based learning (PBL) denotes self-determined learning and learning through discovery, activity-based education, interdisciplinary education, and self-assessment. The participants in problem based learning courses learn to analyze a subject or a problem with minimal guidance by their teacher or rather their facilitator of learning. Students find and use the suitable sources of information by themselves, and finally, compare, select and convert the results. The essential highlight of the PBL approach is the examination of authentic (real life) and complex subjects. The origin of the PBL lies in application-based technical engineering subjects and later in medical education.Robotics education is perfectly suited for the application of PBL-scenarios as robotics combines a multitude of technological disciplines (ranging from computer sciences, software engineering, artificial intelligence, electrical engineering up to technology design) and its ubiquitous popularity with a variety soft skills (team skills, complex problem-solving strategies, etc.), required in the development process. The popularity of robots can be easily deduced from the large number of robotic heroes in literature and movies. Thus, robotics is ideally suited as a model project-oriented course of combining communication skills, development of strategies to solve complex interdisciplinary challenges, and different concepts of soft- and hardware engineering.Among the wide range of robotics applications, one field of particular importance is the field of ""Rescue Robots"". Here, robots are developed that operate in catastrophe-scenarios, e.g. earthquakes or fires. Based on the data obtained from their various sensors (video cameras, infrared sensors, laser scanner and gas sensors), these robots have to manage their tasks autonomously in catastrophe-based scenarios. This comprises detection, rescue, and aid for victims should the situation arise. In order to fulfill these complex tasks, development of basic skills such as exact movements on unstable bedrock, field mapping, positioning and communication in weakly structured environments is necessary. Besides the construction of preferably all-terrain and robust robots, the improvement of innovative analysis procedures for complex sensor data is another focus of development. In addition, conception and realization of novel man-machine-interfaces come to the fore in order to support the operators of robots with their exhausting control tasks.Integrated in the ""RoboCup"", the ""Rescue-Robot League"" clarifies the intensified orientation of the ""RoboCup initiative"" on real life applications. Another hint that rescue robotics represents a ideal playground for PBL scenarios in academic education.Beyond that, robotics is increasing the number of female students in the natural sciences and engineering. It has the potential of attracting girls and young females at their respective levels education by illustrating their own potential in a playful experimental setting. Independent design and construction of robots demonstrates the importance of creativity and social relevance, giving young women more confidence in their technical and scientific skills, facts affecting young women's choice of degree.",2009,2022-09-02T13:29:33Z,2022-09-02T13:29:33Z,NA,NA,NA,NA,NA,NA,NA,NA,eConf '09,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,event-place: Kuwait,NA,NA,NA,robotics; academic education; PBL,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,AE3RHTIP,conferencePaper,2017,"Park, Jaeyeon; Nam, Woojin; Choi, Jaewon; Kim, Taeyeong; Yoon, Dukyong; Lee, Sukhoon; Paek, Jeongyeup; Ko, JeongGil",Glasses for the Third Eye: Improving the Quality of Clinical Data Analysis with Motion Sensor-Based Data Filtering,Proceedings of the 15th ACM Conference on Embedded Network Sensor Systems,978-1-4503-5459-2,NA,10.1145/3131672.3131690,https://doi.org/10.1145/3131672.3131690,"Recent advances in machine learning based data analytics are opening opportunities for designing effective clinical decision support systems (CDSS) which can become the ""third-eye"" in the current clinical procedures and diagnosis. However, common patient movements in hospital wards may lead to faulty measurements in physiological sensor readings, and training a CDSS from such noisy data can cause misleading predictions, directly leading to potentially dangerous clinical decisions. In this work, we present MediSense, a system to sense, classify, and identify noise-causing motions and activities that affect physiological signal when made by patients on their hospital beds. Essentially, such a system can be considered as ""glasses"" for the clinical third eye in correctly observing medical data. MediSense combines wirelessly connected embedded platforms for motion detection with physiological signal data collected from patients to identify faulty physiological signal measurements and filters such noisy data from being used in CDSS training or testing datasets. We deploy our system in real intensive care units (ICUs), and evaluate its performance from real patient traces collected at these ICUs through a 4-month pilot study at the Ajou University Hospital Trauma Center, a major hospital facility located in Suwon, South Korea. Our results show that MediSense successfully classifies patient motions on the bed with &gt;90% accuracy, shows 100% reliability in determining the locations of beds within the ICU, and each bed-attached sensor achieves a lifetime of more than 33 days, which satisfies the application-level requirements suggested by our clinical partners. Furthermore, a simple case-study with arrhythmia patient data shows that MediSense can help improve the clinical diagnosis accuracy.",2017,2022-09-02T13:29:34Z,2022-09-02T13:29:34Z,NA,NA,NA,NA,NA,NA,NA,NA,SenSys '17,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Delft, Netherlands",NA,NA,NA,Clinical Decision Support System; Health Care Information Systems; Motion Sensing; Noise Filter; Wireless Sensor Network,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,TI69ARHD,conferencePaper,2007,"Shankar, Anil; Louis, Sushil J.; Dascalu, Sergiu; Hayes, Linda J.; Houmanfar, Ramona",User-Context for Adaptive User Interfaces,Proceedings of the 12th International Conference on Intelligent User Interfaces,1-59593-481-2,NA,10.1145/1216295.1216357,https://doi.org/10.1145/1216295.1216357,"We present results from an empirical user-study with ten users which investigates if information from a user's environment helps a user interface to personalize itself to individual users to better meet usability goals and improve user-experience. In our research we use a microphone and a web-camera to collect this information (user-context) from the vicinity of a subject's desktop computer. Sycophant, our context-aware calendaring application and research test-bed uses machine learning techniques to successfully predict a user-preferred alarm type. Discounting user identity and motion information significantly degrades Sycophant's performance on the alarm prediction task. Our user study emphasizes the need for user-context for personalizable user interfaces which can better meet effectiveness and utility usability goals. Results from our study further demonstrate that contextual information helps adaptive interfaces to improve user-experience.",2007,2022-09-02T13:29:34Z,2022-09-02T13:29:34Z,NA,321–324,NA,NA,NA,NA,NA,NA,IUI '07,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Honolulu, Hawaii, USA",NA,NA,NA,machine learning; context; learning classifier systems; user-context,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,NTVH3K5L,journalArticle,2005,"Lee, Newton",A Word from the Editor,Comput. Entertain.,NA,NA,10.1145/1057270.1057431,https://doi.org/10.1145/1057270.1057431,"Welcome to the third volume and first issue of 2005 for the ACM Computers in Entertainment online magazine!In this issue we publish seven interesting papers on entertainment technologies, including animation, games, interactive TV, storytelling, and artificial intelligence. The article on inverse kinematics was voted the best paper and presentation at the Second International Game Design and Technology Workshop, held last September at Liverpools John Moores University.To begin, the Interviews column features video interviews with three of our distinguished advisory board members: Bill Kinder, Elisabeth Freeman, and Eric Freeman. Bill Kinder, Director of Editorial and Postproduction at the Pixar Animation Studios, talks about the new technology for the Pixar movies ""The Incredibles (2004)"" and ""Cars (2006)"", digital cinema, home theater, and animation. Elisabeth and Eric Freeman, authors and computer scientists, discuss digital rights management, movies on demand, disruptive technology, and their new book, Head First Design Patterns (O'Reilly, 2004).In the Animation section, Michael Meredith and Steve Maddock (University of Sheffield) present a technique that enhances an inverse kinematics solver such that when the results are applied to a computer character, they can generate a level of individualization tailored to both the character and the environment, e.g. a walking motion can become ""stiffer"" or can be turned into a limping motion. The article is accompanied by four exciting videos that demonstrate the authors techniques. Bill Tomlinson (University of California, Irvine) describes the differences between linear animation and interactive animation in several areas of character design: character intelligence, emotional expressiveness, navigation, transitions among animations, and multi-character interaction.In the Games section, Jesse Schell (Carnegie Mellon University) explores the common principles that underlie both story- and game-based entertainment. He argues that with the advent of computer games, story and gameplay, two age-old enterprises with very different sets of rules, are showing a similar phenomenon to the ""wave-particle"" duality in the physical world. Bride Mallon and Brian Webb (Queens University of Belfast) report results from a series of empirical studies exploring narrative dimensions of adventure and role-play in computer-game design. A phenomenological, reader-response methodology was used in their studies to identify narrative considerations appropriate to the game-players experiences.In the Interactive Television section, Lydia Loizides (Paphion Inc. &amp; National Academy of Television Arts and Sciences) dispels the mistruths and misconceptions in the media concerning interactive TV. She shows some examples of advancement that iTV has made over the past decade, and ponders how quickly the industry can embrace and deploy interactive applications that will ultimately make watching television a more relevant and satisfying experience for the viewer.In the Book Reviews column, Georgios N. Yannakakis (University of Southern Denmark) reviews the book AI Game Development: Synthetic Creatures with Learning and Reactive Behaviors by Alex J. Champandard (New Riders, 2004). The book attempts to bridge the current gap between artificial intelligence research in academia and computer game development in industry. The language-independent open-source project FEAR (Flexible Embodied Animat aRchitecture http://fear.sourceforge.net/) is used extensively in the book for demos and examples. Edgar A. Maldonado and Joseph A. Zupko (The Pennsylvania State University) review the book Interactive Storytelling: Techniques for 21st Century Fiction by Andrew S. Glassner (A K Peters, 2004). The book analyzes games and storytelling, and describes the principal problems that developers face in their attempts to merge these two activities into an interactive form of entertainment. It would be interesting to compare and contrast the book and Jesse Schells paper ""Understanding Entertainment: Story and Gameplay Are One"" published in this issue.Last but not least, we join the world in expressing our deep sorrows and sympathy for the earthquake and tsunami victims in many parts of Asia and east Africa. We support the United Nations Childrens Fund www.unicefusa.org, the American Red Cross www.redcross.org, and other disaster relief agencies. The meaning of life for human beings is to serve one another for the survival of humanity and the advancement of civilization.Thank you for your continuing support. Please enjoy this exciting issue of the magazine.Sincerely, Newton Lee Editor-in-Chief ACM Computers in Entertainment Los Angeles— January 2005",2005-01,2022-09-02T13:29:34Z,2022-09-02T13:29:34Z,NA,1,NA,1,3,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,PAYJ2MJT,conferencePaper,2020,"Jayaweera, Nimna; Gamage, Binura; Samaraweera, Mihiri; Liyanage, Sachintha; Lokuliyana, Shashika; Kuruppu, Thilmi",Gesture Driven Smart Home Solution for Bedridden People,Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering Workshops,978-1-4503-8128-4,NA,10.1145/3417113.3422998,https://doi.org/10.1145/3417113.3422998,"Conversion of ordinary houses into smart homes has been a rising trend for past years. Smart house development is based on the enhancement of the quality of the daily activities of normal people. But many smart homes have not been designed in a way that is user friendly for differently-abled people such as immobile, bedridden (disabled people with at least one hand movable). Due to negligence and forgetfulness, there are cases where the electrical devices are left switched on, regardless of any necessity. It is one of the most occurred examples of domestic energy wastage. To overcome those challenges, this research represents the improved smart home design: MobiGO that uses cameras to capture gestures, smart sockets to deliver gesture-driven outputs to home appliances, etc. The camera captures the gestures done by the user and the system processes those images through advanced gesture recognition and image processing technologies. The commands relevant to the gesture are sent to the specific appliance through a specific IoT device attached to them. The basic literature survey content, which contains technical words, is analyzed using Deep Learning, Convolutional Neural Network (CNN), Image Processing, Gesture recognition, smart homes, IoT. Finally, the authors conclude that the MobiGO solution proposes a smart home system that is safer and easier for people with disabilities.",2020,2022-09-02T13:29:34Z,2022-09-02T13:29:34Z,NA,152–158,NA,NA,NA,NA,NA,NA,ASE '20,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Virtual Event, Australia",NA,NA,NA,deep learning; computer vision; internet of things; gesture; smart appliances,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,9AGPDF4V,conferencePaper,2021,"Zhao, Yijun; Shen, Yong; Wang, Xiaoqing; Cao, Jiacheng; Xia, Shang; Ying, Fangtian; Wang, Guanyun",PneuMat: Pneumatic Interaction System for Infant Sleep Safety Using Shape-Changing Interfaces,Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems,978-1-4503-8095-9,NA,10.1145/3411763.3451597,https://doi.org/10.1145/3411763.3451597,"Sleep plays an integral role in human health and is vitally important for neurological development in infants. In this study, we propose the PneuMat, an interactive shape-changing system integrating sensors and pneumatic drives, to help ensure sleep safety through novel human-computer interaction. This system comprises sensor units, control units and inflatable units. The sensor units utilize information exchange between infants and the system, and detect the infant's sleeping posture, sending raw data to control units. For better sleep experience, the inflatable units are divided into nine areas. The inflatable units are multi-mode, can be independently inflated in different areas, and can be inflated in different areas together. We aim to ensure sleep safety by ensuring that infants stay in a safe sleeping position while in bed, by autonomously actuating the PneuMat's shape-changing capability. In this article, we describe the division of PneuMat, the design of the control unit, integration of the sensors and our preliminary experiments to evaluate the feasibility of our interaction system. Finally, based on the results, we will discuss future work involving the PneuMat.",2021,2022-09-02T13:29:34Z,2022-09-02T13:29:34Z,NA,NA,NA,NA,NA,NA,NA,NA,CHI EA '21,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Yokohama, Japan",NA,NA,NA,Infant; Interaction system; Shape-changing interfaces,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,XK6PVZBR,conferencePaper,2012,"Onut, Iosif Viorel",3rd Workshop on Smart Surveillance System Applications,Proceedings of the 2012 Conference of the Center for Advanced Studies on Collaborative Research,NA,NA,NA,NA,"Automatic recognition of people and their activities has very important social implications, because it is related to the extremely sensitive topic of civil liberties. Society needs to address this issue of automatic recognition and find a balanced solution that is able to meet its various needs and concerns. In the post 9/11 period, population security and safety considerations have given rise to research needs for identification of threatening human activities and emotional behaviours.Timely identification of human intent is one of the most challenging areas of ""all-hazards"" risk assessment in the protection of critical infrastructure, business continuity planning and community safety. The ""all-hazards"" approach is used extensively by the public and private sector, including Public Safety Canada (PS Canada – formerly PSEPC), Emergency Management Ontario (EMO), US Federal Emergency Management Agency (FEMA) and US Department of Homeland Security (DHS).There is a clear need for industry and the research community to addresses fundamental issues involved in the prevention of human-made disasters, namely the variable context-dependent, real-time detection/identification of potential threatening behaviour of humans, acting individually or in crowded environments.Such an industry and academia forum will have to discuss development and commercialization of new multimodal (video and infrared, voice and sound, RFID and perimeter intrusion) intelligent sensor technologies for location and socio-cultural context-aware security risk assessment and decision support in human-crowd surveillance applications in environments such as school campuses, hospitals, shopping centers, subways or railway stations, airports, sports and artistic arenas etc. Due to the complexity of the surveillance task, there is a clear need for the development of a distributed intelligent surveillance system architecture, which combines visual and audio surveillance based on wireless sensor nodes equipped with video or infrared (IR) cameras, audio detectors, or other object detection and motion sensors with location aware wireless sensor network solutions. The integration of visual, sound and radio tracking methods results in a highly intelligent, proactive, and adaptive surveillance and security solution sensor networks. Task-directed sensor data collection and observation planning algorithms need to be developed to allow for a more elastic and efficient use of the inherently limited sensing and processing capabilities. Each task a sensor has to carry out determines the nature and the level of the information that is actually needed. There is a need for ""selective environment perception"" methods that focus on object parameters that are important for the specific decision to be made for the task at hand and avoid wasting effort to process irrelevant data.Multisensor data fusion techniques should be investigated for the dynamic integration of the multi-thread flow of information provided by the heterogeneous network of surveillance sensors into a coherent multimodal model of the monitored human crowd.In the context of crowds, robust tracking of people represents an important challenge. The numerous sources of occlusions and the large diversity of interactions that might occur make difficult the long-term tracking of a particular individual over an extended period of time and using a network of sensors. Realtime image processing and computer-vision algorithms need to be studied for the identification, tracking and recognition of gait and other relevant body-language patterns of the human agents who can be deemed of interest for security reasons. Real-time signal processing algorithms have to be designed for the identification and evaluation of environmental and human-subject multimodal parameters (such as human gait, gestures, facial emotions, human voice, background sound, ambient light, etc.) that provide the contextual information for the specific surveillance activity.A multidisciplinary, context-aware, situation-assessment system, including human behaviour, cognitive psychology, multicultural sociology, learning systems, artificial intelligence, distributed multimedia and software design elements, has to be ultimately developed for the real-time evaluation of the activity and emotional behaviour of the human subjects identified as being potentially of security interest in the monitored dynamic environment.The development of such a complex system requires the seamless integration of new and improved surveillance techniques and methodologies supporting both functional and non functional requirements for surveillance networks. Functional requirements are signal processing functions and data fusion, archiving and tracking human behaviours, assessment and interpretation functions of the data, and supporting human decision makers, among others. Non-functional requirements include interoperability, scalability, availability, and manageability.The partial and heterogeneous sensor-views of the environment have to fuse into a coherent Virtualized Reality Environment (VRE) model of the explored environment. Being based on information about real/physical world objects and phenomena, as captured by a variety of sensors, VREs have more ""real content"" than the pure Virtual Reality environments entirely based on computer simulations. The VREs model of the explored environment allows human operators to combine their intrinsic reactive-behaviour with higher-order world model representations of the immersive VRE systems.A synthetic environment will eventually be needed to provide efficient multi granularity-level function-specific feedback and human-computer interaction interfaces for the human users who are the final assessors and decision makers in the specific security monitoring situation.An ideal system should provide efficient multi granularity-level function-specific feedback for the human users who are the final assessors and decision makers in the specific security monitoring situation.The rate at which surveillance systems can currently disseminate data to evaluate new threats is mainly limited due to the developed and implemented nature of existing systems and their limited ability to operate with other systems. IBM's Service-Oriented Architecture (SOA) provides the much needed deployment ready solution which supports the integration of external systems developed by diverse industrial and institutional partners.",2012,2022-09-02T13:29:34Z,2022-09-02T13:29:34Z,NA,262–264,NA,NA,NA,NA,NA,NA,CASCON '12,NA,NA,NA,IBM Corp.,USA,NA,NA,NA,NA,NA,NA,NA,"event-place: Toronto, Ontario, Canada",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,3CKBJY2T,conferencePaper,2011,"Onut, Iosif Viorel (Vio); Aldridge, Don; Mindel, Marcellus; Perelgut, Stephen",2nd Workshop on Smart Surveillance System Applications,Proceedings of the 2011 Conference of the Center for Advanced Studies on Collaborative Research,NA,NA,NA,NA,"Motivation and Justification:Automatic recognition of people and their activities has very important social implications, because it is related to the extremely sensitive topic of civil liberties. Society needs to address this issue of automatic recognition and find a balanced solution that is able to meet its various needs and concerns. In the post 9/11 period, population security and safety considerations have given rise to research needs for identification of threatening human activities and emotional behaviours.Timely identification of human intent is one of the most challenging areas of ""all-hazards"" risk assessment in the protection of critical infrastructure, business continuity planning and community safety. The ""all-hazards"" approach is used extensively by the public and private sector, including Public Safety Canada (PS Canada – formerly PSEPC), Emergency Management Ontario (EMO), US Federal Emergency Management Agency (FEMA) and US Department of Homeland Security (DHS).There is a clear need for industry and the research community to addresses fundamental issues involved in the prevention of human-made disasters, namely the variable context-dependent, real-time detection/identification of potential threatening behaviour of humans, acting individually or in crowded environments.Such an industry and academia forum will have to discuss development and commercialization of new multimodal (video and infrared, voice and sound, RFID and perimeter intrusion) intelligent sensor technologies for location and socio-cultural context-aware security risk assessment and decision support in human-crowd surveillance applications in environments such as school campuses, hospitals, shopping centers, subways or railway stations, airports, sports and artistic arenas etc. Due to the complexity of the surveillance task there is a clear need for the development of a distributed intelligent surveillance system architecture, which combines visual and audio surveillance based on wireless sensor nodes equipped with video or infrared (IR) cameras, audio detectors, or other object detection and motion sensors with location aware wireless sensor network solutions. The integration of visual, sound and radio tracking methods results in a highly intelligent, proactive, and adaptive surveillance and security solution sensor networks. Task-directed sensor data collection and observation planning algorithms need to be developed to allow for a more elastic and efficient use of the inherently limited sensing and processing capabilities. Each task a sensor has to carry out determines the nature and the level of the information that is actually needed. There is a need for ""selective environment perception"" methods that focus on object parameters that are important for the specific decision to be made for the task at hand and avoid wasting effort to process irrelevant data.Multisensor data fusion techniques should be investigated for the dynamic integration of the multi-thread flow of information provided by the heterogeneous network of surveillance sensors into a coherent multimodal model of the monitored human crowd.In the context of crowds, robust tracking of people represents an important challenge. The numerous sources of occlusions and the large diversity of interactions that might occur make difficult the long-term tracking of a particular individual over an extended period of time and using a network of sensors. Realtime image processing and computer-vision algorithms need to be studied for the identification, tracking and recognition of gait and other relevant body-language patterns of the human agents who can be deemed of interest for security reasons. Real-time signal processing algorithms have to be designed for the identification and evaluation of environmental and human-subject multimodal parameters (such as human gait, gestures, facial emotions, human voice, background sound, ambient light, etc.) that provide the contextual information for the specific surveillance activity.A multidisciplinary, context-aware, situation-assessment system, including human behaviour, cognitive psychology, multicultural sociology, learning systems, artificial intelligence, distributed multimedia and software design elements, has to be ultimately developed for the real-time evaluation of the activity and emotional behaviour of the human subjects identified as being potentially of security interest in the monitored dynamic environment.The development of such a complex system requires the seamless integration of new and improved surveillance techniques and methodologies supporting both functional and non functional requirements for surveillance networks. Functional requirements are signal processing functions and data fusion, archiving and tracking human behaviours, assessment and interpretation functions of the data, and supporting human decision makers, among others. Non-functional requirements include interoperability, scalability, availability, and manageability.The partial and heterogeneous sensor-views of the environment have to fuse into a coherent Virtualized Reality Environment (VRE) model of the explored environment. Being based on information about real/physical world objects and phenomena, as captured by a variety of sensors, VREs have more ""real content"" than the pure Virtual Reality environments entirely based on computer simulations. The VREs model of the explored environment allows human operators to combine their intrinsic reactive-behavior with higher-order world model representations of the immersive VRE systems.A synthetic environment will eventually be needed to provide efficient multi granularity-level function-specific feedback and human-computer interaction interfaces for the human users who are the final assessors and decision makers in the specific security monitoring situation.An ideal system should provide efficient multi granularity-level function-specific feedback for the human users who are the final assessors and decision makers in the specific security monitoring situation.The rate at which surveillance systems can currently disseminate data to evaluate new threats is mainly limited due to the developed and implemented nature of existing systems and their limited ability to operate with other systems. IBM's Service-Oriented Architecture (SOA) provides the much needed deployment ready solution which supports the integration of external systems developed by diverse industrial and institutional partners.",2011,2022-09-02T13:29:34Z,2022-09-02T13:29:34Z,NA,382–384,NA,NA,NA,NA,NA,NA,CASCON '11,NA,NA,NA,IBM Corp.,USA,NA,NA,NA,NA,NA,NA,NA,"event-place: Toronto, Ontario, Canada",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,2EM5P3QK,journalArticle,2006,"Lai, Chih; Rafa, Taras; Nelson, Dwight E.",Mining Motion Patterns Using Color Motion Map Clustering,SIGKDD Explor. Newsl.,NA,1931-0145,10.1145/1233321.1233322,https://doi.org/10.1145/1233321.1233322,"Automatically extracting previously unknown behavior patterns from videos that track animals with various physical conditions can accelerate our understanding of animal behaviors and their influential factors, resulting in major medical and economic benefits. Unfortunately, extracting behavior patterns from videos recordings remains as a very challenging task due to their extensive duration and the unstructured natures. This task is further complicated in a completely darken animal cage with inconsistent infrared lighting, moving reflections, or other cage debris such as the cage bedding. In this research, we propose a new motion model that enables us to measure the similarities among different animal movements in high precision so a clustering method can correctly separate recurring movements from infrequent random movements. More specifically, our model first transforms the spatial and temporal features of animal movements into a sequence of color images, referred to as color motion maps (CMMs). The task of mining recurring behavior patterns is then reduced to clustering similar color images in a database. We will use a real infrared video to demonstrate the capability of our model in capturing distinguished but brief animal movements that are embedded within a sequence of other animal movements.",2006-12,2022-09-02T13:29:34Z,2022-09-02T13:29:34Z,NA,3–10,NA,2,8,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,binary motion map (BMM); color autocorrelogram; color motion map (CMM),NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,ZTZDA7GZ,conferencePaper,2013,"Ranu, Sayan; Telang, Aditya D.; Kolar, Vinay","Trajectory Analytics: Indexing, Mining, and Applications to Network Optimization",Proceedings of the 19th International Conference on Management of Data,NA,NA,NA,NA,"The last decade has witnessed an unprecedented growth in the availability of devices equipped with location-tracking sensors. Examples of such devices include cellphones, in-car navigation systems and weather monitoring gadgets. The widespread usage of these devices has resulted in an abundance of data that are in the form of trajectories. Querying and mining these trajectories is critical to extract the knowledge hidden in the raw datasets and to design intelligent spatio-temporal data management systems. For example, in cellular network analytics, cellphone service providers are interested in identifying ""bottleneck"" regions that affect a high volume of trajectories due to poor coverage [15]. In zoology, tracking movements of animals is critical to understand their flocking behaviors [8] and migratory patterns [1]. Meteorologists are interested in analyzing trajectories of wildfires and tornadoes to identify ""alleys"" that are conducive to these environmental disasters [13]. For efficient traffic management, governmental agencies are interested in understanding how congestions spread across a road network so that infrastructure developments can be prioritized in an appropriate manner. In this tutorial, we will survey the rich area of trajectory analytics, which offers solutions to the above problems. Additionally, we will analyze the pros and cons of existing techniques and outline challenges that remain to be solved.",2013,2022-09-02T13:29:35Z,2022-09-02T13:29:35Z,NA,11–12,NA,NA,NA,NA,NA,NA,COMAD '13,NA,NA,NA,Computer Society of India,"Mumbai, Maharashtra, IND",NA,NA,NA,NA,NA,NA,NA,"event-place: Ahmedabad, India",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,CUBZCJRP,journalArticle,2015,"Kalinin, Alexander; Cetintemel, Ugur; Zdonik, Stan",Searchlight: Enabling Integrated Search and Exploration over Large Multidimensional Data,Proc. VLDB Endow.,NA,2150-8097,10.14778/2794367.2794378,https://doi.org/10.14778/2794367.2794378,"We present a new system, called Searchlight, that uniquely integrates constraint solving and data management techniques. It allows Constraint Programming (CP) machinery to run efficiently inside a DBMS without the need to extract, transform and move the data. This marriage concurrently offers the rich expressiveness and efficiency of constraint-based search and optimization provided by modern CP solvers, and the ability of DBMSs to store and query data at scale, resulting in an enriched functionality that can effectively support both data- and search-intensive applications. As such, Searchlight is the first system to support generic search, exploration and mining over large multi-dimensional data collections, going beyond point algorithms designed for point search and mining tasks.Searchlight makes the following scientific contributions:• Constraint solvers as first-class citizens Instead of treating solver logic as a black-box, Searchlight provides native support, incorporating the necessary APIs for its specification and transparent execution as part of query plans, as well as novel algorithms for its optimized execution and parallelization.• Speculative solving Existing solvers assume that the entire data set is main-memory resident. Searchlight uses an innovative two stage Solve-Validate approach that allows it to operate speculatively yet safely on main-memory synopses, quickly producing candidate search results that can later be efficiently validated on real data.• Computation and I/O load balancing As CP solver logic can be computationally expensive, executing it on large search and data spaces requires novel CPU-I/O balancing approaches when performing search distribution.We built a prototype implementation of Searchlight on Google's Or-Tools, an open-source suite of operations research tools, and the array DBMS SciDB. Extensive experimental results show that Searchlight often performs orders of magnitude faster than the next best approach (SciDB-only or CP-solver-only) in terms of end response time and time to first result.",2015-06,2022-09-02T13:29:35Z,2022-09-02T13:29:35Z,NA,1094–1105,NA,10,8,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Publisher: VLDB Endowment,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,TN72NJCV,journalArticle,2013,"Natanzon, Assaf; Bachmat, Eitan",Dynamic Synchronous/Asynchronous Replication,ACM Trans. Storage,NA,1553-3077,10.1145/2508011,https://doi.org/10.1145/2508011,"Online, remote, data replication is critical for today’s enterprise IT organization. Availability of data is key to the success of the organization. A few hours of downtime can cost from thousands to millions of dollars With increasing frequency, companies are instituting disaster recovery plans to ensure appropriate data availability in the event of a catastrophic failure or disaster that destroys a site (e.g. flood, fire, or earthquake).Synchronous and asynchronous replication technologies have been available for a long period of time. Synchronous replication has the advantage of no data loss, but due to latency, synchronous replication is limited by distance and bandwidth. Asynchronous replication on the other hand has no distance limitation, but leads to some data loss which is proportional to the data lag. We present a novel method, implemented within EMC Recover-Point, which allows the system to dynamically move between these replication options without any disruption to the I/O path. As latency grows, the system will move from synchronous replication to semi-synchronous replication and then to snapshot shipping. It returns to synchronous replication as more bandwidth is available and latency allows.",2013-08,2022-09-02T13:29:39Z,2022-09-02T13:29:39Z,NA,NA,NA,3,9,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,Remote replication,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,9T4SH73Q,conferencePaper,1987,"Hammond, W. E.",Patient Management Systems: The Early Years,Proceedings of ACM Conference on History of Medical Informatics,0-89791-248-9,NA,10.1145/41526.41541,https://doi.org/10.1145/41526.41541,"As I scanned through old papers and reports in preparation for these remarks, I became depressed in the “sameness” of those proposals and descriptions with what is happening today. Then I realized there are major differences - today's systems work and are affordable.The health care delivery system is an industry whose magnitude, complexity and pervasiveness are rarely acknowledged. In a few decades, the industry has literally changed from a cottage industry to a multi-billion dollar giant with whom every individual in our society has come into contact. It is a personal industry, yet at the same time, one of our most technically sophisticated industries. It is not surprising that computers are becoming an integral part of that system. This paper discusses some of the experiences in reaching that goal.As a beginning engineer back in the 1960s, I, with many others, felt that the development of computerized patient management systems was not only natural but mandatory. One merely needs to observe the process to realize that keeping track of what was done and charging appropriately, of sending information from one place to another, of storing data and printing it on demand, and of controlling process and flow are tasks which computers perform well. Many medical specialties already used forms for the collection of data. Most medical knowledge was already clearly identified in textbooks, including what questions to ask, what parameters to measure, what tests to order, how to diagnose, and how to treat. “A simple matter of programming” was a phrase often used and believed. It later became a standing joke. Many predicted that the use of computers for medical applications would develop into a multi-million dollar market whose potential would be quickly realized. The actual events proved to be quite different.The development of patient management systems has been influenced by several factors. The first, and perhaps one of the most significant factors, is that of technology - hardware and software. During this development period, computers evolved from single tasking, “untouchable” and “unfriendly” mainframes to highly interactive, multiuser minicomputers.A second factor is that of the people involved - both the developers and the users. The developers had to learn first what to do and how to do it and then learn how to package and sell it to the ultimate user.Economic factors also influenced progress. As computer costs decreased, the cost of delivering patient care increased. Computers seem to be offer one way to reduce and control these costs.Another factor was the tremendous increase in the amount of data generated and the demand for that data by a variety of individuals. For example, both the number of laboratory tests available and the number of tests actually ordered increased exponentially during this period. Estimates on the costs of information handling vary between 25 and 39% of the total cost of health care [1]. With the influx of many research dollars from NIH, actual medical knowledge increased.Finally, the influence of external factors such as the government and third party payers contributed significantly to the development of patient management systems. As one observer commented [2], “I think that just as the Medicare legislation forced hospitals, almost without exception, to use the computer for financial processing, patient accounting, and patient billing, the PSRO type of thing - which will get built on more and more, particularly with national health insurance likely to go in within the next year - will force computerization of the clinical side of the hospital.”The digital computer became available for general use in the late 1950s. These first systems provided few user-oriented features and required considerable knowledge and skill to use. Early systems were batch oriented and supported single tasking only. These computers were large, required specially prepared spaces, and were quite expensive. In addition to machine language, followed by assembly language, only Fortran and Cobol were available as higher level languages. Most programs were written by computer specialists who had only limited interaction with those who would ultimately use the systems. The reliability of early systems left much to be desired. Hardware failures were the norm rather than the exception. Software crashes were commonplace. Perhaps life with these early systems was best described as “working with a machine you couldn't touch; working with a machine that didn't work; working with a machine that you couldn't afford; and working with systems that were not useful.”I shared office space with two cardiology fellows who seemed to spend most of their day making meticulous measurements of amplitudes and time durations of the various waveforms of the ECG. After recording these carefully on paper, they applied a set of rules to interpret the ECG readings. This task seemed to me to be a simple engineering problem which could be solved almost trivially by a computer. Unfortunately there were the problems of noise, wandering baselines, arrhythmias and PVC's, variations in patterns and other factors to solve to produce the same result as the human. Researchers quickly learned that it was difficult to teach the computer to recognize patterns which were easily identified by humans [3, 4, 5].Gordon [6] points out difficulties of attempting to overlay the computer's orderly, pedantic and, indeed, binary world with the softness, variability and “between the lines implications” of medical data under human direction - a point that is still valid. He notes that the adoption of computer technology in practice must be concerned with the customs of 200,000 physicians serving independently or in 7,000 hospitals and clinics. Changes from manual documentation to automated procedures are often bewildering and ineffective.The early development of patient management systems was supported primarily by NIH grants. Since 1968, the National Center for Health Services Research has played a major role in supporting the development, application and evaluation of patient management systems [7]. No hospital could afford a computer. Since the funding came from external sources, developers often did what they wanted to do and how they wanted to do it, rather than interfacing with users who wanted to have nothing to do with the system in the first place.Developers were consistent in their reasons for developing patient care systems. Almost all papers or proposals started with a line, “We are currently in the midst of a health-care crisis. The average cost of a hospital bed has tripled since 1957.” Systems were proposed to reduce the costs of patient care, to reduce length of stay, to improve patient care, to improve nursing care, to improve communication, and to improve decision making. Little evaluation was done. For the most part, we did what we knew how to do and wrote research papers to justify it.Melville H. Hodge sets the stage for this period in the Preface of his book Medical Information Systems [8]. He states that, in the early 1960s, a small group of hospitals became identified with one common goal, that of a commitment to serve as a site for the development of computerized handling of patient information. Some of these early hospitals include Akron Childrens' Hospital in Ohio; El Camino in Mountain View, California; Baptist in Beaumont, Texas; St. Francis in Peoria, Illinois; Charlotte Memorial in North Carolina; Washington Veteran's Administration Hospital; Henry Ford Hospital, Detroit, Michigan; Monmouth Medical Center, Long Branch, N.J.; Mary's Help Hospital, Daly City, California; Deaconess Hospital, Livingston, Indiana; Latter Day Saints Hospital, Salt Lake City, Utah; and Downstate Medical Center, New York City, New York. We owe a debt of gratitude to these early pioneers, and I might say suffering sites.Most major computer companies, such as IBM, Burroughs, Control Data, Honeywell and NCR, seeing the potential of significant sales, were active in their support. Industries experienced in using computers to manage complex systems joined in. Some of these companies include Lockheed, who supported the early development of the Technicon Hospital Information System; McDonnell-Douglas, who is still active in the field; and other companies, such as GE, who later abandoned these efforts. Most of these systems were well reported in the literature (See, for example (9,10]).Many groups in Europe were developing systems at the same time: the Danderyd Hospital [11] and Karolinska Hospital [12] in Sweden; London Hospital [13] and Kings Hospital [14] in England; and the Hanover Hospital [15] in Germany to mention a few.Unfortunately, most of these early systems resulted in resounding failures. The reason primarily for these failures and for the slow progress into the 1970s was largely due to underestimating the complexity of the information requirements of patient management systems. Furthermore, users, as contrasted to developers, were not involved at an adequate level and, in fact, were not ready for computers. Hardware and software tools were inadequate. Hospitals felt that they had been oversold an unattainable product, and, at the loss of millions of dollars, abandoned their efforts in computerization. As Hodge notes, optimism and enthusiasm was replaced by skepticism and then cynicism.Fortunately others persisted. As technology advanced, driven by the space efforts of the '60s, developers learned to appreciate the complexity of the problem and began to address smaller, more easily defined components of the overall system. A few successes appeared, although some projects failed in the transition from carefully nurtured demonstration projects into systems which interfaced with, usually, the least paid, least motivated, and least educated employees of the medical support staff.By the early 1970s, however, some of these early systems, after years of development and many more development dollars than anyone anticipated, became commercially available [16,17]. After a period of overpromise and underachievement, some progress could be noted [18].The Technicon system, begun by Lockheed in the 1960s, was installed at the El Camino Hospital in Mountain View, California and became, perhaps, the best known “successful” application. The “success” of this system in its early years at El Camino can perhaps be measured by an article in the October 1973 issue of DATAMATION [19]. El Camino was truly a guinea pig in the development of the hospital information system and suffered through the many bugs. During the first year of installation, more than 2000 changes were made to the system, many of these major changes which affected the appearance of things such as reports. Each passing day saw improvement in the attitude of doctors and nurses. In mid-1972, 66% of the doctors opposed the system. By the beginning of 1973, the majority of doctors, except for internists, favored the system. The El Camino system is perhaps one of the most thoroughly evaluated systems of any of the early development systems [20, 21]. The results of this evaluation did encourage further development in patient management systems.The ultimate success of the system at El Camino led to the spread of this and other systems into other hospitals.New crises were encountered as reduced funding from the federal government forced hospitals to decide if computerization was worth the cost and then to find the money to do it. Some hospitals were forced to abandon systems even though the systems finally looked promising.Patient management systems tend to be primarily an automation of manual processes. In 1969, Feinstein [22] noted that while computers had been applied effectively in situations where a standard mechanism already exists for dealing with the data, computers had not yet had an important impact on the more inherently clinical features of medical strategy and tactics. Many of the points made in this article are still valid criticisms of patient management systems. Schwartz [23] makes a similar point. He states that “few systems have fully explored the possibility that the computer as an intellectual tool can reshape the present system of health care, fundamentally alter the role of the physician, and profoundly change the nature of medical manpower recruitment and medical education - in short, the possibility that the health-care system by the year 2000 will be basically different from what it is today.” We clearly have some distance to go.The development of many of the components of a patient management system was driven in the late 1960s and early 1970s by interest in automated multiphasic health testing. The work of Dr. Morris Collen and his colleagues at the Kaiser-Permanente Medical Group in California [24,25] contributed to both a high level of interest in this field and in the progress of automation of tests, data collection and analysis. Dr. Collen stressed the need for AMHT systems to provide high quality testing, to provide good service to doctors and patients, and to be economical. In the early 1970s, only the first of these conditions had been met. The same could be said about other components of patient management systems.Barnett, in an article [26] in The New England Journal of Medicine, again argued the cause for computer applications in areas of medical care. He identified seven major areas in patient management systems which had made progress in development. Caceres [27] similarly reviewed the state of the art and stressed that the physician and patient care data must interact via the computer to realize automated patient management system goals.Patient management systems, to be effective, do need to become a part of the physician/patient interface. Early systems were designed partly by the scientist, partly from the business world, and very little by the practicing physician. Systems designed in our computer laboratories often had major flaws which were obvious when we introduced them into the real world. Intelligent use of computers requires an understanding of the things computers do well: quantified information, well-defined vocabulary, great speed, repetition, accuracy, and versatile control. Humans, on the other hand, communicate by speech, vision, and touch, and have an unlimited vocabulary and great adaptability. It is when the computer is applied in areas of human incompetence, that previously impossible results can be achieved [28]. Too few systems take advantage of this fact. Often we fail to realize that the computer is no substitute for intelligence. It is not a magic box which can make gold from straw.One early experience at Duke is typical of the early days. For over two years, Duke had been involved with IBM in the development of a system called Clinical Decision Support Systems (CDSS). Duke had sent several MDs to work with IBM to develop a system in which the doctor would sit down with a computer terminal, describe the patient's history, physical findings, and laboratory data, and the computer would return the diagnosis and recommend a treatment. A remote system was set up at Duke, and the system was to be demonstrated to the faculty and house staff. Before the grand opening, a few doctors sat down and entered data on patient with some “easy” problems, such as influenza or pneumonia. After an hour of conversation with the computer, the computer was no closer to a conclusion than it was at the beginning. It seems that the computer did not know of the more common diseases since they were not well defined in the literature. The decision was made not to demonstrate or implement the system.Instead, Duke then decided to develop a smaller subset of the system - the automation of the initial or screening medical history. A 19-page mark sense form was designed to be completed by the patient, processed by the computer, and be presented to the doctor in narrative form. After three iterations, the form was complete, and actually did an effective job of collecting the initial medical history. Unfortunately, the logistics of processing this form on a large, remotely located main frame computer led to itsfailure. The 19-page history was scanned by a mark sense reader and the results written on a 9-track magnetic tape. The patient's name, address, and free text data was keypunched onto cards, and the tape, cards, and program were submitted for delivery to the Triangle Universities Computation Center (TUCC), located some 12 miles away, for processing. Rarely did the tape, data, and program arrive at TUCC at the same time, and we spent most of our time trying to track down the components and get them together for processing. And when we managed that, the tape, created on one vendor's machine, could not be read on the other vendor's tape unit. The result was the history usually arrived in the doctor's hands a week after the patient had been seen. This problem was ultimately solved with a minicomputer directly interfaced to the scanner which produced the histories immediately.We tried to use what we had learned with the automated histories to develop a computerized medical record for the Division of Obstetrics at Duke. We metwith a group of physicians, argued over what parameters constituted an appropriate data base, and finally compromised by including any parameter any person felt they might use. The result was a 23 page, narrative printout for a new OB workup. Obviously, this computer program was not reducing the paper work nor helping the doctor. A quick redesign with the assistance of only one physician reduced the output to an acceptable amount; in fact, the essence of the output was reduced to approximately ten lines on the first page in a starred box. We learned an important lesson - the difference between “what I might want and what I need”.Technology produced the minicomputer in the mid-60s and removed some of the problems associated with the mainframes. The cost of these computers was around $30,000. The first of these was the LINC or Laboratory Instrumentation Computer developed at MIT and distributed to a number of system developers by NIH. This move by NIH was, in my opinion, one of the most significant events in the field of medical informatics, and really led to the development of the minicomputer industry. The LINC permitted an affordable, hands-on, real-time interaction with a computer. The minicomputer moved into the locations in which the projects were developed. The first minis were single user and had to be programmed in assembly language. The University of Washington in St. Louis developed a popular operating system which solved many of the system problems.The minicomputer opened the door for many new development in patient management including clinical laboratory systems, automated ECG systems, and ambulatory care patient record systems. Octo Barnett, at Mass General, led the way with the development of COSTAR and the programming language MUMPS [29].At Duke, we learned of the power of the minicomputer on a borrowed LINC-8 and designed a system in 1967 to createon-line surface maps of cardiac body potentials - a process which had previously been performed on a mainframe at a much greater expense of time and money. A group of us then became interested in developing a computerized medical record. Our newly-acquired Digital Equipment Corporation PDP-12 was a dream. It had a 4K memory of 12-bit words, a CRT screen which had to be refreshed under program control, two 135 kbyte DEC minitapes, 12 binary control switches, 6 A-to-D channels, and 6 potentiometers A-to-D inputs. Our first system was the Obstetrical Medical Record in which detailed data was retained during the pregnancy of some 1500 women who subsequently delivered at the Duke Medical Center. One tape would contain the records of approximately one month's pregnancies. Near the end of each month, someone was on call to change the tapes as the women came to Duke for delivery. The output was in upper case only on a teletype located just outside the delivery suite. One lesson we learned was that MDs did place value on the ability of a system to deliver information reliably as it was needed.The programs were written originally in assembly language and used the LAP-6 operating system. These assembly language programs were later converted into a programming language called GEMISCH which we use today.The PDP 12 gave way to a PDP 11/20 in the early '70s. The addition of a movable head, 1.2 Mbyte hard disk seemed to offer more storage than we could ever need. This minicomputer had 28 Kwords of 16-bit memory. We wrote a multiuser operating system which supported 7 simultaneous users using a round-robin swapping algorithm.User acceptance of computers played a major role in the development of patient management systems. The success of any innovation in a medical setting depends upon the attitude of the physicians involved. Surveys [30] indicated that physicians were reluctant to touch the keyboard of a CRT. They were doctors and “not typists”. Systems designed and introduced by physicians were more apt to be accepted than one designed by a non-MD.At Duke, we conducted one experiment which demonstrates this attitude. We asked a number of primary care physicians to look at a computer-generated medical history and a hand-written, human-generated history. The physicians overwhelmingly selected the hand-written form. We then reversed the process, taking the computer-generated medical history and coping it by hand, reformatting it slightly. We then took a human-generated history, typed it into the computer, and printed it on a drum printer so that it was obviously computer-generated. We showed these two histories to a number of physicians and again they overwhelmingly selected the hand-written form.Many worried, and perhaps justly, that computers would be over-accepted, andthe computer's “word” would become truth. In an editorial in JAMA [31], M. Southgate compares today's physician with the medicine man of a primitive tribe who consults his spirits for knowledge. To the modern physician, the computer becomes the powerful and all knowing spirit.Patients had little problem in accepting the computer as part of their health care delivery team [32]. Our own experience with using the PDP-12, certainly a rather imposing creature to a unenlightened patient, for collecting headache histories suggested that patients were less intimidated by the computer than the doctor. The adventuresome spirit of our patients was best illustrated by one incident involving a 67 year old lady. While answering questions about her headache, she would occasionally laugh. Not thinking our displays were humorous, we finally asked her what was funny. She replied that she was just waiting until the man hidden in the “computer box” would step out and greet her.The developers of patient management systems were committed to the task. Typical of that attitude is Mel Hodge: “I am a believer. I happen to believe that the problems of health care delivery are susceptible to well-considered, well-executed approaches and that the introduction of information systems technology is among the more powerful approaches available. I have invested more than a decade to my life in this belief [8].” Many of us can now say we have invested a career to this belief.Both of our speakers in this patient management systems section have contributed significantly to the development of this field. Both have been involved from the early years. Melville Hodge headed the development team which was responsible for the Technicon Medical Information System. This system was the first successful HIS which was subsequently implemented in a number of institutions and is today still a leader in the field of patient management systems.Homer Warner, with his colleagues at the Latter Day Saints (LDS) Hospital in Salt Lake City, Utah, developed a number of subsystems over this period which constitute a patient management system called HELP.The HELP system had its beginning in the late 1950s when Dr. Warner and colleagues began exploring the use of computers in the diagnosis of congenital heart disease [33]. The HELP system grew out of a group of subsystems which were designed to directly help the doctor or the nurse with specific data as relates to recognizing and dealing with specific events in a patient's illness [34]. These efforts included the goal of using the computer to enhance the decision making process [35] in the medical arena. Dr. Warner and colleagues dealt early with specific data collection, management [36], and analysis in such areas as the clinical laboratory, patient monitoring [37], and electrocardiographic interpretation by computer [38]. In the early 1970s, theseareas were integrated to use a common database. Warner describes the HELP system in a recent book [39].The Technicon system, and the contributions of Hodge, is important because it was one on the first systems which worked and was accepted. This system primarily dealt with the service-related components of a patient management system - order entry and result reporting. Contributions were made in what was done and how it was done, even though other systems did not necessarily follow exactly the same patterns. The Technicon system represents one milestone in the development of patient management systems.Warner and his group, through years of development, have added and important and necessary component of clinical involvement. By early-on collecting data, Warner and his group were able to develop their own probabilities for diseases and their relationship to signs, symptoms, and findings. Most impressive is that the HELP system is still evolving at even now represents a state of the art approach to automated patient management.These early years of development had to occur. I am always impressed that, as we became smart enough to recognize what we should do next, technology was always just available to enable us to do it. We are now entering a stage in which the tools seem to be adequate, the users seem to be receptive, the results justify the costs, and the applications seem to be useful. Perhaps we have now arrived at the point in which computerized patient management systems can change the way we teach physicians, the way we practice medicine, and the way we do medical research.",1987,2022-09-02T13:29:39Z,2022-09-02T13:29:39Z,NA,153–164,NA,NA,NA,NA,NA,NA,HMI '87,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Bethesda, Maryland, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,KWAS9LEZ,conferencePaper,2011,"Zhang, Kehuan; Zhou, Xiaoyong; Chen, Yangyi; Wang, XiaoFeng; Ruan, Yaoping",Sedic: Privacy-Aware Data Intensive Computing on Hybrid Clouds,Proceedings of the 18th ACM Conference on Computer and Communications Security,978-1-4503-0948-6,NA,10.1145/2046707.2046767,https://doi.org/10.1145/2046707.2046767,"The emergence of cost-effective cloud services offers organizations great opportunity to reduce their cost and increase productivity. This development, however, is hampered by privacy concerns: a significant amount of organizational computing workload at least partially involves sensitive data and therefore cannot be directly outsourced to the public cloud. The scale of these computing tasks also renders existing secure outsourcing techniques less applicable. A natural solution is to split a task, keeping the computation on the private data within an organization's private cloud while moving the rest to the public commercial cloud. However, this hybrid cloud computing is not supported by today's data-intensive computing frameworks, MapReduce in particular, which forces the users to manually split their computing tasks. In this paper, we present a suite of new techniques that make such privacy-aware data-intensive computing possible. Our system, called Sedic, leverages the special features of MapReduce to automatically partition a computing job according to the security levels of the data it works on, and arrange the computation across a hybrid cloud. Specifically, we modified MapReduce's distributed file system to strategically replicate data, moving sanitized data blocks to the public cloud. Over this data placement, map tasks are carefully scheduled to outsource as much workload to the public cloud as possible, given sensitive data always stay on the private cloud. To minimize inter-cloud communication, our approach also automatically analyzes and transforms the reduction structure of a submitted job to aggregate the map outcomes within the public cloud before sending the result back to the private cloud for the final reduction. This also allows the users to interact with our system in the same way they work with MapReduce, and directly run their legacy code in our framework. We implemented Sedic on Hadoop and evaluated it using both real and synthesized computing jobs on a large-scale cloud test-bed. The study shows that our techniques effectively protect sensitive user data, offload a large amount of computation to the public cloud and also fully preserve the scalability of MapReduce.",2011,2022-09-02T13:29:39Z,2022-09-02T13:29:39Z,NA,515–526,NA,NA,NA,NA,NA,NA,CCS '11,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Chicago, Illinois, USA",NA,NA,NA,automatic program analysis; cloud security; computation split; data privacy; mapreduce,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,UJVWXBRA,conferencePaper,2022,"Liu, Jie; Deng, Ya; Kaabar, Mohammed K. A",Speed Correction of Electrical Imaging Logging Based on Fuzzy Logic,"2021 4th International Conference on E-Business, Information Management and Computer Science",978-1-4503-9568-7,NA,10.1145/3511716.3511726,https://doi.org/10.1145/3511716.3511726,"Depth’ is taken to be the ‘cable depth’ by logging system that is collected at regular depth intervals. Due to the distortion of log measurement caused by cable stretch, irregular motion, and imaging logging tool sticking, serious distortion of logging image occurs, which affects the preparation and acquisition of geological information. Therefore, speed correction is needed to restore the ‘true depth’ of downhole instrument sampling data. In this paper, the motion state of the imaging logging tool is analyzed. Firstly, the Kalman filter model is constructed, and the noise variance of the Kalman filter is corrected in real-time by using a fuzzy logic controller and ‘tool sticking’ identification results, to improve the output accuracy of the system. Through the analysis of logging data, it is found that the method can eliminate the phenomenon of image compression and stretching caused by tool stuck, and restore the subtle characteristics of the formation such as fractures, pores, and bedding, which proves the effectiveness of the technology.",2022,2022-09-02T13:29:39Z,2022-09-02T13:29:39Z,NA,62–67,NA,NA,NA,NA,NA,NA,EBIMCS 2021,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Hong Kong, China",NA,NA,NA,Fuzzy Logic; alman Filter; lectrical Imaging; peed Correction,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,9BUFDCPG,conferencePaper,1989,"Phillips, D.; Pique, M.; Moler, C.; Torborg, J.; Greenberg, D.",Distributed Graphics: Where to Draw the Lines?,ACM SIGGRAPH 89 Panel Proceedings,0-89791-353-1,NA,10.1145/77276.77291,https://doi.org/10.1145/77276.77291,"Good morning, ladies and gentlemen. Welcome to the panel entitled Distributed Graphics: Where to Draw the Lines?My name is Dick Phillips. I'm from Los Alamos National Laboratory and I'll be your chair this session. I'll be joined by a great group of panelists — friends and colleagues all.Our second speaker following me will be Michael Pique from Scripps Clinic. Following him will be Cleve Moler from Ardent Computer. After Cleve we'll hear from Jay Torborg who is associated with Alliant Computer. And batting in the clean-up position is going to be Don Greenberg from Cornell University.I have to give you one administrative announcement. You probably know this by now if you've been attending panel sessions all week. But once again, these proceedings are being audio taped for subsequent transcription and publication. That means that when we open up the session for question and answer, which will be in another 30 or 40 minutes, if you would like to ask a question, you must come to one of the microphones that's situated in the aisles. They are just about in every aisle, part way back and close to the front. And to be recognized, please state your name and affiliation, and I'll remind you of that when we get into the question and answer session.The title of our panel begs a question — where to draw the lines. Well, the trivial answer to that question is obviously on the display that you have available. The real implication of that title was where to draw the lines of demarcation for graphics processing. You're going to hear from me and from my other panelists several different points of view. Just when you thought everything was settling down and it was clear that all graphics processing was moving out to workstations or graphic supercomputers, you're going to hear at least two different points of view that may sound a bit nostalgic.Let me take you back in time just a bit, and this is a greatly oversimplified graphics time line — where we have been and where we are and where we're going in the evolution of visualization capability.I'm not going to dwell too much on the part of this time line to the left. We're really interested in what's up at the right hand side. But I can't resist pointing out that back in the days which I have labeled pre-history here, a lot of us can remember getting excited about seeing output in the form of a printer plot, thinking that we were doing visualization and that that was really computer graphics. And I for one can remember the first time I had 300 band available to me on a storage tube terminal and I thought this is blazing speed. I cannot believe what kind of graphics capability I have got now.Where things really get interesting though, if you move along that time line to the right, up into the mid 1980s, I have put some I think seminal events on there — Silicon Graphics introducing the geometry engine in the workstation. Well, workstations in general. That was a real watershed event that has changed the way that we do graphics and where we do graphics considerably.Then as we move into the later part of the 1980s, I have noted the appearance of graphics accelerators for workstations. These are specialized plug-in boards that have all of the graphics features like Phong shading and high speed transformations built into them. Graphic supercomputers like Ardent and Stellar and HP/Apollo have appeared in that time frame. Then we look a little bit further into the '90s and I have indicated the occurrence of very high speed networks is going to have a profound effect on the way we do graphics display and how we distribute the activities that are associated with it.Let me give a very oversimplified couple of statements on what gave rise to the need for specialized graphics hardware — the accelerators that I talked about and indeed the graphic supercomputers. As I've said, to terribly oversimplify, it was certainly the need for real time transformations and rendering. All of the advances in computer graphics over the last 10 or 15 years, many of them we can now find built into the hardware of the workstations and graphic supercomputers that we have available to us.One of the other reasons for wanting to bring all of that high speed computational capability right to the desktop, as it is, was to compensate for the lamentably low communication bandwidths which we had then — which we have now, as a matter of fact. And I'm even including Ethernet and I'll be bold enough to say that the FDDI, which is not really upon us, is also in that lamentably slow category for many of the kinds of things we'd like to do.It turns out — in my view, at least — that that specialized hardware, wonderful as it is for many, many applications, and make no mistake, it has revolutionized the way that we can do interactive graphics — it's not useful for all applications.One application that I've listed as a first bullet is one where we're doing specialized rendering — research rendering let's call it. Not everything we wanted — not all the research in rendering has been done — right? So Gouraud shading and Phong shading and so on is not the be-all end-all necessarily. There's a lot of interesting work being done. It has been reported at this conference, as a matter of fact.That is really a small reason for wanting to do the graphics computing on yet another system. But the next one that I've listed is a very compelling reason in many installations, particularly where large scale heavy-duty simulations are being done. I've mentioned that I'm from Los Alamos and that's certainly one center where there are computations that are done on supercomputers and that need to be visualized, and because of the nature of the computations all of the specialized hardware in accelerator boards and in graphic supercomputers is not necessarily useful. Indeed, I'll argue that in many cases it's of no value whatsoever.The last point I want to make here — before I show you a couple of specific slides of these simulations that I'm referring to — is that what will happen is that the emergence of very high speed networks — both local networks and international and national networks — is going to provide a way for these large scale simulations to take advantage of graphics hardware that does not necessarily have the specialized capabilities we just talked about.At Los Alamos a group of folks in our network engineering department have taken the lead in defining what is called the High Speed Channel specification. Before I get to that, let me just give you an idea of the kinds of computations that are being done at Los Alamos — and I know at many other places — that simply can't take advantage of the specialized hardware that I've just been referring to. This happens to be the mesh that's associated with a finite difference computation for some simulation. It doesn't really matter what it is, but I just wanted to show you that we're talking typically tens of thousands of individual mesh points, and I can guarantee you this is a fairly sparse mesh compared to the kinds of things that most of our users encounter.The point in showing you this is that as the simulation evolves in time, there is a different version of this mesh for every single time step. The scientists who are doing the simulation would like to be able — either after the fact or perhaps if the timing is appropriate — to steer the computations that are going on by being able to visualize the evolution in time of meshes like this. And they need to be sent to some display device. And ideally you'd like to do that at the rate of 24 frames per second, but we can go through some computations and find that's simply not feasible with the kind of network bandwidths that are available today.The specialized hardware that I've just been talking about gives us no help at all here, because what I need to be able to do is to send one instance of this mesh to the display device for every time step, as I mentioned a moment ago.In addition, the scientists at Los Alamos and other places would like to be able to have the counterpart of a numerical laboratory. This is completely synthesized, but you can — and many of you may have had experience in the past with visualization techniques and fluid flow, where you can actually see shock waves by various lighting techniques. The intent here is to be able to simulate that situation and be able to show the flow evolving — not necessarily as it's being computed, but perhaps after the fact — but be able to pick out important points by seeing a temporal evolution of that particular simulation.So those are just a couple of examples that have given rise to the development of a high speed channel specification and an accompanying network at Los Alamos, and I wanted to say right now — just so you don't think oh, great, a special purpose solution for a national laboratory that no one else will ever be able to use — not so.Many of you out there I am sure know — and I know several of our panelists are either aware of or working on high speed channel hardware for their particular products. There are about 30 vendors that have signed on to the high speed channel specification.In addition, Digital Equipment Corporation is building the corresponding network, which is called CP*. I'm not going to go into network details here because that's not my point. I really wanted to describe what is now a new highway for data transmission that facilitates my job, which is to help the scientists do the visualization that they need to do.So what we're seeing here is a very simplified view of how this high speed network, which is spec'ed at 800 megabits and a corresponding cross bar switch-style network that is going to allow effective point-to-point connections between the various components of the computing environment — the supercomputers, the data storage devices, and the display devices. And each — unlike with a bus structure — each user will effectively have that complete bandwidth available to him or her.A larger view of that network is shown here and it gives us an idea of how we might interconnect the various devices and again. I don't want to go through the details here, but you notice that we're accommodating FDDI gateways, so that the FDDI LANs can be used easily in this environment, and various workstations. I've shown a Sun workstation there. I described vendors who are signing on to this concept, and Sun is providing a high speed interface to their TAAC board, which can then be put into a Sun workstation, and connected at 800 megabits directly over the network.I mentioned earlier that this is not necessarily limited to just our local area networks. Many of you are probably aware of the work that's going on now to establish these so-called national data highways. The Corporation for National Research Initiatives is coordinating an activity to establish centers throughout the United States that will participate in a test bed of what is to become in the 1990s a four gigabit data highway spanning the United States.So I'd like to leave you with the thought that while we have migrated a lot of the graphics computing capabilities — graphics related computing requirements to workstations and specialized graphic supercomputers — the emergence of extremely high speed data communications makes one rethink these situations — particularly when you are faced with the kinds of computing tasks that I just mentioned that we have for large scale simulations at national laboratories.I'm going to stop my heretical remarks here and I'm going to turn it over to the panel to describe several different points of view.As I mentioned earlier, the next speaker will be Michael Pique from Scripps Clinic and Research Foundation. Michael? Thank you.",1989,2022-09-02T13:29:39Z,2022-09-02T13:29:39Z,NA,257–280,NA,NA,NA,NA,NA,NA,SIGGRAPH '89,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Boston, Massachusetts, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,3QM29UXS,journalArticle,1989,"Phillips, D.; Pique, M.; Moler, C.; Torborg, J.; Greenberg, D.",Distributed Graphics: Where to Draw the Lines?,SIGGRAPH Comput. Graph.,NA,0097-8930,10.1145/77277.77291,https://doi.org/10.1145/77277.77291,"Good morning, ladies and gentlemen. Welcome to the panel entitled Distributed Graphics: Where to Draw the Lines?My name is Dick Phillips. I'm from Los Alamos National Laboratory and I'll be your chair this session. I'll be joined by a great group of panelists — friends and colleagues all.Our second speaker following me will be Michael Pique from Scripps Clinic. Following him will be Cleve Moler from Ardent Computer. After Cleve we'll hear from Jay Torborg who is associated with Alliant Computer. And batting in the clean-up position is going to be Don Greenberg from Cornell University.I have to give you one administrative announcement. You probably know this by now if you've been attending panel sessions all week. But once again, these proceedings are being audio taped for subsequent transcription and publication. That means that when we open up the session for question and answer, which will be in another 30 or 40 minutes, if you would like to ask a question, you must come to one of the microphones that's situated in the aisles. They are just about in every aisle, part way back and close to the front. And to be recognized, please state your name and affiliation, and I'll remind you of that when we get into the question and answer session.The title of our panel begs a question — where to draw the lines. Well, the trivial answer to that question is obviously on the display that you have available. The real implication of that title was where to draw the lines of demarcation for graphics processing. You're going to hear from me and from my other panelists several different points of view. Just when you thought everything was settling down and it was clear that all graphics processing was moving out to workstations or graphic supercomputers, you're going to hear at least two different points of view that may sound a bit nostalgic.Let me take you back in time just a bit, and this is a greatly oversimplified graphics time line — where we have been and where we are and where we're going in the evolution of visualization capability.I'm not going to dwell too much on the part of this time line to the left. We're really interested in what's up at the right hand side. But I can't resist pointing out that back in the days which I have labeled pre-history here, a lot of us can remember getting excited about seeing output in the form of a printer plot, thinking that we were doing visualization and that that was really computer graphics. And I for one can remember the first time I had 300 band available to me on a storage tube terminal and I thought this is blazing speed. I cannot believe what kind of graphics capability I have got now.Where things really get interesting though, if you move along that time line to the right, up into the mid 1980s, I have put some I think seminal events on there — Silicon Graphics introducing the geometry engine in the workstation. Well, workstations in general. That was a real watershed event that has changed the way that we do graphics and where we do graphics considerably.Then as we move into the later part of the 1980s, I have noted the appearance of graphics accelerators for workstations. These are specialized plug-in boards that have all of the graphics features like Phong shading and high speed transformations built into them. Graphic supercomputers like Ardent and Stellar and HP/Apollo have appeared in that time frame. Then we look a little bit further into the '90s and I have indicated the occurrence of very high speed networks is going to have a profound effect on the way we do graphics display and how we distribute the activities that are associated with it.Let me give a very oversimplified couple of statements on what gave rise to the need for specialized graphics hardware — the accelerators that I talked about and indeed the graphic supercomputers. As I've said, to terribly oversimplify, it was certainly the need for real time transformations and rendering. All of the advances in computer graphics over the last 10 or 15 years, many of them we can now find built into the hardware of the workstations and graphic supercomputers that we have available to us.One of the other reasons for wanting to bring all of that high speed computational capability right to the desktop, as it is, was to compensate for the lamentably low communication bandwidths which we had then — which we have now, as a matter of fact. And I'm even including Ethernet and I'll be bold enough to say that the FDDI, which is not really upon us, is also in that lamentably slow category for many of the kinds of things we'd like to do.It turns out — in my view, at least — that that specialized hardware, wonderful as it is for many, many applications, and make no mistake, it has revolutionized the way that we can do interactive graphics — it's not useful for all applications.One application that I've listed as a first bullet is one where we're doing specialized rendering — research rendering let's call it. Not everything we wanted — not all the research in rendering has been done — right? So Gouraud shading and Phong shading and so on is not the be-all end-all necessarily. There's a lot of interesting work being done. It has been reported at this conference, as a matter of fact.That is really a small reason for wanting to do the graphics computing on yet another system. But the next one that I've listed is a very compelling reason in many installations, particularly where large scale heavy-duty simulations are being done. I've mentioned that I'm from Los Alamos and that's certainly one center where there are computations that are done on supercomputers and that need to be visualized, and because of the nature of the computations all of the specialized hardware in accelerator boards and in graphic supercomputers is not necessarily useful. Indeed, I'll argue that in many cases it's of no value whatsoever.The last point I want to make here — before I show you a couple of specific slides of these simulations that I'm referring to — is that what will happen is that the emergence of very high speed networks — both local networks and international and national networks — is going to provide a way for these large scale simulations to take advantage of graphics hardware that does not necessarily have the specialized capabilities we just talked about.At Los Alamos a group of folks in our network engineering department have taken the lead in defining what is called the High Speed Channel specification. Before I get to that, let me just give you an idea of the kinds of computations that are being done at Los Alamos — and I know at many other places — that simply can't take advantage of the specialized hardware that I've just been referring to. This happens to be the mesh that's associated with a finite difference computation for some simulation. It doesn't really matter what it is, but I just wanted to show you that we're talking typically tens of thousands of individual mesh points, and I can guarantee you this is a fairly sparse mesh compared to the kinds of things that most of our users encounter.The point in showing you this is that as the simulation evolves in time, there is a different version of this mesh for every single time step. The scientists who are doing the simulation would like to be able — either after the fact or perhaps if the timing is appropriate — to steer the computations that are going on by being able to visualize the evolution in time of meshes like this. And they need to be sent to some display device. And ideally you'd like to do that at the rate of 24 frames per second, but we can go through some computations and find that's simply not feasible with the kind of network bandwidths that are available today.The specialized hardware that I've just been talking about gives us no help at all here, because what I need to be able to do is to send one instance of this mesh to the display device for every time step, as I mentioned a moment ago.In addition, the scientists at Los Alamos and other places would like to be able to have the counterpart of a numerical laboratory. This is completely synthesized, but you can — and many of you may have had experience in the past with visualization techniques and fluid flow, where you can actually see shock waves by various lighting techniques. The intent here is to be able to simulate that situation and be able to show the flow evolving — not necessarily as it's being computed, but perhaps after the fact — but be able to pick out important points by seeing a temporal evolution of that particular simulation.So those are just a couple of examples that have given rise to the development of a high speed channel specification and an accompanying network at Los Alamos, and I wanted to say right now — just so you don't think oh, great, a special purpose solution for a national laboratory that no one else will ever be able to use — not so.Many of you out there I am sure know — and I know several of our panelists are either aware of or working on high speed channel hardware for their particular products. There are about 30 vendors that have signed on to the high speed channel specification.In addition, Digital Equipment Corporation is building the corresponding network, which is called CP*. I'm not going to go into network details here because that's not my point. I really wanted to describe what is now a new highway for data transmission that facilitates my job, which is to help the scientists do the visualization that they need to do.So what we're seeing here is a very simplified view of how this high speed network, which is spec'ed at 800 megabits and a corresponding cross bar switch-style network that is going to allow effective point-to-point connections between the various components of the computing environment — the supercomputers, the data storage devices, and the display devices. And each — unlike with a bus structure — each user will effectively have that complete bandwidth available to him or her.A larger view of that network is shown here and it gives us an idea of how we might interconnect the various devices and again. I don't want to go through the details here, but you notice that we're accommodating FDDI gateways, so that the FDDI LANs can be used easily in this environment, and various workstations. I've shown a Sun workstation there. I described vendors who are signing on to this concept, and Sun is providing a high speed interface to their TAAC board, which can then be put into a Sun workstation, and connected at 800 megabits directly over the network.I mentioned earlier that this is not necessarily limited to just our local area networks. Many of you are probably aware of the work that's going on now to establish these so-called national data highways. The Corporation for National Research Initiatives is coordinating an activity to establish centers throughout the United States that will participate in a test bed of what is to become in the 1990s a four gigabit data highway spanning the United States.So I'd like to leave you with the thought that while we have migrated a lot of the graphics computing capabilities — graphics related computing requirements to workstations and specialized graphic supercomputers — the emergence of extremely high speed data communications makes one rethink these situations — particularly when you are faced with the kinds of computing tasks that I just mentioned that we have for large scale simulations at national laboratories.I'm going to stop my heretical remarks here and I'm going to turn it over to the panel to describe several different points of view.As I mentioned earlier, the next speaker will be Michael Pique from Scripps Clinic and Research Foundation. Michael? Thank you.",1989-07,2022-09-02T13:29:39Z,2022-09-02T13:29:39Z,NA,257–280,NA,5,23,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,MF2LGKXL,conferencePaper,2013,"King, Christopher H.",The Path to Google: Selling Ice to Eskimos,Proceedings of the 41st Annual ACM SIGUCCS Conference on User Services,978-1-4503-2318-5,NA,10.1145/2504776.2504778,https://doi.org/10.1145/2504776.2504778,"Higher education conferences over the past few years have been full of presentations, papers and panels on the processes involved in migrating a campus and its people to Google Apps for Education. While it is useful to hear about marketing tchotchkes, data validation, and the pros and cons of web clients, what seems to get ignored is the process that led to the decision to move to Google Apps in the first place. At North Carolina State University, where students were already using Google Apps, the decision to move employees involved almost as much time, effort and heartache as the technical migration. As the users saw it, they had a working system, even if that system only worked because of huge expenditures of time and money both on the backend server maintenance and the client need to implement terribly complex workarounds for simple functionality. The end result: a 94-page white paper and the realization that it's hard to sell ice to Eskimos , even if you show them that their ice has already melted. This paper and presentation will discuss the information gathering and needs assessment done by NC State prior to the decision to move employees to Google Apps, and the successes and difficulties involved.",2013,2022-09-02T13:29:39Z,2022-09-02T13:29:39Z,NA,185–188,NA,NA,NA,NA,NA,NA,SIGUCCS '13,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Chicago, Illinois, USA",NA,NA,NA,cooperation; implementation; Google; calendaring; cat herding; email,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,J5E9K5FR,conferencePaper,2011,"Serteyn, Aline; Lin, Xintan; Amft, Oliver",Reducing Motion Artifacts for Robust QRS Detection in Capacitive Sensor Arrays,Proceedings of the 4th International Symposium on Applied Sciences in Biomedical and Communication Technologies,978-1-4503-0913-4,NA,10.1145/2093698.2093747,https://doi.org/10.1145/2093698.2093747,"Non-contact capacitive ECG measurements (cECG) have applications in various unobtrusive and ubiquitous systems. However, cECG signals are frequently corrupted by interference and motion artifacts. In this work array processing methods, such as blind source separation, were used to reduce the impact of motion artifacts on QRS detection. The capacitive sensor array was integrated in a bed mattress and covered with two insulating sheets. The array processing methods were compared in terms of their QRS detection error rates (De). Results of our study with five healthy subjects in different recording conditions showed that, when using array processing methods, QRS detection performance during body motion can be substantially improved (De reduced from 0.46 on raw sensor data to 0.06 for a channel difference method). We concluded that array processing is a promising approach to achieve motion-resistant QRS detection and thus suggest wider use of capacitive sensor arrays.",2011,2022-09-02T13:29:39Z,2022-09-02T13:29:39Z,NA,NA,NA,NA,NA,NA,NA,NA,ISABEL '11,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Barcelona, Spain",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,HTELLTEN,conferencePaper,2011,"Rabl, Tilmann; Stegmaier, Florian; Döller, Mario; Vang, The Thong",A Protocol for Disaster Data Evacuation,Proceedings of the ACM SIGCOMM 2011 Conference,978-1-4503-0797-0,NA,10.1145/2018436.2018514,https://doi.org/10.1145/2018436.2018514,"Data is the basis of the modern information society. However, recent natural catastrophes have shown that it is not possible to definitively secure a data storage location. Even if the storage location is not destroyed itself the access may quickly become impossible, due to the breakdown of connections or power supply. However, this rarely happens without any warning. While floods have hours or days of warning time, tsunamis usually leave only minutes for reaction and for earthquakes there are only seconds. In such situations, timely evacuation of important data is the key challenge. Consequently, the focus lies on minimizing the time to move away all data from the storage location whereas the actual time to arrival remains less (but still) important. This demonstration presents the dynamic fast send protocol (DFSP), a new bulk data transfer protocol. It employs striping to dynamic intermediate nodes in order to minimize sending time and to utilize the sender's resources to a high extent.",2011,2022-09-02T13:29:39Z,2022-09-02T13:29:39Z,NA,448–449,NA,NA,NA,NA,NA,NA,SIGCOMM '11,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Toronto, Ontario, Canada",NA,NA,NA,data evacuation; dfsp; dynamic fast send protocol; fsp,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,6YG5EYH4,journalArticle,2011,"Rabl, Tilmann; Stegmaier, Florian; Döller, Mario; Vang, The Thong",A Protocol for Disaster Data Evacuation,SIGCOMM Comput. Commun. Rev.,NA,0146-4833,10.1145/2043164.2018514,https://doi.org/10.1145/2043164.2018514,"Data is the basis of the modern information society. However, recent natural catastrophes have shown that it is not possible to definitively secure a data storage location. Even if the storage location is not destroyed itself the access may quickly become impossible, due to the breakdown of connections or power supply. However, this rarely happens without any warning. While floods have hours or days of warning time, tsunamis usually leave only minutes for reaction and for earthquakes there are only seconds. In such situations, timely evacuation of important data is the key challenge. Consequently, the focus lies on minimizing the time to move away all data from the storage location whereas the actual time to arrival remains less (but still) important. This demonstration presents the dynamic fast send protocol (DFSP), a new bulk data transfer protocol. It employs striping to dynamic intermediate nodes in order to minimize sending time and to utilize the sender's resources to a high extent.",2011-08,2022-09-02T13:29:39Z,2022-09-02T13:29:39Z,NA,448–449,NA,4,41,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,data evacuation; dfsp; dynamic fast send protocol; fsp,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,TR7DBM3E,conferencePaper,2021,"Paluri, Pavan Kumar; Dai, Guangli; Cheng, Albert Mo Kim",ARINC 653-Inspired Regularity-Based Resource Partitioning on Xen,"Proceedings of the 22nd ACM SIGPLAN/SIGBED International Conference on Languages, Compilers, and Tools for Embedded Systems",978-1-4503-8472-8,NA,10.1145/3461648.3463854,https://doi.org/10.1145/3461648.3463854,"A multitude of cloud-native applications take up a significant share of today's world wide web, the majority of which implicitly require soft-real-time guarantees when hosted on servers at various data centers across the globe. With the rapid development of cloud computing and virtualization techniques, many applications have been moved onto cloud and edge platforms that require efficient virtualization techniques. This means a set of applications must be executed on a Virtual Machine (VM) and multiple VMs must be temporally and spatially scheduled on a set of CPUs. Designed to leverage the cloud infrastructure model, many of these cloud-native applications such as media servers strongly demand low data latency and high compute-resource availability, both of which must be predictable. However, state-of-art VM schedulers fail to satisfy these requirements simultaneously. The scheduling of cloud-native applications on VMs and the scheduling of VMs on physical resources (CPUs), collectively need to be real-time in nature as specified by the Hierarchical Real-Time Scheduling (HiRTS) framework. Conforming to the specifications of this framework, the Regularity-based Resource Partitioning (RRP) model has been proposed that introduces the concept of regularity to provide a near-ideal resource supply to all VMs. In this paper, we make the theoretically superior Regularity-based Resource Partitioning (RRP) model ready for prime time by implementing its associated resource partitioning algorithms for the first time ever on the popular x-86 open-source hypervisor Xen, i.e., RRP-Xen. This paper also compares and contrasts the real-time performance of RRP-Xen against contemporary Xen schedulers such as Credit and RTDS. Our contributions include: (1) a novel implementation of the RRP model on Xen's x-86 based hypervisor, thereby providing a test-bed for future researchers; (2) the first-ever multi-core ARINC 653 VM scheduler prototype on Xen; and (3) numerous experiments and theoretical analysis to determine the real-time performance of RRP-Xen under a stringent workload environment.",2021,2022-09-02T13:29:39Z,2022-09-02T13:29:39Z,NA,134–145,NA,NA,NA,NA,NA,NA,LCTES 2021,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Virtual, Canada",NA,NA,NA,ARINC 653; Operating Systems; Real-Time; Virtualization,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,5R93Y7I5,conferencePaper,2009,"Liu, Yong; Hill, David; Marini, Luigi; Kooper, Rob; Rodriguez, Alejandro; Myers, Jim",Web 2.0 Geospatial Visual Analytics for Improved Urban Flooding Situational Awareness and Assessment,Proceedings of the 17th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,978-1-60558-649-6,NA,10.1145/1653771.1653873,https://doi.org/10.1145/1653771.1653873,"Situational awareness of urban flooding during storm events is important for disaster and emergency management. However, no general purpose tools yet exist for rendering rainfall accumulations in real-time at the resolution of hydrologic units used for modeling. This demonstration will exhibit a novel web 2.0 visual analytical approach for understanding and adaptively managing urban flooding issues. The approach generates a geospatial-temporal map of rainfall within urban hydrologic units (sewer-sheds) in real-time. The polygon-averaged rainfall data is generated using virtual sensors which provide customized real-time data products derived from National Weather Service weather radar data using NCSA's workflow tools. Time-series KML (Keyhole Markup Language) layers are generated, where each KML layer represents a particular slice of the geospatial color-coded sewershed map. Such time-aware KML can be replayed as a movie in the web-based Google Earth environment. This geospatial visual analytic approach can provide decision markers and communities a powerful resource for assessment of neighborhood flooding issues. We will demonstrate our technology using historical and real-time rainfall data in the metropolitan Chicago area to show the effectiveness of such approach. Future work by combining additional ground-truth flooding data will allow us move towards real-time improved decision support for flooding and stormwater management.",2009,2022-09-02T13:29:39Z,2022-09-02T13:29:39Z,NA,554–555,NA,NA,NA,NA,NA,NA,GIS '09,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Seattle, Washington",NA,NA,NA,workflow; animation; geospatial visual analytics; keyhole markup language; NEXRAD; rainfall; virtual sensor; web 2.0,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,24H28RY8,conferencePaper,2009,"Tellex, Stefanie; Roy, Deb",Grounding Spatial Prepositions for Video Search,Proceedings of the 2009 International Conference on Multimodal Interfaces,978-1-60558-772-1,NA,10.1145/1647314.1647369,https://doi.org/10.1145/1647314.1647369,"Spatial language video retrieval is an important real-world problem that forms a test bed for evaluating semantic structures for natural language descriptions of motion on naturalistic data. Video search by natural language query requires that linguistic input be converted into structures that operate on video in order to find clips that match a query. This paper describes a framework for grounding the meaning of spatial prepositions in video. We present a library of features that can be used to automatically classify a video clip based on whether it matches a natural language query. To evaluate these features, we collected a corpus of natural language descriptions about the motion of people in video clips. We characterize the language used in the corpus, and use it to train and test models for the meanings of the spatial prepositions ""to,"" ""across,"" ""through,"" ""out,"" ""along,"" ""towards,"" and ""around."" The classifiers can be used to build a spatial language video retrieval system that finds clips matching queries such as ""across the kitchen.""",2009,2022-09-02T13:29:39Z,2022-09-02T13:29:39Z,NA,253–260,NA,NA,NA,NA,NA,NA,ICMI-MLMI '09,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Cambridge, Massachusetts, USA",NA,NA,NA,spatial language; video retrieval,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,8JYZPDZB,conferencePaper,2011,"Kim, Seung-Hun; Park, Changwoo; Jun, Sewoong",Ceiling Vision Based Localizer for Mobile Robot,Proceedings of the 2nd International Conference on Computing for Geospatial Research &amp; Applications,978-1-4503-0681-2,NA,10.1145/1999320.1999374,https://doi.org/10.1145/1999320.1999374,"When mobile robots perform their missions, the self-localization is needed basically. Several past researches established how to obtain their location information from the environment by using a distance sensor or a camera. However, these methods have map-making problem when the environment changes and localization problem while the robot moves from sensing features has typical affine and occlusion characteristics. This paper presents a localizer for mobile robot that travels around indoor environments. Our module uses the only one sensor, a single camera looking up the ceiling. There is no efficient enough SLAM* (Simultaneous Localization And Mapping) algorithm working on embedded system. The initial difficulty of vision based SLAM is computational complexity to acquire reliable feature on their algorithm. To reduce the computational complexity, we use the ceiling segmentation to extract line features of ceiling area. Line features are extracted from the boundaries between the ceiling and walls. The line features have advantages over point features for its robustness to environmental variation and structural information helpful to data association. Extended Kalman Filter is used to estimate the pose of a robot and build the ceiling map with line features. The experiment is practiced in our indoor test bed and the proposed algorithm is proved by the experimental results.*SLAM: Simultaneous localization and mapping is a technique used by robots and autonomous vehicles to build up a map within an unknown environment or to update a map within a known environment while at the same time keeping track of their current location.",2011,2022-09-02T13:29:40Z,2022-09-02T13:29:40Z,NA,NA,NA,NA,NA,NA,NA,NA,COM.Geo '11,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Washington, DC, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,E9MI4M2X,conferencePaper,2009,"Tellex, Stefanie; Roy, Deb",Towards Surveillance Video Search by Natural Language Query,Proceedings of the ACM International Conference on Image and Video Retrieval,978-1-60558-480-5,NA,10.1145/1646396.1646442,https://doi.org/10.1145/1646396.1646442,"Spatial language video retrieval is an important real-world problem that is also a natural test bed for evaluating semantic structures for natural language descriptions of motion on naturalistic data. This paper describes first steps towards a system that grounds the meaning of spatial prepositions in geometric features. This system can be used to search a corpus of surveillance video for clips that match spatial language queries such as ""along the hallway"" and ""across the kitchen."" We present experiments characterizing the performance of models for the prepositions ""across"" and ""along,"" and present a methodology for modeling other spatial prepositions.",2009,2022-09-02T13:29:40Z,2022-09-02T13:29:40Z,NA,NA,NA,NA,NA,NA,NA,NA,CIVR '09,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Santorini, Fira, Greece",NA,NA,NA,spatial language; video retrieval,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,9TYADFK9,conferencePaper,2018,"Kawai, Yasuo; Kaizu, Yurie; Kawahara, Kenta; Obuchi, Youhei; Otsuka, Satoshi; Tomimatsu, Shiori",Development of a Tsunami Evacuation Behavior Simulation System with Massive Evacuation Agents,Proceedings of the 23rd International Conference on Intelligent User Interfaces Companion,978-1-4503-5571-1,NA,10.1145/3180308.3180321,https://doi.org/10.1145/3180308.3180321,"We present an evacuation behavior simulation system at the time of tsunami using the evacuation agent of a game engine. The tsunami evacuation behavior simulation system is a system that enables local governments and residents to work together to formulate disaster prevention plans. As a representation of a simple tsunami, in this system, a slightly oblique plane is inserted as the sea surface to a three-dimensional model of the terrain, building, and road, which is generated by geographical information system data. Mass agents of evacuees randomly placed on the road will move toward the nearest wide evacuation shelter or tsunami evacuation building. As a result, problems were found in the shape of some roads and the position of evacuation buildings.",2018,2022-09-02T13:29:40Z,2022-09-02T13:29:40Z,NA,NA,NA,NA,NA,NA,NA,NA,IUI '18 Companion,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Tokyo, Japan",NA,NA,NA,Disaster Prevention Planning; Disaster Visualization; Evacuation Behavior; Natural Disaster Evacuee; Tsunami,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,BGAP6IH7,book,2016,NA,CHANTS '16: Proceedings of the Eleventh ACM Workshop on Challenged Networks,NA,978-1-4503-4256-8,NA,NA,NA,"Over the years, challenged networks have evolved from niche solution for extremely hostile scenarios (such as disaster relief or connectivity provision in rural and remote areas) to important component of everyday networks. In their second life, challenged networks have entered mobile cloud/mobile edge computing, IoT, mobile data offloading, and SDN. It is exactly these new directions of challenged networking that are the focus of this 2016 edition of CHANTS. While keeping an eye on the future, we also wanted to tackle a years-old affliction: how to move from theory to practice when dealing with challenged networks. For this reason, we also have a lineup spanning DTN software and testbeds that will speed up the jump from the research lab to marketable products.",2016,2022-09-02T13:29:40Z,2022-09-02T13:29:40Z,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,BKMWPDKI,conferencePaper,2016,"Rahman, Muntasir Raihan; Piduri, Sudarsan; Languev, Ilya; Griffith, Rean; Gupta, Indranil",Software-Defined Consistency Group Abstractions for Virtual Machines,Proceedings of the 4th Workshop on Distributed Cloud Computing,978-1-4503-4220-9,NA,10.1145/2955193.2955198,https://doi.org/10.1145/2955193.2955198,"In this paper we propose a practical scalable software-level mechanism for taking crash-consistent snapshots of a group of virtual machines. The group is dynamically defined at the software virtualization layer allowing us to move the consistency group abstraction from the hardware array layer into the hypervisor with very low overhead ( 50 msecs VM freeze time). This low overhead allows us to take crash-consistent snapshots of large software-defined consistency groups at a reasonable frequency, guaranteeing low data loss for disaster recovery. To demonstrate practicality, we use our mechanism to take crash-consistent snapshots of multi-disk virtual machines running two database applications: PostgreSQL, and Apache Cassandra. Deployment experiments confirm that our mechanism scales well with number of VMs, and snapshot times remain invariant of virtual disk size and usage.",2016,2022-09-02T13:29:40Z,2022-09-02T13:29:40Z,NA,NA,NA,NA,NA,NA,NA,NA,DCC '16,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Chicago, Illinois",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,2TQSGKYJ,conferencePaper,2012,"Li, Qingan; Zhao, Mengying; Xue, Chun Jason; He, Yanxiang",Compiler-Assisted Preferred Caching for Embedded Systems with STT-RAM Based Hybrid Cache,"Proceedings of the 13th ACM SIGPLAN/SIGBED International Conference on Languages, Compilers, Tools and Theory for Embedded Systems",978-1-4503-1212-7,NA,10.1145/2248418.2248434,https://doi.org/10.1145/2248418.2248434,"As technology scales down, energy consumption is becoming a big problem for traditional SRAM-based cache hierarchies. The emerging Spin-Torque Transfer RAM (STT-RAM) is a promising replacement for large on-chip cache due to its ultra low leakage power and high storage density. However, write operations on STT-RAM suffer from considerably higher energy consumption and longer latency than SRAM. Hybrid cache consisting of both SRAM and STT-RAM has been proposed recently for both performance and energy efficiency. Most management strategies for hybrid caches employ migration-based techniques to dynamically move write-intensive data from STT-RAM to SRAM. These techniques lead to extra overheads. In this paper, we propose a compiler-assisted approach, preferred caching, to significantly reduce the migration overhead by giving migration-intensive memory blocks the preference for the SRAM part of the hybrid cache. Furthermore, a data assignment technique is proposed to improve the efficiency of preferred caching. The reduction of migration overhead can in turn improve the performance and energy efficiency of STT-RAM based hybrid cache. The experimental results show that, with the proposed techniques, on average, the number of migrations is reduced by 21.3%, the total latency is reduced by 8.0% and the total dynamic energy is reduced by 10.8%.",2012,2022-09-02T13:29:40Z,2022-09-02T13:29:40Z,NA,109–118,NA,NA,NA,NA,NA,NA,LCTES '12,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Beijing, China",NA,NA,NA,compiler; data assignment; hybrid cache,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,GVGR8RSP,journalArticle,2012,"Li, Qingan; Zhao, Mengying; Xue, Chun Jason; He, Yanxiang",Compiler-Assisted Preferred Caching for Embedded Systems with STT-RAM Based Hybrid Cache,SIGPLAN Not.,NA,0362-1340,10.1145/2345141.2248434,https://doi.org/10.1145/2345141.2248434,"As technology scales down, energy consumption is becoming a big problem for traditional SRAM-based cache hierarchies. The emerging Spin-Torque Transfer RAM (STT-RAM) is a promising replacement for large on-chip cache due to its ultra low leakage power and high storage density. However, write operations on STT-RAM suffer from considerably higher energy consumption and longer latency than SRAM. Hybrid cache consisting of both SRAM and STT-RAM has been proposed recently for both performance and energy efficiency. Most management strategies for hybrid caches employ migration-based techniques to dynamically move write-intensive data from STT-RAM to SRAM. These techniques lead to extra overheads. In this paper, we propose a compiler-assisted approach, preferred caching, to significantly reduce the migration overhead by giving migration-intensive memory blocks the preference for the SRAM part of the hybrid cache. Furthermore, a data assignment technique is proposed to improve the efficiency of preferred caching. The reduction of migration overhead can in turn improve the performance and energy efficiency of STT-RAM based hybrid cache. The experimental results show that, with the proposed techniques, on average, the number of migrations is reduced by 21.3%, the total latency is reduced by 8.0% and the total dynamic energy is reduced by 10.8%.",2012-06,2022-09-02T13:29:40Z,2022-09-02T13:29:40Z,NA,109–118,NA,5,47,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,compiler; data assignment; hybrid cache,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,6A767V2B,conferencePaper,2012,"Xu, Chenren; Firner, Bernhard; Zhang, Yanyong; Howard, Richard; Li, Jun; Lin, Xiaodong",Improving RF-Based Device-Free Passive Localization in Cluttered Indoor Environments through Probabilistic Classification Methods,Proceedings of the 11th International Conference on Information Processing in Sensor Networks,978-1-4503-1227-1,NA,10.1145/2185677.2185734,https://doi.org/10.1145/2185677.2185734,"Radio frequency based device-free passive localization has been proposed as an alternative to indoor localization because it does not require subjects to wear a radio device. This technique observes how people disturb the pattern of radio waves in an indoor space and derives their positions accordingly. The well-known multipath effect makes this problem very challenging, because in a complex environment it is impractical to have enough knowledge to be able to accurately model the effects of a subject on the surrounding radio links. In addition, even minor changes in the environment over time change radio propagation sufficiently to invalidate the datasets needed by simple fingerprint-based methods. In this paper, we develop a fingerprinting-based method using probabilistic classification approaches based on discriminant analysis. We also devise ways to mitigate the error caused by multipath effect in data collection, further boosting the classification likelihood.We validate our method in a one-bedroom apartment that has 8 transmitters, 8 receivers, and a total of 32 cells that can be occupied. We show that our method can correctly estimate the occupied cell with a likelihood of 97.2%. Further, we show that the accuracy remains high, even when we significantly reduce the training overhead, consider fewer radio devices, or conduct a test one month later after the training. We also show that our method can be used to track a person in motion and to localize multiple people with high accuracies. Finally, we deploy our method in a completely different commercial environment with two times the area achieving a cell estimation accuracy of 93.8% as an evidence of applicability to multiple environments.",2012,2022-09-02T13:29:40Z,2022-09-02T13:29:40Z,NA,209–220,NA,NA,NA,NA,NA,NA,IPSN '12,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Beijing, China",NA,NA,NA,discriminant analysis; device-free passive localization; multipath; rss footprint,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,4JF92FRZ,journalArticle,2020,"Deng, Lijia; Xu, Wenzheng; Liang, Weifa; Peng, Jian; Zhou, Yingjie; Duan, Lei; Das, Sajal K.",Approximation Algorithms for the Min-Max Cycle Cover Problem With Neighborhoods,IEEE/ACM Trans. Netw.,NA,1063-6692,10.1109/TNET.2020.2999630,https://doi.org/10.1109/TNET.2020.2999630,"In this paper we study the min-max cycle cover problem with neighborhoods, which is to find a given number of K cycles to collaboratively visit n Points of Interest (POIs) in a 2D space such that the length of the longest cycle among the K cycles is minimized. The problem arises from many applications, including employing mobile sinks to collect sensor data in wireless sensor networks (WSNs), dispatching charging vehicles to recharge sensors in rechargeable sensor networks, scheduling Unmanned Aerial Vehicles (UAVs) to monitor disaster areas, etc. For example, consider the application of employing multiple mobile sinks to collect sensor data in WSNs. If some mobile sink has a long data collection tour while the other mobile sinks have short tours, this incurs a long data collection latency of the sensors in the long tour. Existing studies assumed that one vehicle needs to move to the location of a POI to serve it. We however assume that the vehicle is able to serve the POI as long as the vehicle is within the neighborhood area of the POI. One such an example is that a mobile sink in a WSN can receive data from a sensor if it is within the transmission range of the sensor (e.g., within 50 meters). It can be seen that the ignorance of neighborhoods will incur a longer traveling length. On the other hand, most existing studies only took into account the vehicle traveling time but ignore the POI service time. Consequently, although the length of some vehicle tour is short, the total amount of time consumed by a vehicle in the tour is prohibitively long, due to many POIs in the tour. In this paper we first study the min-max cycle cover problem with neighborhoods, by incorporating both neighborhoods and POI service time into consideration. We then propose novel approximation algorithms for the problem, by exploring the combinatorial properties of the problem. We finally evaluate the proposed algorithms via experimental simulations. Experimental results show that the proposed algorithms are promising. Especially, the maximum tour times by the proposed algorithms are only about from 80% to 90% of that by existing algorithms.",2020-08,2022-09-02T13:29:40Z,2022-09-02T13:29:40Z,NA,1845–1858,NA,4,28,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Publisher: IEEE Press,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,M4MHE2QV,conferencePaper,2018,"Alharthi, Sultan A.; Sharma, Hitesh Nidhi; Sunka, Sachin; Dolgov, Igor; Toups, Zachary O.",Designing Future Disaster Response Team Wearables from a Grounding in Practice,"Proceedings of the Technology, Mind, and Society",978-1-4503-5420-2,NA,10.1145/3183654.3183662,https://doi.org/10.1145/3183654.3183662,"Wearable computers are poised to impact disaster response, so there is a need to determine the best interfaces to support situation awareness, decision support, and communication. We present a disaster response wearable design created for a mixed reality live-action role playing design competition, the Icehouse Challenge. The challenge, an independent event in which the authors were competitors, offers a simulation game environment in which teams compete to test wearable designs. In this game, players move through a simulated disaster space that requires team coordination and physical exertion to mitigate virtual hazards and stabilize virtual victims. Our design was grounded in disaster response and team coordination practice. We present our design process to develop wearable computer interfaces that integrate physiological and virtual environmental sensor data and display actionable information through a head-mounted display. We reflect on our observations from the live game, discuss challenges, opportunities, and design implications for future disaster response wearables to support collaboration.",2018,2022-09-02T13:29:40Z,2022-09-02T13:29:40Z,NA,NA,NA,NA,NA,NA,NA,NA,TechMindSociety '18,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Washington, DC, USA",NA,NA,NA,Wearable; augmented reality; collaboration; disaster response; head-mounted display; LARP; mixed reality; team coordination,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,5JJGN4YD,conferencePaper,2022,"Islam, Kazi Ashik; Marathe, Madhav; Mortveit, Henning; Swarup, Samarth; Vullikanti, Anil",Data-Driven Agent-Based Models for Optimal Evacuation of Large Metropolitan Areas for Improved Disaster Planning,Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems,978-1-4503-9213-6,NA,NA,NA,"Evacuation plans are designed to move people to safety in case of a disaster. It mainly consists of two components: routing and scheduling. Joint optimization of these two components with the goal of minimizing total evacuation time is a computationally hard problem, specifically when the problem instance is large. Moreover, often in disaster situations, there is uncertainty regarding the passability of roads throughout the evacuation time period. In this paper, we present a way to model the time-varying risk associated with roads in disaster situations. We also design a heuristic method based on the well known Large Neighborhood Search framework to perform the joint optimization task. We use real-world road network and population data from Harris County in Houston, Texas and apply our heuristic to find evacuation routes and schedules for the area. We show that the proposed method is able to find good solutions within a reasonable amount of time. We also perform agent-based simulations of the evacuation using these solutions to evaluate their quality and efficacy.",2022,2022-09-02T13:29:40Z,2022-09-02T13:29:40Z,NA,1639–1641,NA,NA,NA,NA,NA,NA,AAMAS '22,NA,NA,NA,International Foundation for Autonomous Agents and Multiagent Systems,"Richland, SC",NA,NA,NA,NA,NA,NA,NA,"event-place: Virtual Event, New Zealand",NA,NA,NA,simulation; routing; evacuation; heuristic; individual and social utility; large neighborhood search; MIP; scheduling,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,JTTUN4ZG,conferencePaper,2011,"Legendre, Franck",30 Years of Ad Hoc Networking Research: What about Humanitarian and Disaster Relief Solutions? What Are We Still Missing?,Proceedings of the 1st International Conference on Wireless Technologies for Humanitarian Relief,978-1-4503-1011-6,NA,10.1145/2185216.2185279,https://doi.org/10.1145/2185216.2185279,"In this invited talk, we will start by surveying the research works conducted during the last 30 years on wireless networking technologies from ad hoc, mesh to delay-tolerant opportunistic networks. We present how these networking technology may be applied to uphold communications in the event of a disaster where the communication infrastructure can be wiped-out (earthquakes, floods), overloaded (surge of traffic and flash crowds) or not existing in the first place (developing countries). We summarize the advantages and disadvantages of each unique approach, how they can be combined together (and with legacy systems), and focus on recent advances in the field. In a second part we will present, Twimight, our Twitter application relying on opportunistic communications to spread tweets and sensor data in an epidemic fashion. Twimight is an open source Twitter client for Android phones featured with a ""disaster mode"", which users enable upon losing connectivity. In the disaster mode, tweets are not sent to the online Twitter servers but stored on the phone, carried around as people move, and forwarded opportunistically via Bluetooth or WiFi Direct when in proximity with other smartphones.We will demonstrate how opportunistic technologies such as Twimight can be of great value right after a disaster by enabling the self-organization of victims and a better coordination with first rescue organizations. Eventually, we will conclude with the main challenges still to overcome and provide directions for future research in this emerging field from protocol and system design to security and data privacy. We will stress the need for cross-disciplinary approaches to better understand the psychology of distressed victims and their interaction with innovative communication technologies.",2011,2022-09-02T13:29:40Z,2022-09-02T13:29:40Z,NA,217,NA,NA,NA,NA,NA,NA,ACWR '11,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Amritapuri, Kollam, Kerala, India",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,28Z2B8UU,conferencePaper,2011,"Hossmann, Theus; Carta, Paolo; Schatzmann, Dominik; Legendre, Franck; Gunningberg, Per; Rohner, Christian",Twitter in Disaster Mode: Security Architecture,Proceedings of the Special Workshop on Internet and Disasters,978-1-4503-1044-4,NA,10.1145/2079360.2079367,https://doi.org/10.1145/2079360.2079367,"Recent natural disasters (earthquakes, floods, etc.) have show that people heavily use platforms like Twitter to communicate and organize in emergencies. However, the fixed infrastructure supporting such communications may be temporarily wiped out. In such situations, the phones' capabilities of infrastructure-less communication can fill in: By propagating data opportunistically (from phone to phone), tweets can still be spread, yet at the cost of delays.In this paper, we present Twimight and its network security extensions. Twimight is an open source Twitter client for Android phones featured with a ""disaster mode"", which users enable upon losing connectivity. In the disaster mode, tweets are not sent to the Twitter server but stored on the phone, carried around as people move, and forwarded via Bluetooth when in proximity with other phones. However, switching from an online centralized application to a distributed and delay-tolerant service relying on opportunistic communication requires rethinking the security architecture. We propose security extensions to offer comparable security in the disaster mode as in the normal mode to protect Twimight from basic attacks. We also propose a simple, yet efficient, anti-spam scheme to avoid users from being flooded with spam. Finally, we present a preliminary empirical performance evaluation of Twimight.",2011,2022-09-02T13:29:40Z,2022-09-02T13:29:40Z,NA,NA,NA,NA,NA,NA,NA,NA,SWID '11,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Tokyo, Japan",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,G3S5UJHI,conferencePaper,2017,"Hematian, Amirshahram; Nguyen, James; Lu, Chao; Yu, Wei; Ku, Daniel",Software Defined Radio Testbed Setup and Experimentation,Proceedings of the International Conference on Research in Adaptive and Convergent Systems,978-1-4503-5027-3,NA,10.1145/3129676.3129690,https://doi.org/10.1145/3129676.3129690,"Software Defined Radio (SDR) can move the complicated signal processing and handling procedures involved in communications from radio equipment into computer software. Consequently, SDR equipment could consist of only a few chips connected to an antenna. In this paper, we present an implemented SDR testbed, which consists of four complete SDR nodes. Using the designed testbed, we have conducted two case studies. The first is designed to facilitate video transmission via adaptive LTE links. Our experimental results demonstrate that adaptive LTE link video transmission could reduce the bandwidth usage for data transmission. In the second case study, we perform UE location estimation by leveraging the signal strength from nearby cell towers, pertinent to various applications, such as public safety and disaster rescue scenarios where GPS (Global Position System) is not available (e.g., indoor environment). Our experimental results show that it is feasible to accurately derive the location of a UE (User Equipment) by signal strength. In addition, we design a Hardware In the Loop (HIL) simulation environment using the Vienna LTE simulator, srsLTE library, and our SDR testbed. We develop a software wrapper to connect the Vienna LTE simulator to our SDR testbed via the srsLTE library. Our experimental results demonstrate the comparative performance of simulated UEs and eNodeBs against real SDR UEs and eNodeBs, as well as how a simulated environment can interact with a real-world implementation.",2017,2022-09-02T13:29:40Z,2022-09-02T13:29:40Z,NA,172–177,NA,NA,NA,NA,NA,NA,RACS '17,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Krakow, Poland",NA,NA,NA,Testbed; Cognitive Radios; Performance Evaluation; Wireless Networks,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,GPAPJYXE,conferencePaper,2018,"Meyer auf der Heide, Friedhelm; Schaefer, Johannes",Brief Announcement: Communication in Systems of Home Based Mobile Agents,Proceedings of the 30th on Symposium on Parallelism in Algorithms and Architectures,978-1-4503-5799-9,NA,10.1145/3210377.3210662,https://doi.org/10.1145/3210377.3210662,"We consider a scenario where agents have to exchange data in a wireless ad-hoc network, although it is not connected. We assume that each agent has a static home base. To improve connectivity, each agent is allowed to move away from his home base, but only for a limited distance which may be different for different agents. These distances might be dictated by limited batteries of the agents, which forces them to return to their home charging station after a while. An application currently widely considered in literature (and in projects and applications) is disaster management, where helpers are equipped with smartphones to submit important local information to a coordinating station. In case of the network being disconnected, mobile ""postmen” are used for long distance connections. In this paper, we focus on the aspect of ""communication by postmen”. We model such a scenario by a weighted directed graph. It consists of n (static) nodes describing the home bases of the agents. A directed edge from base $v_i$ to base $v_j$ with weight $w(v_i,v_j)$ indicates that agent $a_i$ can walk from his home base to the home base of $a_j$, which needs time $w(v_i,v_j)$. If agent $a_j$ is at home when agent $a_i$ arrives, they can exchange messages. % Alongside with the introduction of the model, we present a randomized distributed algorithm for all-to-all message dissemination and show that its performance is, in many cases, close to optimal.",2018,2022-09-02T13:29:40Z,2022-09-02T13:29:40Z,NA,359–361,NA,NA,NA,NA,NA,NA,SPAA '18,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Vienna, Austria",NA,NA,NA,distributed algorithms; dynamic networks; mobile agents; self-organization,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,FFFICH7J,conferencePaper,2019,"Muttillo, Mirco; Barile, Gianluca; Leoni, Alfiero; Ferri, Giuseppe",Wired Sensors System for Monitoring of Landslide Events,"Proceedings of the 3rd International Conference on Vision, Image and Signal Processing",978-1-4503-7625-9,NA,10.1145/3387168.3387229,https://doi.org/10.1145/3387168.3387229,"Landslides are catastrophic events that change the territory making these events dangerous for buildings and people. Monitoring and alerting on a possible landslide can avoid disasters and can save lives. Thanks to a monitoring system it is possible to prevent and intervene in time before the situation gets worse. The aim of this work is the design of a wired sensor monitoring system for landslide events. The system is composed by one datalogger and many nodes, which measure the inclination, and communicate between each other through RS485. The datalogger is based on a microcontroller ATmega2560 which has the task of retrieving data from nodes and sending them to an FTP server. The nodes have an ATmega328p microcontroller that reads data from a digital accelerometer MMA8451 that is able to detect inclination variations up to 0.1 degrees. Furthermore, the nodes are able to go into sleep mode reducing power consumption. The system includes a calibration phase for the first installation on site to be monitored. The proposed system was tested in a real case and same preliminary data, obtained after a post processing done with Matlab, are here reported.",2019,2022-09-02T13:29:40Z,2022-09-02T13:29:40Z,NA,NA,NA,NA,NA,NA,NA,NA,ICVISP 2019,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Vancouver, BC, Canada",NA,NA,NA,Landslide Monitoring; Risk Monitoring; Sensor Network; Wired Sensor System,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,K85IGY9X,conferencePaper,2015,"Trajcevski, Goce",Fusion of Uncertain Location Data from Heterogeneous Sources,Proceedings of the Fourth ACM SIGSPATIAL International Workshop on Mobile Geographic Information Systems,978-1-4503-3977-3,NA,10.1145/2834126.2834818,https://doi.org/10.1145/2834126.2834818,"Many applications of high societal relevance – e.g., transportation and traffic management, disaster remediation, location-aware social networking, (tourist) recommendation systems, military logistics (to name but a few) – rely on some kind of Location Based Services (LBS). The crucial components to support such services, in turn, rely on efficient techniques for managing the data capturing the information pertaining to the whereabouts in time of the moving entities – storing, retrieving and querying such data. Traditionally, such topics were subjects of the fields called Spatial/Spatio-Temporal Databases, Moving Objects Databases (MOD) and Geographic Information Systems (GIS) [2, 5, 11]. To give an intuitive idea about the magnitude – according to Mc Kinsey survey from 2011 [9], the volume of location-in-time data exceeds the order of Peta-Bytes per year just from smartphones – and this is only the ""pure"" GPS (Global Positioning System) data. Including the cell-towers location data would boost the size by two orders of magnitude – however, this is not even close to the full magnitude of the variety of location-related data contained in numerous tweets and other social networks based communications (which is of interest for applications such as behavioral marketing).",2015,2022-09-02T13:29:41Z,2022-09-02T13:29:41Z,NA,1–2,NA,NA,NA,NA,NA,NA,MobiGIS '15,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Bellevue, Washington",NA,NA,NA,uncertainty; heterogeneity; fusion,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,45VVP4UX,conferencePaper,2007,"Griffiths, Karen; Kramolis, Tammie",Twelve Steps to Recovery: My Co-Dependent Relationship with Tivoli,Proceedings of the 35th Annual ACM SIGUCCS Fall Conference,978-1-59593-634-9,NA,10.1145/1294046.1294078,https://doi.org/10.1145/1294046.1294078,"Several years ago Baylor University moved from a passively managed data backup model to an actively managed strategy. As much as we would like the responsibility for data backup to reside with the owner of the data, we realize that in most cases this does not hold true. Our clients' expectation is that the Information Technology Systems (ITS) department is backing up their data. In the past, data backup was not likely to be something our client gave any thought to. We often did and still do see faculty members working on research, publications or databases requiring hundreds of hours of work. Users will often keep the only copy of the file on the desktop of their PC. As portable storage devices (flash drives) have come down in price, we are now seeing users backup a copy of a file to a flash drive in order to work on it at another location. They will usually copy a file here or there but usually not for disaster recovery purposes. Although most of the computers on campus have read/write to CD or DVD capabilities, again we don't typically see our users archiving their files unless we instruct them to do so. We see that there is often confusion on their part as to what data is accessed from the client's hard drive and what data actually resides on a server.The storage solution used for Staff/Faculty electronic data at Baylor University is the Tivoli Storage Manager® software program. The support side of ITS was not involved in the decision to migrate to this software so we were not prepared for the amount of attention that would be required. Tivoli Storage Manager® is a powerful program and from a Help Desk or Client Support standpoint, it was a high maintenance relationship from the beginning. We tried unsuccessfully to rid ourselves of this time consuming and frustrating relationship. Later we realized that as much as Tivoli needed us, we needed Tivoli. Much like any other codependent relationship, we've had our ups and downs. We like to believe that we have reached a point of happy coexistence with Tivoli and we'd like to share the journey we took to arrive at this place. We also realize that like any other relationship in our lives, it requires effort on our part to ensure that the data backup process continues to work in a smooth and consistent manner. We may not be able to change the need for the software or the software's need for our attention but a shift in thinking can open up different ways of handling issues that come up in a positive and productive way. We will use the premise of a 12 step program used to recover manageability to one's life as a basis for the presentation of our data recovery program.",2007,2022-09-02T13:29:41Z,2022-09-02T13:29:41Z,NA,135–138,NA,NA,NA,NA,NA,NA,SIGUCCS '07,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Orlando, Florida, USA",NA,NA,NA,security; baylor resnet; bearweb; data recovery; data storage; heat®; help desk; information technology services; ITS; relationship; software support; tivoli storage manager®,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,IBBYB4NE,journalArticle,2020,"Naghizade, Elham; Kulik, Lars; Tanin, Egemen; Bailey, James",Privacy- and Context-Aware Release of Trajectory Data,ACM Trans. Spatial Algorithms Syst.,NA,2374-0353,10.1145/3363449,https://doi.org/10.1145/3363449,"The availability of large-scale spatio-temporal datasets along with the advancements in analytical models and tools have created a unique opportunity to create valuable insights into managing key areas of society from transportation and urban planning to epidemiology and natural disasters management. This has encouraged the practice of releasing/publishing trajectory datasets among data owners. However, an ill-informed publication of such rich datasets may have serious privacy implications for individuals. Balancing privacy and utility, as a major goal in the data exchange process, is challenging due to the richness of spatio-temporal datasets. In this article, we focus on an individual’s stops as the most sensitive part of the trajectory and aim to preserve them through spatio-temporal perturbation. We model a trajectory as a sequence of stops and moves and propose an efficient algorithm that either substitutes sensitive stop points of a trajectory with moves from the same trajectory or introduces a minimal detour if no safe Point of Interest (POI) can be found on the same route. This hinders the amount of unnecessary distortion, since the footprint of the original trajectory is preserved as much as possible. Our experiments shows that our method balances user privacy and data utility: It protects privacy through preventing an adversary from making inferences about sensitive stops while maintaining a high level of similarity to the original dataset.",2020-01,2022-09-02T13:29:41Z,2022-09-02T13:29:41Z,NA,NA,NA,1,6,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,semantics; data publication; Spatio-temporal databases; trajectory privacy,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,9Y4YYKHY,conferencePaper,2017,"Kim, Kyoung-Sook; Kim, Dongmin; Jeong, Hyemi; Ogawa, Hirotaka",Stinuum: A Holistic Visual Analysis of Moving Objects with Open Source Software,Proceedings of the 25th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,978-1-4503-5490-5,NA,10.1145/3139958.3140011,https://doi.org/10.1145/3139958.3140011,"With the development of position tracking technologies and the increasing usage of mobile devices, the analysis of moving objects, such as pedestrians, vehicles, drones, and hurricanes has become an important topic in various applications including intelligent transportation, disaster management, and urban planning. Many of existing studies have focused on managing and analyzing only time-varying locations of point-based objects. However, real-world moving phenomena are space-time continua occupying volumes, having an area at a time; even more, they contain dynamic attributes depending on time and space, such as the velocity of vehicles or the average of wind speed of hurricanes. In this demonstration, we introduce a comprehensive data format to represent various types of temporal geometries and dynamic properties of moving objects based on OGC® Moving Features. Moreover, we present a visual extension of Cesium to visualize moving objects in a space-time cube by cooperating with a data server that manages moving objects in a Cassandra database via RESTful APIs. This demonstration presents how to analyze a correlation between typhoon trajectories and geo-tagged Twitter messages with our systems.",2017,2022-09-02T13:29:41Z,2022-09-02T13:29:41Z,NA,NA,NA,NA,NA,NA,NA,NA,SIGSPATIAL '17,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Redondo Beach, CA, USA",NA,NA,NA,Cassandra; Cesium; Geovisualization; JSON; OGC® Moving Features; REST; Space-time Cube,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,42WNMM9J,conferencePaper,2011,"Sun, Zhenyu; Bi, Xiuyuan; Li, Hai (Helen); Wong, Weng-Fai; Ong, Zhong-Liang; Zhu, Xiaochun; Wu, Wenqing",Multi Retention Level STT-RAM Cache Designs with a Dynamic Refresh Scheme,Proceedings of the 44th Annual IEEE/ACM International Symposium on Microarchitecture,978-1-4503-1053-6,NA,10.1145/2155620.2155659,https://doi.org/10.1145/2155620.2155659,"Spin-transfer torque random access memory (STT-RAM) has received increasing attention because of its attractive features: good scalability, zero standby power, non-volatility and radiation hardness. The use of STT-RAM technology in the last level on-chip caches has been proposed as it minimizes cache leakage power with technology scaling down. Furthermore, the cell area of STT-RAM is only 1/9 1/3 that of SRAM. This allows for a much larger cache with the same die footprint, improving overall system performance through reducing cache misses. However, deploying STT-RAM technology in L1 caches is challenging because of the long and power-consuming write operations. In this paper, we propose both L1 and lower level cache designs that use STT-RAM. In particular, our designs use STT-RAM cells with various data retention time and write performances, made possible by different magnetic tunneling junction (MTJ) designs. For the fast STT-RAM bits with reduced data retention time, a counter controlled dynamic refresh scheme is proposed to maintain the data validity. Our dynamic scheme saves more than 80% refresh energy compared to the simple refresh scheme proposed in previous works. A L1 cache built with ultra low retention STT-RAM coupled with our proposed dynamic refresh scheme can achieve 9.2% in performance improvement, and saves up to 30% of the total energy when compared to one that uses traditional SRAM. For lower level caches with relative large cache capacity, we propose a data migration scheme that moves data between portions of the cache with different retention characteristics so as to maximize the performance and power benefits. Our experiments show that on the average, our proposed multi retention level STT-RAM cache reduces 30 70% of the total energy compared to previous works, while improving IPC performance for both 2-level and 3-level cache hierarchy.",2011,2022-09-02T13:29:41Z,2022-09-02T13:29:41Z,NA,329–338,NA,NA,NA,NA,NA,NA,MICRO-44,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Porto Alegre, Brazil",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,TDR5DMDP,conferencePaper,1988,"Miller, William B.",To DOS or Not to DOS,Proceedings of the 16th Annual ACM SIGUCCS Conference on User Services,0-89791-286-1,NA,10.1145/62548.62660,https://doi.org/10.1145/62548.62660,"Much to the disappointment of hard core disk operating system (DOS) wizards, many computer users have little knowledge of DOS commands and, in fact, they may not need much DOS knowledge in the future.Computer users today are able to manage files and move from application to application without directly invoking a DOS command. Application packages such as word processors, spread sheets, and data bases provide for file management. Special software programs are available that allow the user to backup an entire hard disk without any knowledge of DOS.Menu programs can be placed on a hard disk which allow the user to choose applications without knowing DOS commands. Perhaps the most creative programs to help the user avoid DOS, are the DOS management systems available on the market today which allow the user to speak English while the program speaks DOS to the system.On some campuses personnel are available to install and set up computers with hard disks using menu programs, applications, and DOS management programs. The user is trained in using the application and shown how to work with the menu system. As long as the system does not have a hardware or software problem, the user is able to be productive without extensive training in DOS commands. This process saves a great deal of time and money in training the computer user. Emphasis can be placed on training programs in areas where there is direct return for the time and money spent.Certainly a case could be developed to support DOS training for all computer users. Knowledge of the operating system, file management, backup procedures, etc. could be a tremendous advantage for the user. However, management must weigh the expenditure of time and cost against the advantages of training a staff in MS-DOS. Furthermore, not all computer users will find DOS friendly and their attempt to use the DOS commands could become frustrating and time consuming.",1988,2022-09-02T13:29:41Z,2022-09-02T13:29:41Z,NA,373–376,NA,NA,NA,NA,NA,NA,SIGUCCS '88,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Long Beach, California, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,IMYU485N,journalArticle,2002,"Glass, Robert L.","How to Handle Real Project Risks, While Filing Gaps in the Risk Theory Literature",SIGMIS Database,NA,0095-0033,10.1145/513264.513268,https://doi.org/10.1145/513264.513268,"Who would have thought research projects could make for interesting books? This is my second recent column about a research project that led to a book. I still find myself scratching my head about that as a concept.Nevertheless, here again is a book based entirely on a single research project. In this case, the research was conducted by the author, Tony Moynihan, in his role of Professor of Computer Applications at Dublin City University in Ireland. The topic? The techniques used by experienced software project managers for addressing and managing risks on their projects.You might expect that would make for a boring book. But, in fact, it isn't! This is probably one of the most real, useful, and entertaining books I have ever read on project management. (You may know that project management isn't my favorite software engineering topic!).What was the research project, and what is so real about it? The author interviewed a collection of 30-odd IS/IT project managers, from the point of view of project risks they had experienced. He asked them to discuss and rank risks on projects they had managed, and then on hypothetical projects he presented to them, all the while eliciting comments on how they did or would handle those risks. The result came through as the most real collection of thoughts on project management I have ever read, in that they were straight from the horse's mouth (that is, from experienced software project managers).Having elicited all those opinions, the author then aggregated them into perhaps the most useful chapter of the book, the one that presents ""some strategies/recipes"" for handling specific risks. There's even a chapter on ""when to walk away"" from a project that looks like a disaster-in-the-making.Now, an important question is ""Who's the target audience for this book?"" The author says it's for ""IS/IT software project managers."" Well, I suppose that makes sense. But there's a whole lot of researchy stuff - methods and approaches - that the average practitioner would want to move swiftly over, but the average researcher might gobble up. There's a chapter on linking the findings to risk theory that also would be eminently skippable for many practitioners, but would be the heart of the book for a researcher. In fact, as I read this, I found myself wishing it could be required reading for IS/IT academics! The reality of the findings would help immensely in getting those academics to move down to earth in their consideration of what's important in IS/IT and software. As a particular example, there's even a research finding that identifies gaps in the traditional risk theoretical literature, issues that arose during the interviews that are not present in that literature.As a further example, the problem that kept recurring as the most serious one to worry about was variously called either ""control"" (issues over which you haven't much control are real potential project pitfalls), or ""customer people problems"" (that's where many of those control issues were categorized). And the resolution of those control problems was most frequently found in a subject the author considered only in passing, contractual approaches.I think most academics, especially those who tend to deal largely in technical matters, would be surprised at how unimportant such issues really are to people in the field!As an example of that, the author noted that ""requirements uncertainty,"" a matter of high concern in most academic textbooks, was simply not much of a concern in practice. Why? Because practitioners have ""a rich mixture of strategies"" for dealing with that.What didn't I like about this book? It leaped precipitously into the interview results without setting sufficient context for them. Tables of fascinating data were often difficult to read because they weren't sufficiently well captioned. Discussions of interview after interview tended to get repetitious. Odd discrepancies, like saying there were 30 project manager subjects when there were apparently really 34, and saying the study analyzed 32 ""constructs"" when the tables contained 34.Non-American expressions (they added a nice Irish context, however!) like ""carry the can,"" and ""sussing out,"" and ""horses for courses.And two perhaps more serious weaknesses. The managers were discussing a collection of projects which ranged in size from one to six people, too close to ""toy"" projects to be terribly useful in the larger-project world.And the managers were all positioned with companies in Ireland (the author makes a nice argument for why that may not be terribly important, however).On balance, do I like this book? Yes, strongly. This is one of those ""and now for something completely different"" books that really adds a worthwhile dimension to the (often boring!) IS/IT project management literature.",2002-06,2022-09-02T13:29:41Z,2022-09-02T13:29:41Z,NA,7–8,NA,2,33,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,YMGXF2LI,conferencePaper,2020,"Soliman, Mohamed A.; Antova, Lyublena; Sugiyama, Marc; Duller, Michael; Aleyasen, Amirhossein; Mitra, Gourab; Abdelhamid, Ehab; Morcos, Mark; Gage, Michele; Korablev, Dmitri; Waas, Florian M.",A Framework for Emulating Database Operations in Cloud Data Warehouses,Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data,978-1-4503-6735-6,NA,10.1145/3318464.3386128,https://doi.org/10.1145/3318464.3386128,"In recent years, increased interest in cloud-based data warehousing technologies has emerged with many enterprises moving away from on-premise data warehousing solutions. The incentives for adopting cloud data warehousing technologies are many: cost-cutting, on-demand pricing, offloading data centers, unlimited hardware resources, built-in disaster recovery, to name a few. There is inherent difference in the language surface and feature sets of on-premise and cloud data warehousing solutions. This could range from subtle syntactic and semantic differences, with potentially big impact on result correctness, to complete features that exist in one system but are missing in other systems. While there have been some efforts to help automate the migration of on-premise applications to new cloud environments, a major challenge that slows down the migration pace is the handling of features not yet supported, or partially supported, by the cloud technologies. In this paper we build on our earlier work in adaptive data virtualization and present novel techniques that allow running applications utilizing sophisticated database features within foreign query engines lacking the native support of such features. In particular, we introduce a framework to manage discrepancy of metadata across heterogeneous query engines, and various mechanisms to emulate database applications code in cloud environments without any need to rewrite or change the application code.",2020,2022-09-02T13:29:41Z,2022-09-02T13:29:41Z,NA,1447–1461,NA,NA,NA,NA,NA,NA,SIGMOD '20,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Portland, OR, USA",NA,NA,NA,query processing; cloud data warehousing; data warehousing; database emulation; database migration; metadata management; query rewriting,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,MSPAGN3E,conferencePaper,2017,"Hayashi, Hideki; Ogawa, Yuichi; Sugaya, Natsuko; Asahara, Akinori; Tomita, Hitoshi",Stream Geo-Location Data Processing for Detecting Rescuers in a Large-Scale Disaster,Proceedings of the 3rd ACM SIGSPATIAL Workshop on Emergency Management Using,978-1-4503-5493-6,NA,10.1145/3152465.3154400,https://doi.org/10.1145/3152465.3154400,"In a large-scale disaster, it is important for rescue workers to quickly grasp the disaster situation that changes from moment to moment on rescue activities in the field. In this study, we focused on large-scale stream geo-location data sequentially collected by moving sensors such as smartphones. Then we developed a technology which can send a notice to external systems in real-time when the distance between the two streams data becomes closer. In a scenario of Tokyo Inland Earthquake, we assumed one million stream data items must be processed in 5 minutes and our evaluation showed that our proposed method can achieve it.",2017,2022-09-02T13:29:41Z,2022-09-02T13:29:41Z,NA,NA,NA,NA,NA,NA,NA,NA,EM-GIS'17,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Redondo Beach, CA, USA",NA,NA,NA,stream data; real-time; disaster management; location data; mobile,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,PCAM5AKN,conferencePaper,1989,"Natchez, M.; Prose, T.",Creating Effective Hypercard Online Documentation and Training,Proceedings of the 7th Annual International Conference on Systems Documentation,0-89791-337-X,NA,10.1145/74311.74318,https://doi.org/10.1145/74311.74318,"In recent years, the “hypers” have made a strong impact on technical communication. Hypertext and hypermedia applications have shown that it is possible to communicate information in user-defined, non-linear ways, taking advantage of multiple sources and delivery mechanisms. HyperCard is a particular application, written by Bill Atkinson and packaged with every Macintosh computer, that provides a structure for creating an easy-to-use, interactive learning experience that can easily combine text, graphics, sound, animation, and even video-taped segments. Depending on the design of the application, users can proceed sequentially along a predefined path, or jump between topics of interest.For example, rather than giving a student a manual that starts at page one and goes sequentially through the range of material, the instructor or technical writer gathers relevant material, enters it on-line, and provides indexes or menus for students to direct their own learning. Material may be graphic, audio, text-based, animated, interactive, or any combination of the above. This creates a tremendous variety in the learning system and lets the user determine the most relevant path through it.With the advent of this type of application, however, writers, trainers, and program developers face new problems in design. These problems include envisioning the overall design of the application, designing effective mapping techniques, streamlining text, creating consistent screens and metaphors, creating guideposts for the user, and planning the effective use of sound, animation, and graphics. This paper addresses these problems and offers guidelines and solutions. We will cover strategies for planning and development of HyperCard projects, and explore two case studies: one, turning a brochure into a HyperCard presentation; the other, designing a HyperCard troubleshooting guide for mainframe operations. While the examples used focus on HyperCard, the instructional design precepts behind them are applicable to any hypermedia presentation.In the flash and dazzle of the new technology it is important to integrate basic writing and instructional design theory. These are all the more critical because they are often neglected. Right now, when technology is changing so rapidly, we tend to be seduced by the newest and most exciting video laser displays, touch screen presentations, and animated screens, and forget that a poorly designed or executed presentation is equally ineffective in whatever medium it is presented.The first step for any project, HyperCard or not, is to perform a needs assessment. If you are unfamiliar with this term, a needs assessment is the determination of who your audience is and what they need. To perform the assessment, you interview the people who know, you interview the people who are going to need to know, and you determine the best way to get the information from one to the other. Identifying your audience and what they need to learn is the first step in any instructional design, and there are several excellent references on this process listed in the bibliography.Next, you must determine whether a specific project will translate effectively into a HyperCard application. The material that works best in HyperCard is subject matter that can be broken down into fairly discrete segments. On-screen reading does not work for long pages of text, so you have be able to convey meaning in a few paragraphs or less. Can this information be assembled in a series of paragraphs that can be linked together by a road map? If so, HyperCard is a viable alternative. Some examples of information that translates well are troubleshooting procedures, brochures, advertising material, orientations, maps, and job aides. The subject can be large — even encyclopedic — as long as it can be broken down into manageable subject areas. Job aids translate well to HyperCard because typically, you are dealing with particular job functions that you can document and show on-screen in a lively and engaging way. You can convey the information before the user gives up on reading the screen.Marketing presentations can translate into powerful hypermedia presentations, because you are trying to present the features of a product or a service in an eye-catching way. These images can be conveyed more easily with pictures, sound, music, and short bursts of text than they can be on a one-dimensional page that someone is likely to throw into the trash.We have worked on projects to translate reference manuals into HyperCard. These can translate effectively because the essential focus of a reference manual is: first, find the information you need; and second, describe it as briefly as application can be implemented here, as long as text is kept to a maximum of three screens per topic. The reader is not interested in the entire reference manual, but rather in one specific piece of information at a time, and then perhaps related subjects.Another type of presentation that translates well is one that requires the user to move in a more structured way with alternate paths. For example, in troubleshooting you have to go from step one to step two to step x, with the progression depending on the problems encountered and the previous response. It is easy to miss a procedure on a page, or to get confused as to the next step. By putting the troubleshooting into a HyperCard application, where you can click and change from step one to step two, you encourage the user to focus on each section of the presentation separately. You also have a natural decision-based branching mechanism. These enhance the presentation.Projects that do not lend themselves to HyperCard presentation include most scientific articles, theoretical discussions, and abstract concepts. These do not work in the kind of “burst of information” environment that HyperCard provides. Translating an ordinary book to HyperCard generally is not a good idea. Philosophy, detailed technical information, or novels are not natural projects for HyperCard.Once you have determined that a project will benefit from presentation in HyperCard, you should turn your attention to mapping the project and determining how the user is going to access the information. This is the problem of providing structure so that the user does not get lost. You need to keep the structure flexible, but you also need to make your information accessible sequentially when appropriate. It is important to keep in mind that there are many types of learners. The application must be available not only to independent thinking, creative people, but also to those of us who like to go through learning processes in a more structured and orderly fashion.Mapping the application is the first job. It requires a clear overview of your objectives, how you envision the user interacting with your material, and what the nature of the logical links between subjects. The more thorough the mapping process, the more satisfactory the end result. It is here that basic instructional design rules can help. Define your objectives and your methodology. Then map your material in as simple and straightforward a manner as possible. Any “flash” comes later, when you enhance the presentation. Figure 1 shows a sample HyperCard application map.The map shows how the user will access various topics covered in the application. In the example shown, the application includes basic operations troubleshooting procedures and background information on the computer system. There is a startup screen, with an optional introduction to the Macintosh. Then the Main Menu appears. From there, users can select individual topics, returning to the menu at the completion of a topic, or go to an index/glossary, for a definition of a term or concept. They can move to a related procedure, or see how a component fits into the system configuration when appropriate. Access to specific procedures is also available by looking up an error message or symptom or by looking at a map of the system, selecting a component. Users are then directed to the related procedure. This allows access by concept, by error message, by symptom, by visual overview, or by procedure.In addition to this initial map for developing the application, you must also build in maps and guideposts to help users navigate easily to the information they want. These range from the simple (forward and backward arrows, a return symbol to return to the starting menu) to the more complex (specific icons, imbedded maps, menu bars, webbed views). They are all designed to help users determine their current position and where to go next. For example, you might place a “where am I” button in the lower right hand corner of the screen. When users click this button they can get an overview of where they have come from, and where they can go. You can go up or down several levels by clicking further. This is a very effective mapping technique. Another technique is to provide a consistent menu bar that gives simple choices such as: go back one, back to start (start meaning point of entry), and index. An sample of this type of menu bar and index is shown in figure 2:Bookmarks are another excellent technique for helping the users find their way around. A bookmark is a way users can say, “save my place, go to somewhere else, and then return.” A web view of the application is also very helpful. A web view is an asymmetrical picture or web of related topics and where they might lead. It gives the user a feel for how the current text is linked to other topics in the application. Another proven navigation tool is a browser. This is a map of the hard links that you have created so the user can quickly see where the logical connectors are going. The browser enables users to see the direction you had in mind in the design of the application. They can then choose whether or not to follow that path.A filter is a more sophisticated mapping tool. With a filter, users can set conditions or choose conditions from a list, and then view a display of topics that correspond to these criteria. This creates a subset of topics from the data base of available material.Indexes are still an excellent way to find information. Many of on-line help systems use them for that reason and they're also effective for HyperCard. Whatever techniques you choose, well-designed navigation for the user is of critical importance to the success of the application. When you have chosen your approach, you must then map a logical flow from several perspectives. You have to create hard links so that the user who doesn't want to explore without a guide can explore the application in a guided fashion.Specific icons to represent topics or areas are also helpful. For example, in a complex procedure with a section on loading tape drives, on CPU commands, and on disc commands, you might have a representative icon for tapes, CPUs and discs. When users are in the CPU procedure, they could click on the tape icon to return to the tape drive procedure, or on the disc icon to go to a procedure for disc drives.The idea of icons brings us to the question of metaphor in general. In selecting images for icons, graphic illustrations, or concepts, it is important to keep imagery simple, logical, and consistent. At the simplest level, if you decide to use forward and backward arrows, they should always be the same arrows, in the same area of the screen. The appropriate icons should be identified and maintained throughout the application, and they should work in a logical way, a way that makes intuitive sense. For example, if you have chosen the image of a VCR control panel as a navigation tool, then the buttons should function in the same way as a real VCR.Consistency is also important in the layout of the screen…Consistent screen design provides a high comfort level for the user. This does not mean that you should only have one screen pattern for every display, but you might have five or six basic patterns and then add to these, repeat them, vary them, add animation, add sound, change, fade, scroll, etc. However you enhance them, the basic patterns, like the road maps, provide a framework for the user. You should try to have a consistent area for instruction, for feedback, and for navigation, so users always know where to look for specific information.The design of the screen is also very important. It is not possible to cover all the principles of screen design in this presentation; screen design is a field in itself. But there are some basics to keep in mind. First, you should have plenty of white space on your screen, never less than 20% is the rule for the page, never less than 30% is a good rule for on-screen presentations. This helps the user focus on the text.Another basic rule is to use both upper and lower case letters for text; the eye can easily distinguish patterns in letters that are upper and lower case. Use all capitals only for emphasis. X-height of fonts is also important. X-height is the distance from the bottom of a letter to the top of the lower case letter. A font with a low x-height, like Times, is harder to read on-screen than a font with a tall x-height, like Stuttgart. In general, use fonts between 12 and 18 points for best onscreen readability - occasionally larger for titles or, very rarely, smaller for notes. Let's look at several screen examples to illustrate some effective designs. (Screen examples will be shown and discussed here.)Writing style for HyperCard is another important area. Technical writing can be oppressively convoluted and scholarly. This is something you must avoid in HyperCard presentations. Writing for HyperCard must be clear, direct, and pared down. It needs to have a punch to it — active voice, imperative verbs, short sentences, and very specific words. Especially for HyperCard, good writing is clear writing. You should be able to understand the words as quickly as your eye can read them, and text should convey information in as few words as possible.For example, you could change, “You should try to avoid using long, involuted sentences in your presentation” to “use short, clear sentences in your presentation.” When possible, use the font and style capabilities of the Macintosh to pare down your sentences. For example, instead of “If you want to choose open from the file menu, move to the file menu, pull it down, and choose open.” You might write, “To open a file, from the File menu, select Open.” This makes use of fonts to clarify your point and uses about half the number of words.Use plenty of examples - graphic examples where possible. HyperCard lends itself to visual presentations, so exploit this capability. If you can say it in a picture, don't say it with words. Good graphics greatly enhance HyperCard. Any place where a picture will convey an idea, you can use a picture to enhance the text. You can use libraries of existing graphics or scan in custom or existing graphics.The final area we will discuss is the inclusion of animation and sound. The first rule here is “less is better.” Cuteness or pizzazz, which are the basic functions of animation and sound, are wonderful enhancements to presentations. However, they are wearing as a steady diet. There are two very effective ways you can this technique in your presentations. One is to illustrate how to perform an activity. You can use an animated presentation: move to this, press this, and this happens. Another way is to use an animated display for entertainment, to add a little whimsicality to the presentation. You may have seen the demo of a camera with various shutter speeds taking photos with different exposures. This makes a point in a charming way with animation, and is very effective in small doses.In the same way, sound can capture the ear, focus the user, simulate an event, or provide a background. If you are using background music, it should be unobtrusive, and in line with the tone of your presentation. I would never recommend that you use music as a background for an entire presentation, but only for portions. For example, in one of the case studies we are going to look at, we had an automated tour of several topics. During the automated presentation we used a musical background. If you decided not to take what we called the “guided tour,”but to find your way through the presentation yourself, there was no music. The music was there to keep you engaged while things were happening on the screen.With that, we will review the case studies, and talk a little about them. We will use our checklists to evaluate the presentations and their success or lack of success, and learn from the presentations themselves.*In conclusion, I want to summarize the points we have discussed here. We opened this presentation with overall management concerns. We presented guidelines for projects to determine which should or should not be attempted in the HyperCard environment. Once we determined that a project would benefit from presentation in HyperCard, we discussed the steps necessary to plan for and organize the development of this application.We discussed mapping techniques, and methods to keep the user from getting lost or feeling overwhelmed by this new environment and strategies for helping the user navigate through an application. We discussed how to build these keys into the original application design. We discussed the importance of consistency for icons, metaphors, and screen layout, and discussed basic criteria for good screen design.We also explored HyperCard writing techniques, focusing on how to pare the writing down to the minimum necessary to convey meaning. We discussed how to present text in ways that make it memorable in a screen environment, as opposed to designing for the page. Finally, we discussed the use of sound, animation, and graphics, and how these can be used to accent a presentation.We demonstrated two case studies, evaluated them according to a checklist, and discussed user reactions to the case studies, and what was learned from user feedback. Our belief is that thoughtful selection and planning can lead to excellent HyperCard applications.",1989,2022-09-02T13:29:41Z,2022-09-02T13:29:41Z,NA,41–44,NA,NA,NA,NA,NA,NA,SIGDOC '89,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Pittsburg, Pennsylvania, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,R4YQPNV5,conferencePaper,2014,"Roy, Pooja; Manoharan, Manmohan; Wong, Weng Fai",EnVM: Virtual Memory Design for New Memory Architectures,"Proceedings of the 2014 International Conference on Compilers, Architecture and Synthesis for Embedded Systems",978-1-4503-3050-3,NA,10.1145/2656106.2656121,https://doi.org/10.1145/2656106.2656121,"Virtual memory is optimized for SRAM-based memory devices in which memory accesses are symmetric, i.e., the latency of read and write accesses are similar. Unfortunately, with the emergence of newer non-volatile memory (NVM) technologies that are denser and more energy efficient, this assumption is no longer valid. For example, STT-RAMs are known to have high write latencies and limited write endurance which the virtual memory is unaware of. A popular architecture is a hybrid cache that uses both SRAM and NVM. There are a number of proposals for such architectures at nearly all the levels of the cache. However, these proposals are often self-contained with monitoring and management schemes implemented with special hardware at the level where the cache is deployed. With moves to use NVM at several levels of the memory hierarchy, such solutions may lead to duplication and higher overheads. Worse, because the management algorithms implemented can be different at different levels of memory, it may lead to negative interference between them resulting in impaired efficiency.In this paper, we propose a virtual memory design, EnVM, that takes into consideration the idiosyncrasies of NVM-based hybrid caches. The new virtual memory layout is implicitly used to allocate data to NVM and SRAM at any level of the memory hierarchy and is not dependant on the particular arrangements of the two partitions. The proposed design successfully filters out write operations and allocates them to SRAM. Moreover, it can be applied to any existing fine-grained data allocation technique to enhance the efficiency of these memories.",2014,2022-09-02T13:29:41Z,2022-09-02T13:29:41Z,NA,NA,NA,NA,NA,NA,NA,NA,CASES '14,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: New Delhi, India",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,N9WPRLQJ,journalArticle,2008,"Stafford, Tom; Chau, Patrick Y.K.",Letter from the Editors,SIGMIS Database,NA,0095-0033,10.1145/1341971.1341972,https://doi.org/10.1145/1341971.1341972,"Greetings, Scholars! Welcome to another issue of Data Base.In this issue, we are happy to present the leading edge work of well-known colleagues on topics of importance to both the discipline and our society. Trauth and her colleagues, in continuing a tradition of inquiry into women's issues in the IT profession, provide a study of factors influencing the under-representation of women in the IT practice. This study is carried forward through the lens of regional economic influences and the environmental factors that impact these economies and the employment trends within themGuzman, Stam, and Stanton investigate the IT culture in organizations. Their view that IT workers have their own subsection of corporate culture is quite interesting, and explains much of the differences that have heretofore been anecdotally accounted for between the IT professionals in companies and their colleagues in other functional areas of the firm. That the cultural differences between IT workers and other employees of the firm could lead to potential conflicts is not surprising, but the study provides us with the basis for understanding how the situation can be remediated, providing an excellent focus for future research on organizational subculturesOcker and Fjermestad study the interactions between members of virtual design teams in this issue. The focal point of their investigation regards the influences of asynchronous communications between teams, and they analyze differences between differing levels of team performance. This topic will be increasingly important in the world of outsourcing, where design team members interact across large geographical distances.Watch these pages for interesting global developments to come! With the able guidance of Global Co-Editor Patrick Chau, we have top papers headed our way from the Chinese AIS chapter meeting, from the Pacific association meeting, and other corners of the increasingly wired world. We'll also be bringing you leading edge thinking on important technical topics such as systems testing in future issues. Meantime, please visit our online global publishing portal at http://www.editorialmanager.com/sigmisdb/ and register yourself as a participant in our fine publication. We're eager to see your best work in our pages, and welcome your contributions. It's just one click of the mouse awayAs we've progressed through the past several issues, we've added new members to our Editorial Staff, and said farewell to departing members who've moved on to other responsibilities. Notably, we're grateful to Detmar Straub for his long-term contribution to Data Base; he departs to take the editorship of another leading journal in our field, and we offer him our thanks, gratitude and a heart-felt ""Godspeed"" as he takes this important new step. We're pleased to have new members join us to increase our global presence and theoretical diversity, including Laku Chidambaram, Phillip Ein-Dor, George Marakas, Paul Pavlou, and Hock Hai Teo. As of this issue we also bid farewell to Technical Editor Clint Lanier and welcome Professor Loel Kim to the position for her first issue as Data Base Technical Editor",2008-01,2022-09-02T13:29:41Z,2022-09-02T13:29:41Z,NA,4,NA,1,39,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,Z8L5W95A,journalArticle,1995,"Van House, Nancy",UC Berkeley's NSF/ARPA/NASA Digital Libraries Project,SIGOIS Bull.,NA,0894-0819,10.1145/226188.226199,https://doi.org/10.1145/226188.226199,"The UC Berkeley Electronic Environmental Library Project is a multi-disciplinary project funded under the NSF/NASA/ARPA Digital Libraries Initiative. The goal is to develop a massive, distributed, electronic, work-centered library of environmental information containing text, images, maps, sound, full-motion videos, numeric datasets, and hypertextual multimedia composite documents to support actual environmental planning decisions.By work-centered, we mean a digital library designed to support the work of the users, in this case, environmental planning. The users are from diverse organizations, 'united by their goal of environmental planning. This project is unusual among digital library research projects in this focus on information in support of public policymaking. The potential users and uses of the system are extremely varied and the applications are complex and of substantial practical significance.Our primary goals are to provide a coherent, content-based view of a diverse distributed collection which will scale to very large collections and large numbers of clients and servers, and to improve data acquisition technology. The project is addressing these problems by research focusing on:• New paradigms of user-system interaction;• Fully automated indexing and intelligent retrieval;• Data base technology to support electronic library applications;• A more effect protocol for client/server information retrieval;• Resources discovery and distributed search algorithms;• A communications-theoretic approach to document analysis;• Compression and communication for remote browsing;• New methods of user needs assessment and evaluation.The testbed consists of the diverse information types and media that are used in environmental planning. The data range from unprocessed sensor data through many levels of analysis and synthesis to policy recommendations and decision. The media include text, images, maps, and geo-referenced datasets, in paper and electronic forms. The initial focus has been water planning for the San Francisco Bay Delta; currently we are broadening our scope to other geographical areas. The target users are the participants in environmental planning employees of state agencies, but also people in local and federal agencies, environmental and industry groups, and the public.",1995-12,2022-09-02T13:29:41Z,2022-09-02T13:29:41Z,NA,18–19,NA,2,16,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,YRX9KTRE,conferencePaper,2021,"Fenton, Kevin; Simske, Steven","Engineering of an Artificial Intelligence Safety Data Sheet Document Processing System for Environmental, Health, and Safety Compliance",Proceedings of the 21st ACM Symposium on Document Engineering,978-1-4503-8596-1,NA,10.1145/3469096.3474933,https://doi.org/10.1145/3469096.3474933,"Chemical Safety Data Sheets (SDS) are the primary method by which chemical manufacturers communicate the ingredients and hazards of their products to the public. These SDSs are used for a wide variety of purposes ranging from environmental calculations to occupational health assessments to emergency response measures. Although a few companies have provided direct digital data transfer platforms using xml or equivalent schemata, the vast majority of chemical ingredient and hazard communication to product users still occurs through the use of millions of PDF documents that are largely loaded through manual data entry into downstream user databases. This research focuses on the reverse engineering of SDS document types to adapt to various layouts and the harnessing of meta-algorithmic and neural network approaches to provide a means of moving industrial institutions towards a digital universal SDS processing methodology. The complexities of SDS documents including the lack of format standardization, text and image combinations, and multi-lingual translation needs, combined, limit the accuracy and precision of optical character recognition tools.The approach in this document is to translate entire SDSs from thousands of chemical vendors, each with distinct formatting, to machine-encoded text with a high degree of accuracy and precision. Then the system will ""read"" and assess these documents as a human would; that is, ensuring that the documents are compliant, determining whether chemical formulations have changed, ensuring reported values are within expected thresholds, and comparing them to similar products for more environmentally friendly alternatives.",2021,2022-09-02T13:29:42Z,2022-09-02T13:29:42Z,NA,NA,NA,NA,NA,NA,NA,NA,DocEng '21,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Limerick, Ireland",NA,NA,NA,neural networks; validation; optical character recognition; EHS compliance; meta-algorithmics; safety data sheets,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,NCLEQWSY,conferencePaper,2004,"Ahuja, Manju; Robinson, Jean; Herring, Susan; Ogan, Chris",Exploring Antecedents of Gender Equitable Outcomes in IT Higher Education,"Proceedings of the 2004 SIGMIS Conference on Computer Personnel Research: Careers, Culture, and Ethics in a Networked Environment",1-58113-847-4,NA,10.1145/982372.982401,https://doi.org/10.1145/982372.982401,"This research-in-progress paper reports on a National Science Foundation funded project aimed at examining ways to engage women and girls in courses of study that will qualify and motivate them for information technology (IT)-related careers. This Information Technology Work Force (ITWF) award provides support to investigate 15 tertiary education programs in information systems, information science, instructional systems technology, and informatics, with computer science programs as a baseline comparison, in five major IT degree-granting institutions. The purpose of the study is to systematically investigate the contribution of organizational culture to student experiences and outcomes, determining factors that favor female success over time.The programs are hypothesized to be differentially responsive to female students due to differences in academic culture, operationalized in terms of the availability of mentorship, role models, peer support networks, grant programs, and other resources at the departmental, university, and disciplinary levels. These measures of organizational culture will be correlated with measures of student outcomes and self-reports of student experiences. Data about students' experiences will be collected through a web-based survey of a sample of 5,000 students, followed by three face-to-face interviews with an estimated 155 students, over-sampling for females, over a two-year period. In addition, faculty, administrators and staff in the study programs will be interviewed by telephone and in person. Student survey data will be collected by April 2004 and analyzed by May 2004.At the conference, we will report preliminary findings based on analysis of data collected from our pilot site (Indiana University).The project will identify encouraging and discouraging factors, and produce comparative statistics, that can be used as a baseline in future research on IT education and gender. Findings can be used to inform programmatic recommendations aimed at moving more women into the IT pipeline through a diverse range of educational programs. To the extent that new IT paradigms such as are taught in schools of information, informatics, education, and business help to create those cultural associations, they can contribute to reducing the persistent gender segregation in academic IT-related programs and thus IT employment.",2004,2022-09-02T13:29:42Z,2022-09-02T13:29:42Z,NA,120–123,NA,NA,NA,NA,NA,NA,SIGMIS CPR '04,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Tucson, AZ, USA",NA,NA,NA,information science; gender; information technology; computer science; enrollments; informatics; mentoring; retention; work-life balance; workforce,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,3N2FYM4G,journalArticle,2018,"Metaxa-Kakavouli, Danaë; Maas, Paige; Aldrich, Daniel P.",How Social Ties Influence Hurricane Evacuation Behavior,Proc. ACM Hum.-Comput. Interact.,NA,NA,10.1145/3274391,https://doi.org/10.1145/3274391,"Natural disasters bring enormous costs every year, both in terms of lives and materials. Evacuation from potentially affected areas stands out among the most critical factors that can reduce mortality and vulnerability to crisis. We know surprisingly little about the factors that drive this important and often life-saving behavior, though recent work has suggested that social capital may play a critical and previously underestimated role in natural disaster preparedness. Moving beyond retrospective self-reporting and vehicle count estimates, we use social media data from a large number of Facebook users to examine connections between levels of social capital and evacuation behavior. This work is the first of its kind, examining these phenomena across three major U.S. disasters-Hurricane Harvey, Hurricane Irma, and Hurricane Maria-with data on over 1.5 million social media users. Our analysis confirms that, holding confounding factors constant, several aspects of social capital are correlated with whether or not an individual evacuates. Higher levels of bridging and linking social ties correlate strongly with evacuation. However, these social capital related factors are not significantly associated with the rate of return after evacuation.",2018-11,2022-09-02T13:29:42Z,2022-09-02T13:29:42Z,NA,NA,NA,CSCW,2,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,social networks; crisis informatics; hurricane evacuation; social capital,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,6ESPHASV,conferencePaper,1984,"Barnetson, Paul",Frangere..Decision Support in Many Dimensions or..How to Break the Old Spread Sheet Approach,Proceedings of the International Conference on APL,0-89791-137-7,NA,10.1145/800058.801069,https://doi.org/10.1145/800058.801069,"This paper describes FRANGERE, IBM's new technique for providing decision support for the planning and control process. It provides management information from a multi-dimensional data structure which the user can view, along any dimensions, as a series of 'pages' or spread-sheets. The information in this structure can be summarised upwards, 'broken back' downwards, or moved sideways, between files on different computers and in different parts of the world. In addition, the planning information in this multi-dimensional structure can be compared with the 'actual' figures held elsewhere on computer files, and in totally different formats. The package provides full-screen support on coloured screens, full system 'help' facilities, and understandable error messages. It provides a large set of pictorial and tabular reports and is a system which the new user can grow into gradually, learning the more advanced facilities at a speed that matches his desires.",1984,2022-09-02T13:29:42Z,2022-09-02T13:29:42Z,NA,1–10,NA,NA,NA,NA,NA,NA,APL '84,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,event-place: Finland,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,IQ7K8Z9U,journalArticle,1984,"Barnetson, Paul",Frangere..Decision Support in Many Dimensions or..How to Break the Old Spread Sheet Approach,SIGAPL APL Quote Quad,NA,0163-6006,10.1145/384283.801069,https://doi.org/10.1145/384283.801069,"This paper describes FRANGERE, IBM's new technique for providing decision support for the planning and control process. It provides management information from a multi-dimensional data structure which the user can view, along any dimensions, as a series of 'pages' or spread-sheets. The information in this structure can be summarised upwards, 'broken back' downwards, or moved sideways, between files on different computers and in different parts of the world. In addition, the planning information in this multi-dimensional structure can be compared with the 'actual' figures held elsewhere on computer files, and in totally different formats. The package provides full-screen support on coloured screens, full system 'help' facilities, and understandable error messages. It provides a large set of pictorial and tabular reports and is a system which the new user can grow into gradually, learning the more advanced facilities at a speed that matches his desires.",1984-06,2022-09-02T13:29:42Z,2022-09-02T13:29:42Z,NA,1–10,NA,4,14,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,6AC92JBM,conferencePaper,2022,"Diller, Jonathan; Hall, Peter; Schanker, Corey; Ung, Kristen; Belous, Philip; Russell, Peter; Han, Qi",ICCSwarm: A Framework for Integrated Communication and Control in UAV Swarms,"Proceedings of the Eighth Workshop on Micro Aerial Vehicle Networks, Systems, and Applications",978-1-4503-9405-5,NA,10.1145/3539493.3539579,https://doi.org/10.1145/3539493.3539579,"Swarms of Unmanned Aerial Vehicles (UAVs) have many applications including search and rescue, disaster response, surveillance, infrastructure inspection, among many others. A key aspect of UAV swarms is keeping the UAVs connected through wireless communication and any deployment of UAV swarms must consider communication constraints during motion planning. In this paper we introduce textitICCSwarm, a framework for integrating communication and control in UAV swarms. textitICCSwarm consists of two phases, a planning phase where combined communication and motion planning are validated in simulation, and a deployment phase, where a UAV architecture designed around integrated communication and control executes missions from the planning phase on physical UAVs. We implemented textitICCSwarm on a physical UAV testbed and evaluated its effectiveness through a unique case study in partnership with NASA's JPL. We deployed the UAVs to trial small satellite orbits for data collection on asteroids and the results validate our design and highlight textitICCSwarm's capabilities.",2022,2022-09-02T13:29:42Z,2022-09-02T13:29:42Z,NA,1–6,NA,NA,NA,NA,NA,NA,DroNet '22,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Portland, OR, USA",NA,NA,NA,autonomous UAVs; UAV data collection; UAV networks; UAV swarm,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,G6MGHW6K,conferencePaper,2019,"Dixon, Barnali; Johns, Rebecca",Vision for a Holistic Smart City-HSC: Integrating Resiliency Framework via Crowdsourced Community Resiliency Information System (CRIS),Proceedings of the 2nd ACM SIGSPATIAL International Workshop on Advances on Resilient and Intelligent Cities,978-1-4503-6954-1,NA,10.1145/3356395.3365541,https://doi.org/10.1145/3356395.3365541,"This vision paper discusses future directions and existing gaps in integrating smart city initiatives with resilience frameworks. It proposes the use of a multi-modular crowdsourced Community Resiliency Information System (CRIS) to overcome traditional smart citiesâĂŹ focus on infrastructure and grid vulnerabilities/resiliency while overlooking socio-economic vulnerabilities. CRIS is conceptualized based on our previous research which identified the importance of customized information and targeted resources to foster preparedness, adaptation and resiliency among diverse communities. Our proposed vision of a smart city integrated with CRIS allows scalable and customizable solutions for policymakers using information generated âĂŸby the peopleâĂŹ, thus ensuring participation of diverse communities in smart city technology, thus creating a Holistic Smart City (HSC).CRIS will foster a two-way communication between government and communities by creating a grassroots, community-based, technology-enhanced needs assessment and disaster-response information system. Among other benefits, CRIS will generate and organize data to be used by the local community and policy makers and foster ongoing dialogue between neighborhoods and policymakers. CRIS will foster social capital at the neighborhood level by increasing grassroots knowledge and access to resources and information, fostering preparedness, adaptation, and resiliency/recovery, and aiding decision-makers in resource allocation and customized communications. CRIS moves the smart city beyond a mere infrastructure to create an interactive space for information exchange, democratic participation and a collaborative resilience-building process.",2019,2022-09-02T13:29:42Z,2022-09-02T13:29:42Z,NA,1–4,NA,NA,NA,NA,NA,NA,ARIC'19,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Chicago, IL, USA",NA,NA,NA,GIS; Community engagement; Crowdsourced; Integrated Decision Support System,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,BRF52DDL,conferencePaper,2019,"Gaide, Brian; Gaitonde, Dinesh; Ravishankar, Chirag; Bauer, Trevor",Xilinx Adaptive Compute Acceleration Platform: VersalTM Architecture,Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays,978-1-4503-6137-8,NA,10.1145/3289602.3293906,https://doi.org/10.1145/3289602.3293906,"In this paper we describe Xilinx's Versal-Adaptive Compute Acceleration Platform (ACAP). ACAP is a hybrid compute platform that tightly integrates traditional FPGA programmable fabric, software programmable processors and software programmable accelerator engines. ACAP improves over the programmability of traditional reconfigurable platforms by introducing newer compute models in the form of software programmable accelerators and by separating out the data movement architecture from the compute architecture. The Versal architecture includes a host of new capabilities, including a chip-pervasive programmable Network-on-Chip (NoC), Imux Registers, compute shell, more advanced SSIT, adaptive deskew of global clocks, faster configuration, and other new programmable elements as well as enhancements to the CLB and interconnect. We discuss these architectural developments and highlight their key motivations and differences in relation to traditional FPGA architectures.",2019,2022-09-02T13:29:46Z,2022-09-02T13:29:46Z,NA,84–93,NA,NA,NA,NA,NA,NA,FPGA '19,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Seaside, CA, USA",NA,NA,NA,acap; adaptable compute acceleration platform; fpga; fpga architecture; fpga cad; math engine; noc; ssit; stacked silicon; versal; xilinx,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,NEUZMYMP,conferencePaper,2021,"Zhang, Yu; Yang, Yang; Sun, Qiyue; Huang, Dong",Sleep Quality Evaluation System Based On Video Surveillance,"Proceedings of the 5th International Conference on High Performance Compilation, Computing and Communications",978-1-4503-8964-8,NA,10.1145/3471274.3471281,https://doi.org/10.1145/3471274.3471281,"Sleep quality evaluation without interference is of great importance for improving human health and reducing the occurrence of various risks. This paper simulates the 100-day sleep video data set of the observed object. Digital image processing method is used to realize the detection function of going to bed, getting up, turning over and other activities By drawing a sleep curve for one day, and then calculating the number of turns over a day, the duration of sleep, and judging the quality of sleep according to parameters such as the number of waking up, the number of turns over, the duration of sleep, and finally the abnormality detection by comparing the similarity of the curves over multiple days. This paper aims to make use of automatic detection of sleep conditions to make intelligent video surveillance play a greater role in human sleep quality.",2021,2022-09-02T13:29:47Z,2022-09-02T13:29:47Z,NA,37–43,NA,NA,NA,NA,NA,NA,HP3C '21,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Guangzhou, China",NA,NA,NA,Image processing; Anomaly detection; Video surveillance; Similarity measurement; Sleep quality evaluation,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,47XFYS9D,journalArticle,2015,"Chen, Shimin; Jin, Qin",Persistent B+-Trees in Non-Volatile Main Memory,Proc. VLDB Endow.,NA,2150-8097,10.14778/2752939.2752947,https://doi.org/10.14778/2752939.2752947,"Computer systems in the near future are expected to have <u>N</u>on-<u>V</u>olatile <u>M</u>ain <u>M</u>emory (NVMM), enabled by a new generation of <u>N</u>on-<u>V</u>olatile <u>M</u>emory (NVM) technologies, such as Phase Change Memory (PCM), STT-MRAM, and Memristor. The non-volatility property has the promise to persist in-memory data structures for instantaneous failure recovery. However, realizing such promise requires a careful design to ensure that in-memory data structures are in known consistent states after failures.This paper studies persistent in-memory B+-Trees as B+-Trees are widely used in database and data-intensive systems. While traditional techniques, such as undo-redo logging and shadowing, support persistent B+-Trees, we find that they incur drastic performance overhead because of extensive NVM writes and CPU cache flush operations. PCM-friendly B+-Trees with unsorted leaf nodes help mediate this issue, but the remaining overhead is still large. In this paper, we propose write atomic B+-Trees (wB+-Trees), a new type of main-memory B+-Trees, that aim to reduce such overhead as much as possible. wB+-Tree nodes employ a small indirect slot array and/or a bitmap so that most insertions and deletions do not require the movement of index entries. In this way, wB+-Trees can achieve node consistency either through atomic writes in the nodes or by redo-only logging. We model fast NVM using DRAM on a real machine and model PCM using a cycle-accurate simulator. Experimental results show that compared with previous persistent B+-Tree solutions, wB+-Trees achieve up to 8.8x speedups on DRAM-like fast NVM and up to 27.1x speedups on PCM for insertions and deletions while maintaining good search performance. Moreover, we replaced Memcached's internal hash index with tree indices. Our real machine Memcached experiments show that wB+-Trees achieve up to 3.8X improvements over previous persistent tree structures with undo-redo logging or shadowing.",2015-02,2022-09-02T13:29:47Z,2022-09-02T13:29:47Z,NA,786–797,NA,7,8,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Publisher: VLDB Endowment,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,AB29L7AB,bookSection,2016,"Wang, Qi; Taylor, John E.",Data-Driven Simulation of Urban Human Mobility Constrained by Natural Disasters,Proceedings of the 2016 Winter Simulation Conference,978-1-5090-4484-9,NA,NA,NA,"Understanding of human movements in urban areas plays a key role in improving our disaster response, evacuation, and relief plans. However, there is a lack of research on human mobility perturbation under the influence of hurricanes. Furthermore, limited simulation studies have had access to empirical human travel data in urban areas during natural disasters. In this paper we developed a computational model to simulate human mobility during the approaching and strike of hurricanes. Inspired by animal movements in a fragmented habitat, we examined human movements in New York City and its adjacent areas during the striking of Hurricane Sandy. Based on the patterns observed, we established a data-driven model to simulate human movements during hurricanes. The model integrated multiple resources of urban informatics including U.S. census data, Twitter data, and Google Maps. The research effort aims to inform policymakers and support decision-making under different emergency situations that can arise during hurricanes.",2016,2022-09-02T13:29:47Z,2022-09-02T13:29:47Z,NA,3357–3364,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,IEEE Press,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,ZDRUGJDC,conferencePaper,2022,"Chen, Juntong; Cai, Hao; Liu, Bo; Yang, Jun",Triple-Skipping near-MRAM Computing Framework for AIoT Era,"Proceedings of the 2022 Conference &amp; Exhibition on Design, Automation &amp; Test in Europe",978-3-9819263-6-1,NA,NA,NA,"Near memory computing (NMC) paradigm shows great significance in non-von Neumann architecture to reduce data movement. The normally-off and instance-on characteristics of spin-transfer torque magnetic random access memory (STT-MRAM) promise energy-efficient storage in the AIoT era. To avoid unnecessary memory-related processing, we propose a novel write-read-calculation triple-skipping (TS) NMC for multiply-accumulate (MAC) operation with minimally modified peripheral circuits. The proposed TS-NMC is evaluated with a custom micro control unit (MCU) in 28-nm high-K metal gate (HKMG) CMOS process and foundry announced universal two-transistor two-magnetic tunnel junction (2T-2MTJ) MRAM cell. The framework consists of a sparse flag which is defined in extra STT-MRAM columns with only 0.73% area overhead, and a calculation block for NMC logic with 9.9% overhead. The TS-NMC can successfully work at 0.6-V supply voltage under 20MHz. This Near-MRAM framework can offer up to 95.6% energy saving compared to commercial SRAM refer to ultra-low-power benchmark (ULP-Benchmark). Classification task on MNIST takes 13nJ/pattern. The energy access of memory, calculation, and the total can be reduced by 52.49×, 2.7×, and 11.3× respectively from the TS scheme.",2022,2022-09-02T13:29:47Z,2022-09-02T13:29:47Z,NA,1401–1406,NA,NA,NA,NA,NA,NA,DATE '22,NA,NA,NA,European Design and Automation Association,"Leuven, BEL",NA,NA,NA,NA,NA,NA,NA,"event-place: Antwerp, Belgium",NA,NA,NA,neural network; STT-MRAM; MAC; AIoT; near memory computing; triple-skipping,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,ZGNSI2K8,conferencePaper,2022,"Feustel, Clayton Ewing; Shu, Nicolas; Clifford, Gari; Anderson, David; Zimring, Craig",Practical High-Fidelity Sensing of the Sleep Environment in the Home,Proceedings of the 15th International Conference on PErvasive Technologies Related to Assistive Environments,978-1-4503-9631-8,NA,10.1145/3529190.3529219,https://doi.org/10.1145/3529190.3529219,"Non-invasive monitoring of the sleep environment can improve health outcomes by capturing the exogenous factors that contribute to sleep disruption. In an aging population, where disturbed sleep is a common occurrence, being able to capture minute changes to the lighting and the sound environment throughout the night is critical to obtaining a more holistic view of sleep behaviors and opportunities for interventions. In order to continuously capture relevant sound and light characteristics in a bedroom environment a robust, low-cost, and scaleable sensing system is needed. Existing systems for capturing the sleep environment are untested, inadequate for permanent placement in the bedroom due to size, or lack detail in the collected acoustic and lighting metrics. This paper describes a low-cost and robust system designed to collect highly accurate environmental light and sound data in a natural home environment at fine temporal resolution. The performance of the sensing modalities was tested and found to closely match simultaneous measurements using industry-standard precision instruments.",2022,2022-09-02T13:29:47Z,2022-09-02T13:29:47Z,NA,155–158,NA,NA,NA,NA,NA,NA,PETRA '22,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Corfu, Greece",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,4EAFZ6CS,conferencePaper,2020,"Bolsens, Ivo",Scalable System and Silicon Architectures to Handle the Workloads of the Post-Moore Era,Proceedings of the 2020 International Symposium on Physical Design,978-1-4503-7091-2,NA,10.1145/3372780.3378166,https://doi.org/10.1145/3372780.3378166,"The end of Moore's law has been proclaimed on many occasions and it's probably safe to say that we are now working in the post-Moore era. But no one is ready to slow down just yet. We can view Gordon Moore's observation on transistor densification as just one aspect of a longer-term underlying technological trend - the Law of Accelerating Returns articulated by Kurzweil. Arguably, companies became somewhat complacent in the Moore era, happy to settle for the gains brought by each new process node. Although we can expect scaling to continue, albeit at a slower pace, the end of Moore's Law delivers a stronger incentive to push other trends of technology progress harder. Some exciting new technologies are now emerging such as multi-chip 3D integration and the introduction of new technologies such as storage-class memory and silicon photonics. Moreover, we are also entering a golden age of computer architecture innovation. One of the key drivers is the pursuit of domain-specific architectures as proclaimed by Turing award winners John Hennessy and David Patterson. A good example is the Xilinx's AI Engine, one of the important features of the Versal? ACAP (adaptive compute acceleration platform) [1]. Today, the explosion of AI workloads is one of the most powerful drivers shifting our attention to find faster ways of moving data into, across, and out of accelerators. Features such as massive parallel processing elements, the use of domain specific accelerators, the dense interconnect between distributed on-chip memories and processing elements, are examples of the ways chip makers are looking beyond scaling to achieve next-generation performance gains. Next, the growing demands of scaling-out hyperscale datacenter applications drive much of the new architecture developments. Given a high diversification of workloads that invoke massive compute and data movement, datacenter architectures are moving away from rigid CPU-centric structures and instead prioritize adaptability and configurability to optimize resources such as memory and connectivity of accelerators assigned to individual workloads. There is no longer a single figure of merit. It's not all about Tera-OPS. Other metrics such as transfers-per-second and latency come to the fore as demands become more real-time; autonomous vehicles being an obvious and important example. Moreover, the transition to 5G will result in solutions that operate across the traditional boundaries between the cloud and edge and embedded platforms that are obviously power-conscious and cost-sensitive. Future workloads will require agile software flows that accommodate the spread of functions across edge and cloud. Another industry megatrend that will drive technology requirements especially in encryption, data storage and communication, is Blockchain. To some, it may already have a bad reputation, tarnished by association with the anarchy of cryptocurrency, but it will be more widely relevant than many of us realize. Who could have foreseen the development of today's Internet when ARPANET first appeared as a simple platform for distributed computing and sending email? Through projects such as the open-source Hyperledger, Blockchain technology could be game-changing as a platform for building trust in transactions executed over the Internet. We may soon be talking in terms of the Trusted Internet. The predictability of Moore's law may have become rather too comfortable and slow. The future requires maximizing the flexibility, agility, and efficiency of new technologies. With Moore's Law now mostly behind us, new adaptable and scalable architectures will allow us to further provide exponential return from technology in order to create a more adaptable and intelligent world.",2020,2022-09-02T13:29:47Z,2022-09-02T13:29:47Z,NA,1–2,NA,NA,NA,NA,NA,NA,ISPD '20,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Taipei, Taiwan",NA,NA,NA,artificial intelligence; adaptable compute acceleration platform; domain specific architectures; scale-out computing,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,T8Q59DBK,conferencePaper,1978,"Zimmerlin, Timothy; Stanley, John; Stone, Warren",A Sensor Simulation and Animation System,Proceedings of the 5th Annual Conference on Computer Graphics and Interactive Techniques,978-1-4503-7908-3,NA,10.1145/800248.807379,https://doi.org/10.1145/800248.807379,"A shaded computer graphics system for sensor simulation and animation must possess extensive capabilities. Sensor simulation involves scenes that are viewed, environments that produce tones in the scenes, and sensors that image the scenes. Animation centers on image generation, but data input, motion specification, and tone specification routines are very important for an effective system.A unique system has been developed that models a variety of scenes, environments, and sensors. It possesses a balance of data input, motion and tone specification, and frame generation routines. The system possesses several user languages for data input. User defined sections of the scene can move. Visible, infrared, laser radar, and radar sensors have been modeled. The frame generator possesses advanced aliasing controls, textured shading, and a very fast list priority hidden surface algorithm. The system is used as a test bed for training simulators and sensor-based system simulation.",1978,2022-09-02T13:29:48Z,2022-09-02T13:29:48Z,NA,105–110,NA,NA,NA,NA,NA,NA,SIGGRAPH '78,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Animation; Computer graphics; Reflection modeling; Sensor simulation; Thermal modeling,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,7IVWU93K,journalArticle,1978,"Zimmerlin, Timothy; Stanley, John; Stone, Warren",A Sensor Simulation and Animation System,SIGGRAPH Comput. Graph.,NA,0097-8930,10.1145/965139.807379,https://doi.org/10.1145/965139.807379,"A shaded computer graphics system for sensor simulation and animation must possess extensive capabilities. Sensor simulation involves scenes that are viewed, environments that produce tones in the scenes, and sensors that image the scenes. Animation centers on image generation, but data input, motion specification, and tone specification routines are very important for an effective system.A unique system has been developed that models a variety of scenes, environments, and sensors. It possesses a balance of data input, motion and tone specification, and frame generation routines. The system possesses several user languages for data input. User defined sections of the scene can move. Visible, infrared, laser radar, and radar sensors have been modeled. The frame generator possesses advanced aliasing controls, textured shading, and a very fast list priority hidden surface algorithm. The system is used as a test bed for training simulators and sensor-based system simulation.",1978-08,2022-09-02T13:29:48Z,2022-09-02T13:29:48Z,NA,105–110,NA,3,12,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,Animation; Computer graphics; Reflection modeling; Sensor simulation; Thermal modeling,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,2Z8BNHDC,journalArticle,2015,"He, Xi; Cormode, Graham; Machanavajjhala, Ashwin; Procopiuc, Cecilia M.; Srivastava, Divesh",DPT: Differentially Private Trajectory Synthesis Using Hierarchical Reference Systems,Proc. VLDB Endow.,NA,2150-8097,10.14778/2809974.2809978,https://doi.org/10.14778/2809974.2809978,"GPS-enabled devices are now ubiquitous, from airplanes and cars to smartphones and wearable technology. This has resulted in a wealth of data about the movements of individuals and populations, which can be analyzed for useful information to aid in city and traffic planning, disaster preparedness and so on. However, the places that people go can disclose extremely sensitive information about them, and thus their use needs to be filtered through privacy preserving mechanisms. This turns out to be a highly challenging task: raw trajectories are highly detailed, and typically no pair is alike. Previous attempts fail either to provide adequate privacy protection, or to remain sufficiently faithful to the original behavior.This paper presents DPT, a system to synthesize mobility data based on raw GPS trajectories of individuals while ensuring strong privacy protection in the form of ε-differential privacy. DPT makes a number of novel modeling and algorithmic contributions including (i) discretization of raw trajectories using hierarchical reference systems (at multiple resolutions) to capture individual movements at differing speeds, (ii) adaptive mechanisms to select a small set of reference systems and construct prefix tree counts privately, and (iii) use of direction-weighted sampling for improved utility. While there have been prior attempts to solve the subproblems required to generate synthetic trajectories, to the best of our knowledge, ours is the first system that provides an end-to-end solution. We show the efficacy of our synthetic trajectory generation system using an extensive empirical evaluation.",2015-07,2022-09-02T13:29:48Z,2022-09-02T13:29:48Z,NA,1154–1165,NA,11,8,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Publisher: VLDB Endowment,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,38E9HJ4X,conferencePaper,2020,"Lockton, Dan; Zea-Wolfson, Tammar; Chou, Jackie; Song, Yuhan (Antonio); Ryan, Erin; Walsh, CJ",Sleep Ecologies: Tools for Snoozy Autoethnography,Proceedings of the 2020 ACM Designing Interactive Systems Conference,978-1-4503-6974-9,NA,10.1145/3357236.3395482,https://doi.org/10.1145/3357236.3395482,"Autoethnographic and other first-person research methods are a topic of increasing interest in design and HCI. This focus parallels the boom in self-tracking and personal informatics, perhaps most intriguingly in the intersection of quantitative and qualitative data and the noticing of patterns in one's own life and everyday wellbeing. But how can design support this? One opportunity is for research probes, or tools, which enable forms of self-inquiry, by design researchers themselves, or others. In this paper-with the broad scope of healthier student sleep as a domain-we present a series of artifacts designed by undergraduates as tools to enable autoethnographic exploration, and detail how they have been used to investigate bedtime routines, personal scheduling of time, focus, sleep data, and sleeping in non-traditional places. We also reflect on the notion of combination autoethnographic 'kits' as a way forward for forms of self-inquiry.",2020,2022-09-02T13:29:48Z,2022-09-02T13:29:48Z,NA,1579–1591,NA,NA,NA,NA,NA,NA,DIS '20,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Eindhoven, Netherlands",NA,NA,NA,design; sleep; health; autoethnography; first-person methods; probes; students,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,AT2LKVXZ,conferencePaper,2001,"Pellom, B.; Ward, W.; Hansen, J.; Cole, R.; Hacioglu, K.; Zhang, J.; Yu, X.; Pradhan, S.",University of Colorado Dialog Systems for Travel and Navigation,Proceedings of the First International Conference on Human Language Technology Research,NA,NA,10.3115/1072133.1072225,https://doi.org/10.3115/1072133.1072225,"This paper presents recent improvements in the development of the University of Colorado ""CU Communicator"" and ""CU-Move"" spoken dialog systems. First, we describe the CU Communicator system that integrates speech recognition, synthesis and natural language understanding technologies using the DARPA Hub Architecture. Users are able to converse with an automated travel agent over the phone to retrieve up-to-date travel information such as flight schedules, pricing, along with hotel and rental car availability. The CU Communicator has been under development since April of 1999 and represents our test-bed system for developing robust human-computer interactions where reusability and dialogue system portability serve as two main goals of our work. Next, we describe our more recent work on the CU Move dialog system for in-vehicle route planning and guidance. This work is in joint collaboration with HRL and is sponsored as part of the DARPA Communicator program. Specifically, we will provide an overview of the task, describe the data collection environment for in-vehicle systems development, and describe our initial dialog system constructed for route planning.",2001,2022-09-02T13:29:48Z,2022-09-02T13:29:48Z,NA,1–6,NA,NA,NA,NA,NA,NA,HLT '01,NA,NA,NA,Association for Computational Linguistics,USA,NA,NA,NA,NA,NA,NA,NA,event-place: San Diego,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,VNHQYALF,conferencePaper,2018,"Perimal-Lewis, Lua; King, Bruce",Patient Journey Modelling: Is a Single Continuous Clinical Care Venue Essential to Good Patient Outcomes? A Retrospective Analysis of Administrative Data Enhanced with Detailed Clinical Care Review,Proceedings of the Australasian Computer Science Week Multiconference,978-1-4503-5436-3,NA,10.1145/3167918.3167957,https://doi.org/10.1145/3167918.3167957,Hospitals are learning to address the discrepancy between the number of admissions and the limited number of hospital beds. The increase in demand for hospital beds and the urgency to move patients out of the Emergency Department means that patients admitted can be placed in other departments' wards. These patients are called outliers. Investigating their outcomes of care using administrative data is not a straightforward process. Aggregate statistical information alone may not be able to discern some of the essential characteristics of the data. To discover insights especially when using secondary data collected for other purposes requires extensive processing of data. This study applied data science concepts to investigate the outcomes of care of outlier patients. It also constructed start-to-end patient journeys for some of the patients to give a holistic view of their journey. This paper describes the process involved in pre-processing and making the data ready for analysis. It presents results which has already enabled the discovery of knowledge on the outlier situation at the hospital. The study was done in collaboration with Nelson Marlborough Health (NMH) in New Zealand.,2018,2022-09-02T13:29:48Z,2022-09-02T13:29:48Z,NA,NA,NA,NA,NA,NA,NA,NA,ACSW '18,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Brisband, Queensland, Australia",NA,NA,NA,data science; administrative health data; outlier patients; patient journey,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,W9G6GSDP,journalArticle,2022,"Zahedi, Mahdi; Lebdeh, Muah Abu; Bengel, Christopher; Wouters, Dirk; Menzel, Stephan; Le Gallo, Manuel; Sebastian, Abu; Wong, Stephan; Hamdioui, Said",MNEMOSENE: Tile Architecture and Simulator for Memristor-Based Computation-in-Memory,J. Emerg. Technol. Comput. Syst.,NA,1550-4832,10.1145/3485824,https://doi.org/10.1145/3485824,"In recent years, we are witnessing a trend toward in-memory computing for future generations of computers that differs from traditional von-Neumann architecture in which there is a clear distinction between computing and memory units. Considering that data movements between the central processing unit (CPU) and memory consume several orders of magnitude more energy compared to simple arithmetic operations in the CPU, in-memory computing will lead to huge energy savings as data no longer needs to be moved around between these units. In an initial step toward this goal, new non-volatile memory technologies, e.g., resistive RAM (ReRAM) and phase-change memory (PCM), are being explored. This has led to a large body of research that mainly focuses on the design of the memory array and its peripheral circuitry. In this article, we mainly focus on the tile architecture (comprising a memory array and peripheral circuitry) in which storage and compute operations are performed in the (analog) memory array and the results are produced in the (digital) periphery. Such an architecture is termed compute-in-memory-periphery (CIM-P). More precisely, we derive an abstract CIM-tile architecture and define its main building blocks. To bridge the gap between higher-level programming languages and the underlying (analog) circuit designs, an instruction-set architecture is defined that is intended to control and, in turn, sequence the operations within this CIM tile to perform higher-level more complex operations. Moreover, we define a procedure to pipeline the CIM-tile operations to further improve the performance. To simulate the tile and perform design space exploration considering different technologies and parameters, we introduce the fully parameterized first-of-its-kind CIM tile simulator and compiler. Furthermore, the compiler is technology-aware when scheduling the CIM-tile instructions. Finally, using the simulator, we perform several preliminary design space explorations regarding the three competing technologies, ReRAM, PCM, and STT-MRAM concerning CIM-tile parameters, e.g., the number of ADCs. Additionally, we investigate the effect of pipelining in relation to the clock speeds of the digital periphery assuming the three technologies. In the end, we demonstrate that our simulator is also capable of reporting energy consumption for each building block within the CIM tile after the execution of in-memory kernels considering the data-dependency on the energy consumption of the memory array. All the source codes are publicly available.",2022-01,2022-09-02T13:29:48Z,2022-09-02T13:29:48Z,NA,NA,NA,3,18,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,architecture; Computation in-memory; ISA; memristor; simulator,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,HZN6MUZH,journalArticle,2016,"Song, Xuan; Zhang, Quanshi; Sekimoto, Yoshihide; Shibasaki, Ryosuke; Yuan, Nicholas Jing; Xie, Xing",Prediction and Simulation of Human Mobility Following Natural Disasters,ACM Trans. Intell. Syst. Technol.,NA,2157-6904,10.1145/2970819,https://doi.org/10.1145/2970819,"In recent decades, the frequency and intensity of natural disasters has increased significantly, and this trend is expected to continue. Therefore, understanding and predicting human behavior and mobility during a disaster will play a vital role in planning effective humanitarian relief, disaster management, and long-term societal reconstruction. However, such research is very difficult to perform owing to the uniqueness of various disasters and the unavailability of reliable and large-scale human mobility data. In this study, we collect big and heterogeneous data (e.g., GPS records of 1.6 million users1 over 3 years, data on earthquakes that have occurred in Japan over 4 years, news report data, and transportation network data) to study human mobility following natural disasters. An empirical analysis is conducted to explore the basic laws governing human mobility following disasters, and an effective human mobility model is developed to predict and simulate population movements. The experimental results demonstrate the efficiency of our model, and they suggest that human mobility following disasters can be significantly more predictable and be more easily simulated than previously thought.",2016-11,2022-09-02T13:29:48Z,2022-09-02T13:29:48Z,NA,NA,NA,2,8,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,Human mobility; disaster informatics; spatiotemporal data mining; urban computing,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,JT2MFJYC,journalArticle,2013,"Ma, Chongyang; Wei, Li-Yi; Lefebvre, Sylvain; Tong, Xin",Dynamic Element Textures,ACM Trans. Graph.,NA,0730-0301,10.1145/2461912.2461921,https://doi.org/10.1145/2461912.2461921,"Many natural phenomena consist of geometric elements with dynamic motions characterized by small scale repetitions over large scale structures, such as particles, herds, threads, and sheets. Due to their ubiquity, controlling the appearance and behavior of such phenomena is important for a variety of graphics applications. However, such control is often challenging; the repetitive elements are often too numerous for manual edit, while their overall structures are often too versatile for fully automatic computation.We propose a method that facilitates easy and intuitive controls at both scales: high-level structures through spatial-temporal output constraints (e.g. overall shape and motion of the output domain), and low-level details through small input exemplars (e.g. element arrangements and movements). These controls are suitable for manual specification, while the corresponding geometric and dynamic repetitions are suitable for automatic computation. Our system takes such user controls as inputs, and generates as outputs the corresponding repetitions satisfying the controls.Our method, which we call dynamic element textures, aims to produce such controllable repetitions through a combination of constrained optimization (satisfying controls) and data driven computation (synthesizing details). We use spatial-temporal samples as the core representation for dynamic geometric elements. We propose analysis algorithms for decomposing small scale repetitions from large scale themes, as well as synthesis algorithms for generating outputs satisfying user controls. Our method is general, producing a range of artistic effects that previously required disparate and specialized techniques.",2013-07,2022-09-02T13:29:48Z,2022-09-02T13:29:48Z,NA,NA,NA,4,32,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,synthesis; analysis; animation; constraints; control; dynamic; element; geometry; optimization; texture,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,6SV7FUCK,conferencePaper,2015,"Chowdhury, Arijit; Banerjee, Tanushree; Chakravarty, Tapas; Balamuralidhar, P.",Smartphone Based Estimation of Relative Risk Propensity for Inducing Good Driving Behavior,Adjunct Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2015 ACM International Symposium on Wearable Computers,978-1-4503-3575-1,NA,10.1145/2800835.2804392,https://doi.org/10.1145/2800835.2804392,"Human activities analyses based on sensor data are gaining much importance. Of particular importance are those situations where man-machine interaction needs to be studied. The detection of risk induced while driving and customizing the insurance premium accordingly is an appropriate example. For such, the individuals are induced to utilize their personally owned smartphones in order to collect data and share them with insurance companies. The traditional approach counts the number of harsh events and infers the risk induced. However, such event-based inference is not necessarily a suitable approach for understanding each individual's propensity to indulge in high risk maneuvers. We propose an alternate method where a statistical route is adopted for quantifying risk propensity as well as a comparative analysis amongst a peer-group of drivers. A relatively moderate scale experimental test bed had been deployed by collecting driving related data (using their smartphones) from approximately 50 volunteers, fora duration of two months at a stretch. The experiment was unsupervised and the relative assessment is dependent on the quantity and quality of the collected data for each driver. In our model, the acceleration profiles displayed by each driver for every completed trip are observed to extract statistical features like 'Skewness squared' and 'Kurtosis'. It is observed that the kurtosis of the acceleration profiles stores major information about the driving styles. Subsequently, we have used statistical techniques to identify trends in data and used it to quantify the nature of the driving style. A comparative analysis within the peer-group (people with similar demographic features and similar work responsibilities) is done to judge individual propensities. It is envisaged that such application can be used to induce road safety through competitive spirit; additionally a large enterprise will find this tool useful to encourage employees to move towards a safe and fulfilling lifestyle. In this paper, we present the initial results of the above mentioned exercise using a smaller subset of the collected data.",2015,2022-09-02T13:29:48Z,2022-09-02T13:29:48Z,NA,743–751,NA,NA,NA,NA,NA,NA,UbiComp/ISWC'15 Adjunct,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Osaka, Japan",NA,NA,NA,statistical analysis; anomaly index; driver behavior; kurtosis; risk propensity,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,68Y74XG6,conferencePaper,2017,"Muckell, Jonathan; Young, Yuchi; Leventhal, Mitch",A Wearable Motion Tracking System to Reduce Direct Care Worker Injuries: An Exploratory Study,Proceedings of the 2017 International Conference on Digital Health,978-1-4503-5249-9,NA,10.1145/3079452.3079493,https://doi.org/10.1145/3079452.3079493,"Patients with functional disabilities often require assistance to perform basic everyday activities, such as bathing, dressing, and getting into/out of bed. These activities typically require the direct care worker (DCW) to transfer (lift &amp; move) the patient from one location to another. These patient transfers are a common cause of injury to health care workers. In fact, depending on the job site, on average a staggering 4% of DCWs are injured every year. Following proper lifting and transfer procedures can dramatically reduce the risk of injury. This research demonstrates that data collected from motion tracking systems, combined with computational analysis can detect risky patient transfer behavior. Testing of the system occurred as part of an exploratory study in an assisted living facility. Two common types of transfers were tested: transfers from bed to shower chair, and transfers from shower chair to wheelchair. These scenarios were tested on two types of patients, one that was completely disabled, and one that was partially disabled. Two major results were determined from this study: (1) risky patient transfer behavior is common in the assisted living facility, and (2) this behavior can be adequately detected via wearable motion tracking sensors. The longer term research goal is to extend these preliminary results to construct a fully wearable motion tracking system that can be used as a tool to reinforce proper lifting and transfer protocols to reduce work-related injuries among DCWs.",2017,2022-09-02T13:29:48Z,2022-09-02T13:29:48Z,NA,202–206,NA,NA,NA,NA,NA,NA,DH '17,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: London, United Kingdom",NA,NA,NA,motion tracking; injury prevention; patient transfers; wearable computing,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,H5YLFWXC,journalArticle,2021,"Dugdale, Julie; Moghaddam, Mahyar T.; Muccini, Henry",IoT4Emergency: Internet of Things for Emergency Management,SIGSOFT Softw. Eng. Notes,NA,0163-5948,10.1145/3437479.3437489,https://doi.org/10.1145/3437479.3437489,"The increasing natural and man-induced disasters such as res, earthquakes, oods, hurricanes, overcrowding, or pandemic viruses endanger human lives. Hence, designing infrastructures to handle those possible crises has become an ever-increasing need. The Internet of Things (IoT) has changed our approach to safety systems by connecting sensors and providing real-time data to managers, rescuers, and endangered people. IoT systems can monitor and react to progressive disasters, people's movements and their behavioral patterns. The community faces challenges in using IoT for crises management: i) how to take advantage of technological advancements and deal with IoT resources installation issues? ii) what environmental contexts should be considered while designing IoT-based emergency handling systems? iii) how should system design comply with various levels of real-time requirements? This paper reports on the results of the First International Workshop on Internet of Things for Emergency Management (IoT4Emergency 2020), which speci cally focuses on challenges and envisioned solutions in using smart connected systems to handle disasters.",2021-01,2022-09-02T13:29:49Z,2022-09-02T13:29:49Z,NA,33–36,NA,1,46,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,risk; detection; cps; crisis; emergency; iot; natural hazards,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,XVGR6Z2B,conferencePaper,2014,"Song, Xuan; Zhang, Quanshi; Sekimoto, Yoshihide; Shibasaki, Ryosuke",Prediction of Human Emergency Behavior and Their Mobility Following Large-Scale Disaster,Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,978-1-4503-2956-9,NA,10.1145/2623330.2623628,https://doi.org/10.1145/2623330.2623628,"The frequency and intensity of natural disasters has significantly increased over the past decades and this trend is predicted to continue. Facing these possible and unexpected disasters, accurately predicting human emergency behavior and their mobility will become the critical issue for planning effective humanitarian relief, disaster management, and long-term societal reconstruction. In this paper, we build up a large human mobility database (GPS records of 1.6 million users over one year) and several different datasets to capture and analyze human emergency behavior and their mobility following the Great East Japan Earthquake and Fukushima nuclear accident. Based on our empirical analysis through these data, we find that human behavior and their mobility following large-scale disaster sometimes correlate with their mobility patterns during normal times, and are also highly impacted by their social relationship, intensity of disaster, damage level, government appointed shelters, news reporting, large population flow and etc. On the basis of these findings, we develop a model of human behavior that takes into account these factors for accurately predicting human emergency behavior and their mobility following large-scale disaster. The experimental results and validations demonstrate the efficiency of our behavior model, and suggest that human behavior and their movements during disasters may be significantly more predictable than previously thought.",2014,2022-09-02T13:29:49Z,2022-09-02T13:29:49Z,NA,5–14,NA,NA,NA,NA,NA,NA,KDD '14,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: New York, New York, USA",NA,NA,NA,disaster informatics; human mobility; spatio-temporal data mining,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,9Z4VB5CH,conferencePaper,2012,"Yan, Da; Zhao, Zhou; Ng, Wilfred",Monochromatic and Bichromatic Reverse Nearest Neighbor Queries on Land Surfaces,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,978-1-4503-1156-4,NA,10.1145/2396761.2396880,https://doi.org/10.1145/2396761.2396880,"Finding reverse nearest neighbors (RNNs) is an important operation in spatial databases. The problem of evaluating RNN queries has already received considerable attention due to its importance in many real-world applications, such as resource allocation and disaster response. While RNN query processing has been extensively studied in Euclidean space, no work ever studies this problem on land surfaces. However, practical applications of RNN queries involve terrain surfaces that constrain object movements, which rendering the existing algorithms inapplicable.In this paper, we investigate the evaluation of two types of RNN queries on land surfaces: monochromatic RNN (MRNN) queries and bichromatic RNN (BRNN) queries. On a land surface, the distance between two points is calculated as the length of the shortest path along the surface. However, the computational cost of the state-of-the-art shortest path algorithm on a land surface is quadratic to the size of the surface model, which is usually quite huge. As a result, surface RNN query processing is a challenging problem.Leveraging some newly-discovered properties of Voronoi cell approximation structures, we make use of standard index structures such as an R-tree to design efficient algorithms that accelerate the evaluation of MRNN and BRNN queries on land surfaces. Our proposed algorithms are able to localize query evaluation by accessing just a small fraction of the surface data near the query point, which helps avoid shortest path evaluation on a large surface. Extensive experiments are conducted on large real-world datasets to demonstrate the efficiency of our algorithms.",2012,2022-09-02T13:29:49Z,2022-09-02T13:29:49Z,NA,942–951,NA,NA,NA,NA,NA,NA,CIKM '12,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Maui, Hawaii, USA",NA,NA,NA,land surface; reverse nearest neighbor; terrain,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,WL3MVA2E,conferencePaper,2014,"Kang, Tae Seung; Tsugawa, Maurício; Matsunaga, Andréa; Hirofuchi, Takahiro; Fortes, José A. B.",Design and Implementation of Middleware for Cloud Disaster Recovery via Virtual Machine Migration Management,Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing,978-1-4799-7881-6,NA,10.1109/UCC.2014.25,https://doi.org/10.1109/UCC.2014.25,"Wide-area Virtual-Machine (VM) live migration can serve as a disaster-recovery solution for IT services by moving virtualized servers to safe locations upon a critical disaster. In this scenario, it is desirable to evacuate as many VMs as possible under limited and changing electrical power and network conditions. The challenges are 1) when migrating many VMs simultaneously, the migration time of each individual VM increases, resulting in high probability of migration failures due to power or network failures, 2) the sequential migration of VMs may not efficiently use the network, and 3) network conditions, such as available bandwidth and congestion, fluctuate over time. There is a need to solve a multi-objective problem that aims at reducing simultaneously the total migration time and individual migration times. In this paper, we focus on precopy migration and present 1) the design and implementation of a feedback-based control system that manages VM migrations of multiple servers and tackles the aforementioned challenges, 2) valuable findings from extensive experiments and 3) a metric to evaluate the migration performance that takes into account both the total and individual migration times. The proposed system monitors the network usage of hosts, adjusts migration parameters, and coordinates the migration scheduling of VMs. It is a promising approach to efficiently transfer IT services from a damaged data enter to a fully functional one by automatically managing migrations across data enters. Experiments are conducted with several combinations of parameters including network conditions, migration strategies, controller type, memory distribution, and live/offline VM migrations. The results show 1) the usefulness of a feedback-based controller with a global view that can coordinate multiple physical machines to efficiently use network resources and reduce migration times, 2) the factors that affect the migration performance of multiple hosts, 3) the potential of improving sequential VM migration by integrating support for parallel TCP connections, and 4) near-optimal operating point is found while balancing both the total migration time and individual migration times by using the proposed control system.",2014,2022-09-02T13:29:52Z,2022-09-02T13:29:52Z,NA,166–175,NA,NA,NA,NA,NA,NA,UCC '14,NA,NA,NA,IEEE Computer Society,USA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,virtualization; controller; disaster recovery; wide-area VM migration,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,7AZHI7D5,conferencePaper,2012,"Moncrief, Robyn; Gobber, William",A Motion Sensor Interactive Interface for Viewing and Manipulating Protein Structural Data in 3D,ACM SIGGRAPH 2012 Posters,978-1-4503-1682-8,NA,10.1145/2342896.2343037,https://doi.org/10.1145/2342896.2343037,"We propose a fun, interactive way to view and alter protein structural data by hand via motion sensors and voice activation. This will enable users to freely zoom, rotate, and view a protein through a friendly hands-on experience. Multiple view and rotation options are given to better understand the structure. The user will also be able to separate the protein by its properties, such as atomic make up, amino acids, backbone, alpha helices and beta sheets, and bond information (Figure 2) and rotation on a user defined pivot point with extreme zooming.",2012,2022-09-02T13:29:52Z,2022-09-02T13:29:52Z,NA,NA,NA,NA,NA,NA,NA,NA,SIGGRAPH '12,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Los Angeles, California",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,8TYPC5VB,conferencePaper,2011,"Bielicky, Michael; Richter, Kamila B.",The Garden of Error and Decay,ACM SIGGRAPH 2011 Art Gallery,978-1-4503-0964-6,NA,10.1145/2019342.2019353,https://doi.org/10.1145/2019342.2019353,"The Garden of Error and Decay is a poetic visualization of real-time world catastrophes. It reflects on the network media reality of the 21st century through a continuous story of current world disasters, expressed by animated pictograms. Every time a disaster-related topic is discussed on Twitter, a new animation appears. Stock exchange information also influences the storytelling. Users interacting with the Garden have the opportunity to either eliminate or multiply the disaster scenes with a shooting device. However, it is not the user who actually has the power to decide in which direction the story develops once an event is triggered. As in real life, everything is driven by stock exchange dynamics; these dictate whether disasters proliferate or die down. This innovative moving image format is not a film, not a game, and not a nonlinear interactive story, but instead a real-time, data-driven narrative.",2011,2022-09-02T13:29:52Z,2022-09-02T13:29:52Z,NA,356–357,NA,NA,NA,NA,NA,NA,SIGGRAPH '11,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Vancouver, British Columbia, Canada",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,EX95YEX3,conferencePaper,2014,"Venkatesan, Rangharajan; Ramasubramanian, Shankar Ganesh; Venkataramani, Swagath; Roy, Kaushik; Raghunathan, Anand",STAG: Spintronic-Tape Architecture for GPGPU Cache Hierarchies,Proceeding of the 41st Annual International Symposium on Computer Architecuture,978-1-4799-4394-4,NA,NA,NA,"General-purpose Graphics Processing Units (GPGPUs) are widely used for executing massively parallel workloads from various application domains. Feeding data to the hundreds to thousands of cores that current GPGPUs integrate places great demands on the memory hierarchy, fueling an ever-increasing demand for on-chip memory.In this work, we propose STAG, a high density, energy-efficient GPGPU cache hierarchy design using a new spintronic memory technology called Domain Wall Memory (DWM). DWMs inherently offer unprecedented benefits in density by storing multiple bits in the domains of a ferromagnetic nanowire, which logically resembles a bit-serial tape. However, this structure also leads to a unique challenge that the bits must be sequentially accessed by performing ""shift"" operations, resulting in variable and potentially higher access latencies. To address this challenge, STAG utilizes a number of architectural techniques : (i) a hybrid cache organization that employs different DWM bit-cells to realize the different memory arrays within the GPGPU cache hierarchy, (ii) a clustered, bit-interleaved organization, in which the bits in a cache block are spread across a cluster of DWM tapes, allowing parallel access, (iii) tape head management policies that predictively configure DWM arrays to reduce the expected number of shift operations for subsequent accesses, and (iv) a shift aware pro- motion buffer (SaPB), in which accesses to the DWM cache are predicted based on intra-warp locality, and locations that would incur a large shift penalty are promoted to a smaller buffer. Over a wide range of benchmarks from the Rodinia, IS- PASS and Parboil suites, STAG achieves significant benefits in performance (12.1% over SRAM and 5.8% over STT-MRAM) and energy (3.3X over SRAM and 2.6X over STT-MRAM)",2014,2022-09-02T13:29:52Z,2022-09-02T13:29:52Z,NA,253–264,NA,NA,NA,NA,NA,NA,ISCA '14,NA,NA,NA,IEEE Press,NA,NA,NA,NA,NA,NA,NA,NA,"event-place: Minneapolis, Minnesota, USA",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,25Z4832Z,journalArticle,2014,"Venkatesan, Rangharajan; Ramasubramanian, Shankar Ganesh; Venkataramani, Swagath; Roy, Kaushik; Raghunathan, Anand",STAG: Spintronic-Tape Architecture for GPGPU Cache Hierarchies,SIGARCH Comput. Archit. News,NA,0163-5964,10.1145/2678373.2665710,https://doi.org/10.1145/2678373.2665710,"General-purpose Graphics Processing Units (GPGPUs) are widely used for executing massively parallel workloads from various application domains. Feeding data to the hundreds to thousands of cores that current GPGPUs integrate places great demands on the memory hierarchy, fueling an ever-increasing demand for on-chip memory.In this work, we propose STAG, a high density, energy-efficient GPGPU cache hierarchy design using a new spintronic memory technology called Domain Wall Memory (DWM). DWMs inherently offer unprecedented benefits in density by storing multiple bits in the domains of a ferromagnetic nanowire, which logically resembles a bit-serial tape. However, this structure also leads to a unique challenge that the bits must be sequentially accessed by performing ""shift"" operations, resulting in variable and potentially higher access latencies. To address this challenge, STAG utilizes a number of architectural techniques : (i) a hybrid cache organization that employs different DWM bit-cells to realize the different memory arrays within the GPGPU cache hierarchy, (ii) a clustered, bit-interleaved organization, in which the bits in a cache block are spread across a cluster of DWM tapes, allowing parallel access, (iii) tape head management policies that predictively configure DWM arrays to reduce the expected number of shift operations for subsequent accesses, and (iv) a shift aware pro- motion buffer (SaPB), in which accesses to the DWM cache are predicted based on intra-warp locality, and locations that would incur a large shift penalty are promoted to a smaller buffer. Over a wide range of benchmarks from the Rodinia, IS- PASS and Parboil suites, STAG achieves significant benefits in performance (12.1% over SRAM and 5.8% over STT-MRAM) and energy (3.3X over SRAM and 2.6X over STT-MRAM)",2014-06,2022-09-02T13:29:52Z,2022-09-02T13:29:52Z,NA,253–264,NA,3,42,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,JATNWSHL,conferencePaper,2021,"Bolsens, Ivo",Scalable System and Silicon Architectures to Handle the Workloads of the Post-Moore Era,Proceedings of the 2021 International Symposium on Physical Design,978-1-4503-8300-4,NA,10.1145/3439706.3446894,https://doi.org/10.1145/3439706.3446894,"The end of Moore's law has been proclaimed on many occasions and it's probably safe to say that we are now working in the post-Moore era. But no one is ready to slow down just yet. We can view Gordon Moore's observation on transistor densification as just one aspect of a longer-term underlying technological trend - the Law of Accelerating Returns articulated by Kurzweil. Arguably, companies became somewhat complacent in the Moore era, happy to settle for the gains brought by each new process node. Although we can expect scaling to continue, albeit at a slower pace, the end of Moore's Law delivers a stronger incentive to push other trends harder. Some exciting new technologies are now emerging such as multi-chip 3D integration and the introduction of new technologies such as storage-class memory and silicon photonics. Moreover, we are also entering a golden age of computer architecture innovation. One of the key drivers is the pursuit of domain-specific architectures as proclaimed by Turing award winners John Hennessy and David Patterson. A good example is the Xilinx's AI Engine, one of the important features of the Versal? ACAP (adaptive compute acceleration platform). Today, the explosion of AI workloads is one of the most powerful drivers shifting our attention to find faster ways of moving data into, across, and out of accelerators. Features such as massive parallel processing elements, the use of domain specific accelerators, the dense interconnect between distributed on-chip memories and processing elements, are examples of the ways chip makers are looking beyond scaling to achieve next-generation performance gains.",2021,2022-09-02T13:29:52Z,2022-09-02T13:29:52Z,NA,53–54,NA,NA,NA,NA,NA,NA,ISPD '21,NA,NA,NA,Association for Computing Machinery,"New York, NY, USA",NA,NA,NA,NA,NA,NA,NA,"event-place: Virtual Event, USA",NA,NA,NA,artificial intelligence; adaptable compute acceleration platform; domain specific architectures; scale-out computing,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
acm,settembre,VLTVMN4M,journalArticle,2015,"Venkatesan, Rangharajan; Sharad, Mrigank; Roy, Kaushik; Raghunathan, Anand",Energy-Efficient All-Spin Cache Hierarchy Using Shift-Based Writes and Multilevel Storage,J. Emerg. Technol. Comput. Syst.,NA,1550-4832,10.1145/2723165,https://doi.org/10.1145/2723165,"Spintronic memories are considered to be promising candidates for future on-chip memories due to their high density, nonvolatility, and near-zero leakage. However, they also face challenges such as high write energy and latency and limited read speed due to single-ended sensing. Further, the conflicting requirements of read and write operations lead to stringent design constraints that severely compromises their benefits.Recently, domain wall memory was proposed as a spintronic memory that has a potential for very high density by storing multiple bits in the domains of a ferromagnetic nanowire. While reliable operation of DWM memory with multiple domains faces many challenges, single-bit cells that utilize domain wall motion for writes have been experimentally demonstrated [Fukami et al. 2009]. This bit-cell, which we refer to as Domain Wall Memory with Shift-based Write (DWM-SW), achieves improved write efficiency and features decoupled read-write paths, enabling independent optimizations of read and write operations. However, these benefits are achieved at the cost of sacrificing the original goal of improved density. In this work, we explore multilevel storage as a new direction to enhance the density benefits of DWM-SW. At the device level, we propose a new device–multilevel DWM with shift-based write (ML-DWM-SW)–that is capable of storing 2 bits in a single device. At the circuit level, we propose a ML-DWM-SW based bit-cell design and layout. The ML-DWM-SW bit-cell incurs no additional area overhead compared to the DWM-SW bit-cell despite storing an additional bit, thereby achieving roughly twice the density. However, it requires a two-step write operation and has data-dependent read and write energies, which pose unique challenges. To address these issues, we propose suitable architectural optimizations: (i) intra-word interleaving and (ii) bit encoding. We design “all-spin” cache architectures using the proposed ML-DWM-SW bit-cell for both general purpose processors as well as general purpose graphics processing units (GPGPUs). We perform an iso-capacity replacement of SRAM with spintronic memories and study the energy and area benefits at iso-performance conditions. For general purpose processors, the ML-DWM-SW cache achieves 10X reduction in energy and 4.4X reduction in cache area compared to an SRAM cache and 2X and 1.7X reduction in energy and area, respectively, compared to an STT-MRAM cache. For GPGPUs, the ML-DWM-SW cache achieves 5.3X reduction in energy and 3.6X area reduction compared to SRAM and 3.5X energy reduction and 1.9X area reduction compared to STT-MRAM.",2015-08,2022-09-02T13:29:52Z,2022-09-02T13:29:52Z,NA,NA,NA,1,12,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Place: New York, NY, USA Publisher: Association for Computing Machinery",NA,NA,NA,cache architecture; Domain wall memory; multilevel bit-cell; spintronic memory,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
embase,settembre,2ASNTBXR,journalArticle,2022,Li D.; Mathews C.; Zamarripa C.; Zhang F.; Xiao Q.,Wound tissue segmentation by computerised image analysis of clinical pressure injury photographs: a pilot study,Journal of wound care,NA,0969-0700,10.12968/jowc.2022.31.8.710,NA,"OBJECTIVE: Wound tissues can provide ample information about the wound development and healing process. However, the manual identification and measurement of wound tissue types is time-consuming and challenging due to the complexities of pressure injuries (PI). This study aims to develop an image analysis algorithm to automatically identify and differentiate wound tissue types from PI wound beds. METHOD(S): This was a cross-sectional algorithm development study. PI photographs were obtained from a western Pennsylvania hospital. We used our previously developed wound bed segmentation tool to identify PI wound beds. We then used the k-means clustering method to classify the subzones on the wound beds. Finally, the support vector machine classifier was used to identify the classified subzones to certain types of wound tissue. RESULT(S): An image analysis algorithm was developed, using 64 selected PI photographs, to automatically identify different wound tissues for PIs. CONCLUSION(S): Validation of the wound tissue identification of the PIs by image analysis algorithm demonstrated that our image analysis algorithm is a reliable and objective approach to monitoring wound healing progress through clinical PI photographs, and offers new insight into PI evaluation and documentation. DECLARATION OF INTEREST: The authors have no conflicts of interest to declare.",2022,2022-09-02T12:15:52Z,2022-09-02T12:15:52Z,NA,710-719,NA,8,31,NA,J Wound Care,NA,NA,NA,NA,NA,NA,NA,English,NA,NA,NA,NA,NA,NA,Place: United Kingdom Publisher: NLM (Medline),NA,NA,http://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=reference&D=emedx&NEWS=N&AN=638840402,*decubitus; *image analysis; *k means clustering; *nursing assessment; *photography; *pilot study; *wound dressing; *wound healing; *wound tissue; article; classifier; documentation; human; imaging algorithm; Pennsylvania; support vector machine; tissues,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
embase,settembre,DBPAKRFA,journalArticle,2022,Hu C.; Li Y.; Wang F.; Peng Z.,Application of Machine Learning for Clinical Subphenotype Identification in Sepsis,Infectious Diseases and Therapy,NA,2193-8229,10.1007/s40121-022-00684-y,http://www.springer.com/springer+healthcare/journal/40121,"Introduction: Sepsis is a heterogeneous clinical syndrome. Identification of sepsis subphenotypes could lead to allowing more precise therapy. However, there is a lack of models to identify the subphenotypes in such patients. Thus, we aimed to identify possible subphenotypes and compare the clinical outcomes for subphenotypes in a large sepsis cohort. Method(s): This machine learning-based, cluster analysis was performed using the Medical Information Mart in Intensive Care (MIMIC)-IV database. We enrolled all adult (> 18 years old) patients diagnosed with sepsis in the first 24 h after intensive care unit (ICU) admission. K-means cluster analysis was performed to identify the number of classes. Multivariable logistic regression models were used to estimate the association between sepsis subphenotypes and in-hospital mortality. Result(s): A total of 8817 participants with sepsis were enrolled. The median age was 66.8 (IQR, 55.9-77.1) years, and 38.1% (3361/8817) were female. Two subphenotypes resulted in optimal separation including 11 routinely available clinical variables obtained during the first 24 h after ICU admission. Participants in subphenotype B showed higher levels of lactate, glucose and creatinine, white blood cell count, sodium and heart rate and lower body temperature, platelet count, systolic blood pressure, hemoglobin and PaO2/FiO2 ratio. In addition, the in-hospital mortality in patients with subphenotype B was significantly higher than that in subphenotype A (29.4% vs. 8.5%, P < 0.001). The difference was still significant after adjustment for potential covariates (adjusted OR 2.214; 95% CI 1.780-2.754, P < 0.001). Conclusion(s): Two sepsis subphenotypes with different clinical outcomes could be rapidly identified using the K-means clustering analysis based on routinely available clinical data. This finding may help clinicians to identify the subphenotype rapidly at the bedside. Graphical abstract: [Figure not available: see fulltext.]Copyright © 2022, The Author(s).",2022,2022-09-02T12:15:52Z,2022-09-02T12:15:52Z,NA,NA,NA,"(Hu, Li, Wang, Peng) Department of Critical Care Medicine, Zhongnan Hospital of Wuhan University, Hubei, Wuhan 430071, China",NA,NA,Infect. Dis. Ther.,NA,NA,NA,NA,NA,NA,NA,English,NA,NA,NA,NA,NA,NA,Place: United Kingdom Publisher: Adis,NA,NA,http://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=reference&D=emedx&NEWS=N&AN=2018774005,*machine learning; *personalized medicine; *sepsis; adult; aged; article; body temperature; clinical outcome; cluster analysis; controlled study; creatinine; endogenous compound; female; glucose; heart rate; hemoglobin; Horowitz index; human; in-hospital mortality; intensive care; intensive care unit; k means clustering; lactic acid; leukocyte count; major clinical study; medical information; outcome assessment; platelet count; sodium; systolic blood pressure,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
embase,settembre,YPJ528BH,journalArticle,2022,Hamade B.; Murugan R.; Lovelace E.; Saul M.; Huang D.T.; Al-Khafaji A.,"Shock Index, Modified Shock Index and MELD as Predictors of Mortality for Critically Ill Patients With Liver Disease",Journal of Intensive Care Medicine,NA,0885-0666,10.1177/08850666211049749,https://journals.sagepub.com/home/jic,NA,2022,2022-09-02T12:15:52Z,2022-09-02T12:15:52Z,NA,1037-1042,NA,8,37,NA,J. Intensive Care Med.,NA,NA,NA,NA,NA,NA,NA,English,NA,NA,NA,NA,NA,NA,Place: United States Publisher: SAGE Publications Inc.,NA,NA,http://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=reference&D=emexb&NEWS=N&AN=2014358586,*critically ill patient; *liver disease; *Model For End Stage Liver Disease Score; *modified shock index; *mortality; *shock; adult; aged; Akaike information criterion; area under the curve; article; auscultation; Bayesian network; beta adrenergic receptor blocking agent/ec [Endogenous Compound]; controlled study; diagnostic test accuracy study; diastolic dysfunction; emergency ward; female; heart arrest; heart lung transplantation; heart rate; hospital bed; hospital mortality; hospitalization; human; hypertensive factor/ec [Endogenous Compound]; ICD-10-CM; intensive care unit; major clinical study; male; mean arterial pressure; middle aged; organ transplantation; oscillometry; outcome assessment; predictive value; receiver operating characteristic; retrospective study; systolic blood pressure,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
embase,settembre,DXJHYMAY,journalArticle,2022,Podell J.; Pergakis M.; Yang S.; Felix R.; Parikh G.; Chen H.; Chen L.; Miller C.; Hu P.; Badjatia N.,Leveraging Continuous Vital Sign Measurements for Real-Time Assessment of Autonomic Nervous System Dysfunction After Brain Injury: A Narrative Review of Current and Future Applications,Neurocritical Care,NA,1541-6933,10.1007/s12028-022-01491-6,http://www.springer.com/humana+press/journal/12028,"Subtle and profound changes in autonomic nervous system (ANS) function affecting sympathetic and parasympathetic homeostasis occur as a result of critical illness. Changes in ANS function are particularly salient in neurocritical illness, when direct structural and functional perturbations to autonomic network pathways occur and may herald impending clinical deterioration or intervenable evolving mechanisms of secondary injury. Sympathetic and parasympathetic balance can be measured quantitatively at the bedside using multiple methods, most readily by extracting data from electrocardiographic or photoplethysmography waveforms. Work from our group and others has demonstrated that data-analytic techniques can identify quantitative physiologic changes that precede clinical detection of meaningful events, and therefore may provide an important window for time-sensitive therapies. Here, we review data-analytic approaches to measuring ANS dysfunction from routine bedside physiologic data streams and integrating this data into multimodal machine learning-based model development to better understand phenotypical expression of pathophysiologic mechanisms and perhaps even serve as early detection signals. Attention will be given to examples from our work in acute traumatic brain injury on detection and monitoring of paroxysmal sympathetic hyperactivity and prediction of neurologic deterioration, and in large hemispheric infarction on prediction of malignant cerebral edema. We also discuss future clinical applications and data-analytic challenges and future directions.Copyright © 2022, Springer Science+Business Media, LLC, part of Springer Nature and Neurocritical Care Society.",2022,2022-09-02T12:15:52Z,2022-09-02T12:15:52Z,NA,206-219,NA,Supplement 2,37,NA,Neurocrit. Care,NA,NA,NA,NA,NA,NA,NA,English,NA,NA,NA,NA,NA,NA,Place: United States Publisher: Springer GE Marquette Solar 7000 8000: General Electric [United States],NA,NA,http://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=reference&D=emexb&NEWS=N&AN=2015587097,*autonomic neuropathy/co [Complication]; *autonomic neuropathy/di [Diagnosis]; *brain injury; *vital sign; article; autonomic nervous system function; blood pressure monitoring; body position; body temperature; brain edema/co [Complication]; brain edema/di [Diagnosis]; brain infarction/co [Complication]; brain infarction/di [Diagnosis]; breathing rate; computer assisted tomography; critical illness; data analysis; data extraction; data integration; diffusion tensor imaging; electrocardiography; fractional anisotropy; GE Marquette Solar 7000 8000; general condition deterioration; heart rate variability; human; machine learning; medical assessment; narrative; National Institutes of Health Stroke Scale; nuclear magnetic resonance imaging; parasympathetic function; paroxysmal sympathetic hyperactivity/co [Complication]; paroxysmal sympathetic hyperactivity/di [Diagnosis]; pathophysiology; patient monitor; patient monitoring; patient vital sign monitor; phenotype; photoelectric plethysmography; prediction; quantitative analysis; Rankin scale; spinal cord injury/co [Complication]; spinal cord injury/di [Diagnosis]; sweating; sympathetic function; systolic blood pressure; time; traumatic brain injury; waveform,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
embase,settembre,KHZW4ELU,journalArticle,2022,Cho S.-W.; Jung S.J.; Shin J.H.; Won T.-B.; Rhee C.-S.; Kim J.-W.,Evaluating Prediction Models of Sleep Apnea From Smartphone-Recorded Sleep Breathing Sounds,JAMA Otolaryngology - Head and Neck Surgery,NA,2168-6181,10.1001/jamaoto.2022.0244,http://archotol.jamanetwork.com/issues.aspx,"Importance: Breathing sounds during sleep are an important characteristic feature of obstructive sleep apnea (OSA) and have been regarded as a potential biomarker. Breathing sounds during sleep can be easily recorded using a microphone, which is found in most smartphone devices. Therefore, it may be easy to implement an evaluation tool for prescreening purposes. Objective(s): To evaluate OSA prediction models using smartphone-recorded sounds and identify optimal settings with regard to noise processing and sound feature selection. Design, Setting, and Participant(s): A cross-sectional study was performed among patients who visited the sleep center of Seoul National University Bundang Hospital for snoring or sleep apnea from August 2015 to August 2019. Audio recordings during sleep were performed using a smartphone during routine, full-night, in-laboratory polysomnography. Using a random forest algorithm, binary classifications were separately conducted for 3 different threshold criteria according to an apnea hypopnea index (AHI) threshold of 5, 15, or 30 events/h. Four regression models were created according to noise reduction and feature selection from the input sound to predict actual AHI: (1) noise reduction without feature selection, (2) noise reduction with feature selection, (3) neither noise reduction nor feature selection, and (4) feature selection without noise reduction. Clinical and polysomnographic parameters that may have been associated with errors were assessed. Data were analyzed from September 2019 to September 2020. Main Outcomes and Measures: Accuracy of OSA prediction models. Result(s): A total of 423 patients (mean [SD] age, 48.1 [12.8] years; 356 [84.1%] male) were analyzed. Data were split into training (n = 256 [60.5%]) and test data sets (n = 167 [39.5%]). Accuracies were 88.2%, 82.3%, and 81.7%, and the areas under curve were 0.90, 0.89, and 0.90 for an AHI threshold of 5, 15, and 30 events/h, respectively. In the regression analysis, using recorded sounds that had not been denoised and had only selected attributes resulted in the highest correlation coefficient (r = 0.78; 95% CI, 0.69-0.88). The AHI (beta = 0.33; 95% CI, 0.24-0.42) and sleep efficiency (beta = -0.20; 95% CI, -0.35 to -0.05) were found to be associated with estimation error. Conclusions and Relevance: In this cross-sectional study, recorded sleep breathing sounds using a smartphone were used to create reasonably accurate OSA prediction models. Future research should focus on real-life recordings using various smartphone devices..Copyright © 2022 American Medical Association. All rights reserved.",2022,2022-09-02T12:15:52Z,2022-09-02T12:15:52Z,NA,515-521,NA,6,148,NA,JAMA Otolaryngol. Head Neck Surg.,NA,NA,NA,NA,NA,NA,NA,English,NA,NA,NA,NA,NA,NA,Place: United States Publisher: American Medical Association,NA,NA,http://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=reference&D=emexb&NEWS=N&AN=637876447,*abnormal respiratory sound; *sleep disordered breathing; *smartphone; adult; apnea hypopnea index; article; audio recording; binary classification; controlled study; cross-sectional study; feature selection; female; human; machine learning; major clinical study; male; middle aged; noise reduction; polysomnography; random forest; regression analysis; root mean squared error; sleep efficiency; sleep latency; sleep stage; snoring; stage 1 sleep; time in bed,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
embase,settembre,NC82DD2J,journalArticle,2022,Chen K.; Beyeler M.; Krichmar J.L.,Cortical motion perception emerges from dimensionality reduction with evolved spike-timing dependent plasticity rules,Journal of Neuroscience,NA,0270-6474,10.1523/JNEUROSCI.0384-22.2022,https://www.jneurosci.org/content/42/30/5882,"The nervous system is under tight energy constraints and must represent information efficiently. This is particularly relevant in the dorsal part of the medial superior temporal area (MSTd) in primates where neurons encode complex motion patterns in order to support a variety of behaviors. A sparse decomposition model based on a dimensionality reduction principle known as Nonnegative Matrix Factorization (NMF) was previously shown to account for a wide range of monkey MSTd visual response properties. This model resulted in sparse, ""parts-based"" representations that could be regarded as basis flow fields, a linear superposition of which accurately reconstructed the input stimuli. This model provided evidence that the seemingly-complex response properties of MSTd may be a by-product of MSTd neurons performing dimensionality reduction on their input. However, an open question is how a neural circuit could carry out this function. In the current study, we propose a Spiking Neural Network (SNN) model of MSTd based on evolved spike-timing dependent plasticity and homeostatic synaptic scaling (STDP-H) learning rules. We demonstrate that the SNN model learns compressed and efficient representations of the input patterns similar to the patterns that emerge from NMF, resulting in MSTd-like receptive fields observed in monkeys. This SNN model suggests that STDP-H observed in the nervous system may be performing a similar function as NMF with sparsity constraints, which provides a test bed for mechanistic theories of how MSTd may efficiently encode complex patterns of visual motion to support robust self-motion perception.Copyright © 2022 the authors.",2022,2022-09-02T12:15:53Z,2022-09-02T12:15:53Z,NA,5882-5898,NA,30,42,NA,J. Neurosci.,NA,NA,NA,NA,NA,NA,NA,English,NA,NA,NA,NA,NA,NA,Place: United States Publisher: Society for Neuroscience,NA,NA,http://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=reference&D=emexb&NEWS=N&AN=2019529895,*dimensionality reduction; *movement perception; *spike; animal experiment; animal model; article; Haplorhini; learning; nerve cell; non-negative matrix factorization; nonhuman; receptive field; spiking neural network; synapse,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
embase,settembre,Q8J5WAHF,journalArticle,2021,Mulkey S.B.; Polglase G.R.,Cerebral oxygen saturation-a useful bedside vital sign for neonatal encephalopathy,Journal of Perinatology,NA,0743-8346,10.1038/s41372-021-00916-y,http://www.nature.com/jp/index.html,NA,2021,2022-09-02T12:15:53Z,2022-09-02T12:15:53Z,NA,2577-2579,NA,11,41,NA,J. Perinatol.,NA,NA,NA,NA,NA,NA,NA,English,NA,NA,NA,NA,NA,NA,Place: United States Publisher: Springer Nature,NA,NA,http://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=reference&D=emexb&NEWS=N&AN=2010386123,*brain injury/di [Diagnosis]; *brain injury/th [Therapy]; *brain oxygen consumption; *near infrared spectroscopy; *newborn disease/di [Diagnosis]; *newborn disease/th [Therapy]; *oxygen saturation; amplitude modulation; anticonvulsive agent/pv [Special Situation for Pharmacovigilance]; blood pressure; brain blood flow; brain blood volume; brain metabolism; brain perfusion; disease severity; editorial; electroencephalogram; gray matter; heart rate; human; image analysis; induced hypothermia; infection risk; length of stay; necrotizing enterocolitis/co [Complication]; neonatal intensive care unit; neuroimaging; neuromonitoring; nomogram; nuclear magnetic resonance imaging; prognosis; pulse oximetry; sedative agent/pv [Special Situation for Pharmacovigilance]; sepsis/co [Complication]; treatment duration,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
embase,settembre,4NZY7N7G,journalArticle,2022,Lin C.-J.; Wei T.-S.; Liu P.-T.; Chen B.-H.; Shih C.-H.,Bed-Exit Behavior Recognition for Real-Time Images within Limited Range,"Sensors (Basel, Switzerland)",NA,1424-8220 (electronic),10.3390/s22155495,NA,"In the context of behavior recognition, the emerging bed-exit monitoring system demands a rapid deployment in the ward to support mobility and personalization. Mobility means the system can be installed and removed as required without construction; personalization indicates human body tracking is limited to the bed region so that only the target is monitored. To satisfy the above-mentioned requirements, the behavior recognition system aims to: (1) operate in a small-size device, typically an embedded system; (2) process a series of images with narrow fields of view (NFV) to detect bed-related behaviors. In general, wide-range images are preferred to obtain a good recognition performance for diverse behaviors, while NFV images are used with abrupt activities and therefore fit single-purpose applications. This paper develops an NFV-based behavior recognition system with low complexity to realize a bed-exit monitoring application on embedded systems. To achieve effectiveness and low complexity, a queueing-based behavior classification is proposed to keep memories of object tracking information and a specific behavior can be identified from continuous object movement. The experimental results show that the developed system can recognize three bed behaviors, namely off bed, on bed and return, for NFV images with accuracy rates of 95~100%.",2022,2022-09-02T12:15:53Z,2022-09-02T12:15:53Z,NA,NA,NA,15,22,NA,Sensors (Basel),NA,NA,NA,NA,NA,NA,NA,English,NA,NA,NA,NA,NA,NA,Place: Switzerland Publisher: NLM (Medline),NA,NA,http://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=reference&D=emexb&NEWS=N&AN=638622077,*hospital; human; physiologic monitoring; procedures,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
embase,settembre,PY58DV44,journalArticle,2022,Bardyn C.; Ravey F.; Hubbard I.; Buluschek P.; Bally J.; Ryvlin P.,Filling key monitoring gaps in Parkinson's Disease using AI and in-home sensor data,European Journal of Neurology,NA,1468-1331,10.1111/ene.15465,NA,"Background and aims: Conventional monitoring tools for Parkinson's disease (PD) include questionnaires, diaries, and structured clinical exams focused on motor symptoms, which have known limitations such as subjectivity, adherence, and fluctuations with PD symptoms throughout the day. Spouses and partners also frequently report better performances during medical exams. All in all, clinicians can hardly trust their observations. They must rely on patient history which is often not informative enough- particularly for patients with cognitive difficulties. Combined with the fact that patients are typically examined every few months, tools powered by more continuous and objective sources of data would help fill in key monitoring gaps. Method(s): We monitored 15 patients for 6 months using in-home passive sensors including a pressure-based bed sensor measuring movement intensity as well as heart and respiration rates. Patients were asked to keep a daily diary of important events, such as medication changes, and were evaluated every 3 months using standard rating scales. Result(s): We developed a cloud-based clinical decision support system (CDSS) to monitor sleep-related aspects of PD continuously and automatically through a variety of biomarkers selected and engineered with PD experts. We developed a novel deep-learning architecture to identify biomarker changes on choosable timescales, and designed a dashboard to visualise the evolution of biomarkers and quickly identify regions of interest based on changes. Conclusion(s): The biomarkers and changes made available to clinicians by the developed CDSS revealed a great level of detail about patient trajectories, displaying clear correlations with clinical events such as treatment modifications.",2022,2022-09-02T12:15:53Z,2022-09-02T12:15:53Z,NA,307,NA,Supplement 1,29,NA,Eur. J. Neurol.,NA,8th Annual Congress of the European Academy of Neurology. Vienna Austria.,NA,NA,NA,NA,NA,English,NA,NA,NA,NA,NA,NA,Place: Netherlands Publisher: Blackwell Publishing Ltd,NA,NA,http://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=reference&D=emexb&NEWS=N&AN=638619317,*Parkinson disease; *sensor; adult; biological marker; breathing rate; clinical article; clinical decision support system; conference abstract; controlled study; deep learning; female; genetic marker; heart rate; human; male; medical history; rating scale; sleep,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,marzo,YSH462RB,journalArticle,2022,H. Jung; J. Kimball; T. Receveur; A. H. Gazi; E. Agdeppa; O. Inan,Estimation of Tidal Volume Using Load Cells on a Hospital Bed,IEEE Journal of Biomedical and Health Informatics,NA,2168-2208,10.1109/JBHI.2022.3141209,NA,"Although respiratory failure is one of the primary causes of admission to intensive care, the importance placed on measurement of respiratory parameters is commonly overshadowed compared to cardiac parameters. With the increased demand for unobtrusive yet quantifi- able respiratory monitoring, many technologies have been proposed recently. However, there are challenges to be addressed for such technologies to enable widespread use. In this work, we explore the feasibility of using load cell sensors embedded on a hospital bed for monitoring respi- ratory rate (RR) and tidal volume (TV). We propose a globalized machine learning (ML)-based algorithm for estimating TV without the requirement of subject-specific calibration or training. In a study of 15 healthy subjects performing respiratory tasks in four different postures, the outputs from four load cell channels and the reference spirometer were recorded simultaneously. A signal processing pipeline was implemented to extract features that capture respira- tory movement and the respiratory effects on the cardiac (i.e., ballistocardiogram, BCG) signals. The proposed RR estimation algorithm achieved a root mean square error (RMSE) of 0.6 breaths per minute (brpm) against the ground truth RR from the spirometer. The TV estimation results demonstrated that combining all three axes of the low- frequency force signals and the BCG heartbeat features best quantifies the respiratory effects of TV. The model resulted in a correlation and RMSE between the estimated and true TV values of 0.85 and 0.23 L, respectively, in the posture independent model without electrocardiogram (ECG) signals. This study suggests that load cell sensors already existing in certain hospital beds can be used for convenient and continuous respiratory monitoring in general care settings.",2022,2022-08-24T07:32:20Z,2022-08-24T07:32:20Z,NA,1-1,NA,NA,NA,NA,IEEE Journal of Biomedical and Health Informatics,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Calibration; Feature extraction; Monitoring; Sensors; Hospitals; ballistocardiogram; continuous respiratory monitoring; respiratory rate; Task analysis; tidal volume; TV,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,marzo,WEQHCGRT,journalArticle,2021,C. -S. Son; W. -S. Kang; J. -H. Lee; K. j. Moon,Machine Learning to Identify Psychomotor Behaviors of Delirium for Patients in Long-Term Care Facility,IEEE Journal of Biomedical and Health Informatics,NA,2168-2208,10.1109/JBHI.2021.3116967,NA,"This study aimed to develop accurate and explainable machine learning models for three psychomotor behaviors of delirium for hospitalized adult patients. A prospective pilot study was conducted with 33 participants admitted to a long-term care facility between August 10 and 25, 2020. During the pilot study, we collected 560 cases that included 33 clinical variables and the survey items from the short confusion assessment method (S-CAM), and developed a mobile-based application. Multiple machine learning algorithms, including four rule-mining algorithms (C4.5, CBA, MCAR, and LEM2) and four other statistical learning algorithms (LR, ANNs, SVMs with three kernel functions, and random forest), were validated by paired Wilcoxon signed-rank tests on both macro-averaged F1 and weighted average F1-measures during the 10-times stratified 2-fold cross-validation. The LEM2 algorithm achieved the best prediction performance (macro-averaged F1-measure of 49.35%; weighted average F1-measure of 96.55%), correctly identifying adult patients at delirium risk. In the pairwise comparison between predictive powers observed from independent models, the LEM2 model showed a medium or large effect size between 0.4925 and 0.8766 when compared with LR, ANN, SVM with RBF, and MCAR models. We have confirmed that acute consciousness in S-CAM assessment is closely associated with different predictors for screening three psychomotor behaviors of delirium: 1) education level, dementia type or its level, sleep disorder, dehydration, and infection in mixed-type delirium; 2) gender, education level, dementia type, dehydration, bedsores, and foley catheter in hyperactive delirium; and 3) pain, sleep disorder, and haloperidol use in hypoactive delirium.",2021,2022-08-24T07:32:31Z,2022-08-24T07:32:31Z,NA,1-1,NA,NA,NA,NA,IEEE Journal of Biomedical and Health Informatics,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Machine learning; Support vector machines; Machine Learning; Artificial neural networks; Predictive models; Radio frequency; Data models; Sensitivity; Delirium; Predictive Model; Psychomotor Behaviors of Delirium; Rule Learning,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,4ZC35AAM,conferencePaper,2015,I. -A. Szöke; V. Stoicu-Tivadar; D. Lungeanu,Sleep fragmentation. A study on how daily activities affect our sleeping,2015 IEEE 19th International Conference on Intelligent Engineering Systems (INES),NA,NA,10.1109/INES.2015.7329718,NA,"Physiology sleep study aspects and its quality determines how health became a separate department medical field. The article's goal is to relate the two terms in the following form: time spent with different daily activity and the sleep quality. This way, we may be able to find a connection between the amount of time spent with daily activities and the most important sleep quality indicator: number of awakenings. Also we could find other important connection between the studied parameters: burned calories, steps made, distance walked, sedentary minutes, lightly active minutes, fairly active minutes, very active minutes, activity calories, minutes asleep, minutes awake and time spend in bed. Most important, a conclusion can be drawn in terms of what we can do in order to improve sleep quality and implicitly what can be done in order to reach better performances during daily activities.",2015-09-03,2022-09-02T13:30:03Z,2022-09-02T13:30:03Z,NA,259-263,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Journal Abbreviation: 2015 IEEE 19th International Conference on Intelligent Engineering Systems (INES),NA,NA,NA,Artificial intelligence; Performance evaluation; Physiology; Correlation coefficient; Tracking; Conferences; Correlation,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,2015 IEEE 19th International Conference on Intelligent Engineering Systems (INES),NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,BDWYM2KL,conferencePaper,2011,H. Lu; H. -L. Eng; B. Mandal; D. W. S. Chan; Y. -L. Ng,Markerless video analysis for movement quantification in pediatric epilepsy monitoring,2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society,1558-4615,NA,10.1109/IEMBS.2011.6092040,NA,"This paper proposes a markerless video analytic system for quantifying body part movements in pediatric epilepsy monitoring. The system utilizes colored pajamas worn by a patient in bed to extract body part movement trajectories, from which various features can be obtained for seizure detection and analysis. Hence, it is non-intrusive and it requires no sensor/marker to be attached to the patient's body. It takes raw video sequences as input and a simple user-initialization indicates the body parts to be examined. In background/foreground modeling, Gaussian mixture models are employed in conjunction with HSV-based modeling. Body part detection follows a coarse-to-fine paradigm with graph-cut-based segmentation. Finally, body part parameters are estimated with domain knowledge guidance. Experimental studies are reported on sequences captured in an Epilepsy Monitoring Unit at a local hospital. The results demonstrate the feasibility of the proposed system in pediatric epilepsy monitoring and seizure detection.",2011-09-30,2022-09-02T13:30:03Z,2022-09-02T13:30:03Z,NA,8275-8278,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Journal Abbreviation: 2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society,NA,NA,NA,Monitoring; Image color analysis; Epilepsy; Pediatrics; Electroencephalography; Oscillators; Trajectory,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,LZHWQ6HC,journalArticle,2022,R. Tapwal; S. Misra; P. K. Deb,i-Sheet: A Low-Cost Bedsheet Sensor for Remote Diagnosis of Isolated Individuals,IEEE Sensors Journal,NA,1558-1748,10.1109/JSEN.2022.3198140,NA,"In this paper, we propose a smart bedsheet &#x2013;i-Sheet&#x2013; for remotely monitoring the health of the COVID-19 patients. Typically, real-time health monitoring is very crucial for COVID-19 patients to prevent their health from deteriorating. Conventional healthcare monitoring systems are manual and require patient input to start monitoring health. However, it is difficult for the patients to give input in critical conditions as well as at night. For instance, if the oxygen saturation level decreases during sleep, then it is difficult to monitor. Further, there is a need for a system that monitors post-COVID effects as various vitals get affected, and there are chances of their failure even after the recovery. i-Sheet exploits these features and provides the health monitoring of the COVID-19 patients based on their pressure on the bedsheet. It works in three phases: 1. sensing the pressure exerted by the patient on the bedsheet, 2. categorizing the data into groups (comfortable, uncomfortable) based on the fluctuations in the data, and 3. alerting the caretaker about the condition of the patient. Experimental results demonstrate the effectiveness of i-Sheet in monitoring the health of the patient. i-Sheet effectively categorizes the condition of the patient with the accuracy of 99.3% and utilizes 17.5 Watt of the power. Further, the delay involves in monitoring the health of patients using i-Sheet is 2 secs which is very diminutive and is acceptable.",2022,2022-09-02T13:30:04Z,2022-09-02T13:30:04Z,NA,1-1,NA,NA,NA,NA,IEEE Sensors Journal,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Artificial Intelligence; Monitoring; Sensors; COVID-19; Intelligent sensors; Biomedical monitoring; Temperature measurement; Temperature sensors; Remote Monitoring; Smart Bedsheet,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,QIFKYRQA,conferencePaper,2022,M. Gavenciak; V. Zvoncak; J. Mekyska; K. Safarova; L. Cunek; T. Urbanek; J. M. Havigerova; J. Bednarova; Z. Galaz; J. Mucha,Exploring the Contribution of Isochrony-based Features to Computerized Assessment of Handwriting Disabilities,2022 45th International Conference on Telecommunications and Signal Processing (TSP),NA,NA,10.1109/TSP55681.2022.9851254,NA,"Approximately 30&#x2013;60 &#x0025; of the time children spend in school is associated with handwriting. However, up to 30 &#x0025; of them experience handwriting disabilities (HD), which lead to a decrease in their academic performance. Current HD assessment methods are not unified and show signs of subjectivity which can lead to misdiagnosis. The aim of this paper is to propose a new approach to objective HD assessment based on the principle of movement isochrony. For this purpose, we used a database of 137 children attending a primary school, who performed a transcription and dictation task, and who were associated with a BHK (Concise Evaluation Scale for Children&#x0027;s Handwriting) score. Employing a machine learning model, we were able to estimate this score with 18 &#x0025; error. An interpretation of the model suggests that the isochrony-based features could bring new benefits to the objective assessment of HD.",2022-07-13,2022-09-02T13:30:04Z,2022-09-02T13:30:04Z,NA,355-359,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Journal Abbreviation: 2022 45th International Conference on Telecommunications and Signal Processing (TSP),NA,NA,NA,Machine learning; Signal processing; Computational modeling; Predictive models; Databases; Analytical models; developmental dysgraphia; Estimation error; handwriting difficulties; isochrony; online handwriting,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,2022 45th International Conference on Telecommunications and Signal Processing (TSP),NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,7C4KAT6Z,conferencePaper,2022,M. Afham; U. Haputhanthri; J. Pradeepkumar; M. Anandakumar; A. De Silva; C. U. S. Edussooriya,Towards Accurate Cross-Domain in-Bed Human Pose Estimation,"ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",2379-190X,NA,10.1109/ICASSP43922.2022.9747183,NA,"Human behavioral monitoring during sleep is essential for various medical applications. Majority of the contactless human pose estimation algorithms are based on RGB modality, causing ineffectiveness in in-bed pose estimation due to occlusions by blankets and varying illumination conditions. Long-wavelength infrared (LWIR) modality based pose estimation algorithms overcome the aforementioned challenges; however, ground truth pose generations by a human annotator under such conditions are not feasible. A feasible solution to address this issue is to transfer the knowledge learned from images with pose labels and no occlusions, and adapt it towards real world conditions (occlusions due to blankets). In this paper, we propose a novel learning strategy comprises of two-fold data augmentation to reduce the cross-domain discrepancy and knowledge distillation to learn the distribution of unlabeled images in real world conditions. Our experiments and analysis show the effectiveness of our approach over multiple standard human pose estimation baselines <sup>1</sup>.",2022-05-23,2022-09-02T13:30:04Z,2022-09-02T13:30:04Z,NA,2664-2668,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Journal Abbreviation: ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",NA,NA,NA,Signal processing; Medical services; Training; Lighting; Signal processing algorithms; Pose estimation; Adaptation models; Human pose estimation; domain adaptation; knowledge distillation; self-supervised learning,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,LZEH8LNK,conferencePaper,2022,H. Huang; R. Sun; G. Zhou; P. Zhao,Human Computer Interaction Method for Feeding Demands of the Disabled and the Sick Based on Micro Facial Posture Capture,"2022 4th International Conference on Advances in Computer Technology, Information Science and Communications (CTISC)",NA,NA,10.1109/CTISC54888.2022.9849777,NA,"There are a large number of elderly, disabled, and bedridden people who can not eat independently in China. With the development of science and technology, many eating auxiliary robot systems have been studied at home and all over the world. However, most of these systems lacks humanized humancomputer interaction relying only on based buttons, joysticks or human voice. Such methods can not be well applied to groups with limited limbs, weak body and tired mind. In this paper, we propose a food demand recognition method for the disabled and the sick based on micro facial posture capture. This method can capture the key points of face and face in real-time and accurately, so as to identify whether the user is eating, ready for new food or refusing to eat the food picked up by the robot, and optimize the human-computer interaction method. The effectiveness of the proposed method is proved by experiments.",2022-04-22,2022-09-02T13:30:05Z,2022-09-02T13:30:05Z,NA,1-5,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Journal Abbreviation: 2022 4th International Conference on Advances in Computer Technology, Information Science and Communications (CTISC)",NA,NA,NA,deep learning; Performance evaluation; Computational modeling; Human computer interaction; Information science; Real-time systems; Face recognition; Solid modeling; face detection; human-computer interaction,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"2022 4th International Conference on Advances in Computer Technology, Information Science and Communications (CTISC)",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,TQYNRKBX,conferencePaper,2010,P. W. Aung Aung; S. F. V. Foo; W. Huang; J. Biswas; J. E. Phua; K. Liou; C. -C. Hsia,Evaluation and analysis of multimodal sensors for developing in and around the bed patient monitoring system,2010 Annual International Conference of the IEEE Engineering in Medicine and Biology,1558-4615,NA,10.1109/IEMBS.2010.5626375,NA,"Due to the decline in physical and cognitive abilities, many frail elderly may have to lie in the bed most of their time. It is not feasible to monitor them continuously through manual observations alone. This issue can be resolved by embedding a set of multimodal sensors into the bed and providing automated activity recognition intelligence. But it is important to design and develop such multimodal sensing intelligence system desirable to the demands made by the clinicians. This paper presents the comparison and evaluation of different sensing bed configurations to observe different granularities of patient's contexts and activities in and around the bed. Based on the achievements and lessons learned from the experimental analysis, we propose improved sensing bed hardware and software systems to meet the real needs of in and around the bed patient monitoring.",2010-09-31,2022-09-02T13:30:08Z,2022-09-02T13:30:08Z,NA,2159-2162,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Journal Abbreviation: 2010 Annual International Conference of the IEEE Engineering in Medicine and Biology,NA,NA,NA,Artificial intelligence; Monitoring; Context; Intelligent sensors; Multimodal sensors; Ultrasonic imaging,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,2010 Annual International Conference of the IEEE Engineering in Medicine and Biology,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,WL83R47W,journalArticle,2015,J. J. Liu; M. -C. Huang; W. Xu; X. Zhang; L. Stevens; N. Alshurafa; M. Sarrafzadeh,BreathSens: A Continuous On-Bed Respiratory Monitoring System With Torso Localization Using an Unobtrusive Pressure Sensing Array,IEEE Journal of Biomedical and Health Informatics,NA,2168-2208,10.1109/JBHI.2014.2344679,NA,"The ability to continuously monitor respiration rates of patients in homecare or in clinics is an important goal. Past research showed that monitoring patient breathing can lower the associated mortality rates for long-term bedridden patients. Nowadays, in-bed sensors consisting of pressure sensitive arrays are unobtrusive and are suitable for deployment in a wide range of settings. Such systems aim to extract respiratory signals from time-series pressure sequences. However, variance of movements, such as unpredictable extremities activities, affect the quality of the extracted respiratory signals. BreathSens, a high-density pressure sensing system made of e-Textile, profiles the underbody pressure distribution and localizes torso area based on the high-resolution pressure images. With a robust bodyparts localization algorithm, respiratory signals extracted from the localized torso area are insensitive to arbitrary extremities movements. In a study of 12 subjects, BreathSens demonstrated its respiratory monitoring capability with variations of sleep postures, locations, and commonly tilted clinical bed conditions.",2015-09,2022-09-02T13:30:09Z,2022-09-02T13:30:09Z,NA,1682-1688,NA,5,19,NA,IEEE Journal of Biomedical and Health Informatics,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Monitoring; Sensors; Hip; Hospitals; Biomedical measurement; pressure sensor; Arrays; Pictorial structure; respiration monitoring; signal extraction; Torso,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,S82M6BGE,journalArticle,2019,Q. Xie; Y. Li; G. Wang; Y. Lian,An Unobtrusive System for Heart Rate Monitoring Based on Ballistocardiogram Using Hilbert Transform and Viterbi Decoding,IEEE Journal on Emerging and Selected Topics in Circuits and Systems,NA,2156-3365,10.1109/JETCAS.2019.2951411,NA,"This paper presents an unobtrusive system for monitoring heart rate (HR) based on ballistocardiogram (BCG). The system contains a piezoelectric sensor, which can be embedded into a chair or bed, to convert small body vibrations caused by heart beating into BCG signal and a novel algorithm to estimate HR from the BCG. The algorithm employs the Hilbert Transform to reveal the frequency content of J-peak in the BCG signal for HR estimation. The Viterbi Decoding is applied to improve the HR accuracy for noisy BCG signal by finding the most likely path through time-frequency state-space plane. The performance of the proposed algorithm is evaluated by BCG recordings from 32 subjects. Mean absolute error (MAE) of 2.17 beats per minute (BPM) and standard deviation of absolute error (SDAE) of 2.34 BPM are achieved. Pearson correlation coefficient of 0.956 between estimated HR and true HR is obtained.",2019-12,2022-09-02T13:30:11Z,2022-09-02T13:30:11Z,NA,635-644,NA,4,9,NA,IEEE Journal on Emerging and Selected Topics in Circuits and Systems,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Electrocardiography; heart rate; Biomedical monitoring; Heart rate; Ballistocardiogram; Transforms; Vibrations; Hilbert transform; Piezoelectric devices; piezoelectric element; Viterbi decoding,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,9D9NCDP5,conferencePaper,2009,I. Pek; A. B. Waluyo; W. -S. Yeoh; X. Chen,Motion-based wake-up scheme for ambulatory monitoring in wireless body sensor networks,2009 Annual International Conference of the IEEE Engineering in Medicine and Biology Society,1558-4615,NA,10.1109/IEMBS.2009.5334702,NA,"Given that wearable sensors that are attached on patients for the purpose of continuous real-time medical monitoring typically need to remain operational for periods of up to 24 hours before a battery change or recharge, power preservation schemes play a critical role in minimizing any possible disruption to a patient's daily activities. In this paper, we propose a motion-based wake-up scheme, a feature which combines motion detection with existing power preservation schemes in order to achieve a balance between energy saving and data timeliness, particularly in critical situations. As a showcase, we have integrated this feature with a healthcare application and demonstrate the capability of the scheme to deal with critical events, e.g., when a patient falls down from the bed. This showcase affirms the effective uses of our proposed motion-based wake-up scheme.",2009-09-03,2022-09-02T13:30:12Z,2022-09-02T13:30:12Z,NA,2454-2457,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Journal Abbreviation: 2009 Annual International Conference of the IEEE Engineering in Medicine and Biology Society,NA,NA,NA,Support vector machines; Bayesian methods; Monitoring; Principal component analysis; Medical services; Support vector machine classification; Intelligent sensors; Wireless sensor networks; Algorithm design and analysis; Body sensor networks,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,2009 Annual International Conference of the IEEE Engineering in Medicine and Biology Society,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,P2HXXS5N,conferencePaper,2005,K. Cheikhrouhou; S. Affes; A. Elderini; B. Smida; P. Mermelstein; B. Sultana; V. Sampath,On-line analysis/synthesis-based channel parameters estimation and wideband CDMA receiver design verification,"VTC-2005-Fall. 2005 IEEE 62nd Vehicular Technology Conference, 2005.",1090-3038,NA,10.1109/VETECF.2005.1557955,NA,NA,2005-09-28,2022-09-02T13:30:13Z,2022-09-02T13:30:13Z,NA,468-472,NA,NA,1,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Journal Abbreviation: VTC-2005-Fall. 2005 IEEE 62nd Vehicular Technology Conference, 2005.",NA,NA,NA,Data mining; Parameter estimation; Data models; Time measurement; Receiving antennas; Delay effects; Delay estimation; Interference; Multiaccess communication; Wideband,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"VTC-2005-Fall. 2005 IEEE 62nd Vehicular Technology Conference, 2005.",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,UW7ND6SY,journalArticle,2014,D. W. Jung; S. H. Hwang; H. N. Yoon; Y. -J. G. Lee; D. -U. Jeong; K. S. Park,Nocturnal Awakening and Sleep Efficiency Estimation Using Unobtrusively Measured Ballistocardiogram,IEEE Transactions on Biomedical Engineering,NA,1558-2531,10.1109/TBME.2013.2278020,NA,"Fragmented sleep due to frequent awakenings represents a major cause of impaired daytime performance and adverse health outcomes. Currently, the gold standard for studying and assessing sleep fragmentation is polysomnography (PSG). Here, we propose an alternative method for real-time detection of nocturnal awakening via ballistocardiography using an unobtrusive polyvinylidene fluoride (PVDF) film sensor on a bed mattress. From ballistocardiogram, heart rate and body movement information were extracted to develop an algorithm for classifying sleeping and awakening epochs. In total, ten normal subjects (mean age 38.7 ± 14.6 years) and ten patients with obstructive sleep apnea (OSA) (mean age 44.2 ± 16.5 years) of varying symptom severity participated in this study. Our study detected awakening epochs with an average sensitivity of 85.3% and 85.2%, specificity of 98.4% and 97.7%, accuracy of 97.4% and 96.5%, and Cohen's kappa coefficient of 0.83 and 0.81 for normal subjects and OSA patients, respectively. Also, sleep efficiency was estimated using detected awakening epochs and then compared with PSG results. Mean absolute errors in sleep efficiency were 1.08% and 1.44% for normal subjects and OSA patients, respectively. The results presented here indicate that our suggested method could be reliably applied to real-time nocturnal awakening detection and sleep efficiency estimation. Furthermore, our method may ultimately be an effective tool for long-term, home monitoring of sleep-wake behavior.",2014-01,2022-09-02T13:30:17Z,2022-09-02T13:30:17Z,NA,131-138,NA,1,61,NA,IEEE Transactions on Biomedical Engineering,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Monitoring; Electrocardiography; sleep efficiency; Sleep apnea; Educational institutions; Heart rate; Ballistocardiogram (BCG); Films; heart rate (HR); nocturnal awakening; sleep fragmentation,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,Z83FS5LV,conferencePaper,2007,G. S. Chung; B. H. Choi; D. -U. Jeong; K. S. Park,Noninvasive Heart Rate Variability Analysis Using Loadcell-Installed Bed During Sleep,2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society,1558-4615,NA,10.1109/IEMBS.2007.4352800,NA,"Polysomnography is the standard method to score the sleep stages or to determine the quality of sleep. During all night examination, subjects must attach complicate and numerous electrodes on their body to acquire the biosignals. They can influence participants' sleep stage transition or sleep pattern, and the method seems intricate. In many researches, it is reported that autonomic nervous system (ANS) is varying with sleep stage transition and heart rate variability (HRV) is one of the indices which reflects the changes of autonomic nervous system. In this point of view, we can estimate the sleep quality by observing the HRV variation. In this study, to analyze the heart rate variability, we introduce a new system that can detect the heart beats of subjects during sleep by using bed installed load-cell sensors. The pressure to the sensor changes with the pulsation of the heart and we consider it as ballistocardiogram, the physical heart beat signal. To validate our system, we adopted this system for the 4 subjects with the polysomnography. The results show the LF/HF ratio of the heart rate, one of the reflection parameters of ANS, acquired from the system for each sleep stage. To validate the results, the HRV from electrocardiogram using Ag-AgCl electrodes will be compared.",2007-08-22,2022-09-02T13:30:17Z,2022-09-02T13:30:17Z,NA,2357-2360,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Journal Abbreviation: 2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society,NA,NA,NA,Electrodes; Sleep; Heart rate; Sensor systems; Heart beat; Heart rate variability; Autonomic nervous system; Hafnium; Heart rate detection; Reflection,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,AXDYBSGJ,journalArticle,2010,J. H. Shin; Y. J. Chee; D. -U. Jeong; K. S. Park,Nonconstrained Sleep Monitoring System and Algorithms Using Air-Mattress With Balancing Tube Method,IEEE Transactions on Information Technology in Biomedicine,NA,1558-0032,10.1109/TITB.2009.2034011,NA,"We evaluated the performance of a bed-type sensor system using the air-mattress with balancing tube (AMBT) method to noninvasively monitor the signals of heartbeat, respiration, and events of snoring, sleep apnea and body movement of subject on the system. The proposed system consists of multiple cylindrical air cells, two sensor cells and 18 support cells, and the small physiological signals were measured by the changes in pressure difference between the sensor cells, and the dc component was removed by balancing tube that is connecting the sensor cells. Using newly developed AMBT method, heartbeat, respiration, snoring, and body movement signals were clearly measured. For the concept of a home healthcare system, two automatic processing algorithms were developed: one is to estimate the mean heart and respiration rates for every 30 s, and another one is to detect the snoring, sleep apnea, and body movement events from the measured signals. In the beat-to-beat heart rate and breath-by-breath respiration rate analyses, the correlation coefficients of the heart and respiration rates from the proposed AMBT method compared with reference methods, electrocardiogram, and respiration effort signal from piezoelectric belt, were 0.98 (p < 0.01) and 0.96 (p < 0.01), respectively. Sensitivity and positive predictive value (PPV) of the detection algorithm for snoring event were 93%, 96%, for sleep apnea event were 93%, 88%, and for body movement event were 86%, 100%, respectively. These findings support that ABMT method provides an accurate and reliable means to monitor heartbeat, respiration activities and the sleep events during sleep.",2010-01,2022-09-02T13:30:17Z,2022-09-02T13:30:17Z,NA,147-156,NA,1,14,NA,IEEE Transactions on Information Technology in Biomedicine,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Signal processing; Medical services; Biomedical monitoring; Sleep apnea; sleep monitoring; Pressure measurement; Sensor systems; Heart beat; Heart rate detection; Event detection; respiration; Air-mattress and balancing tube; heartbeat; Joining processes; noninvasive; snoring detection,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,6MB6TRKZ,conferencePaper,2022,R. Oñate-López; G. Palacios-Navarro; I. García-Magariño,Smart bed sensor for detection of sleep disorders in patients with Parkinson's disease,"2022 Congreso de Tecnología, Aprendizaje y Enseñanza de la Electrónica (XV Technologies Applied to Electronics Teaching Conference)",2766-2616,NA,10.1109/TAEE54169.2022.9840578,NA,"Most of the patients with Parkinson&#x0027;s disease present problems in their nighttime sleeping hours caused by REM sleep behavior disorder, restless legs syndrome, periodic leg movement, excessive daytime sleepiness, restless sleep, sleep apneas during sleep, primary insomnia, and all other sleep disorders. The main objective of the work is the implementation of a smart bed sensor for the detection of sleep disorders in patients with Parkinson&#x0027;s disease to improve sleep quality and user experience, employing highly sensitive resistive sensors and internet of things (IoT) technology. Thanks to the smart sensor, it will be able to acquire information such as, respiratory rate, heart rate and posture of the user. The device will be low cost, highly durable, comfortable, easy to install regardless of the type of mattress or foundations, with its own app for easy management, configuration and historical data collection.",2022-07-29,2022-09-02T13:30:18Z,2022-09-02T13:30:18Z,NA,1-4,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"Journal Abbreviation: 2022 Congreso de Tecnología, Aprendizaje y Enseñanza de la Electrónica (XV Technologies Applied to Electronics Teaching Conference)",NA,NA,NA,Parkinson's disease; IoT; User experience; Education; Sleep; smart bed; Sleep apnea; Heart rate; Legged locomotion; resistive sensor; sleep problems,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,"2022 Congreso de Tecnología, Aprendizaje y Enseñanza de la Electrónica (XV Technologies Applied to Electronics Teaching Conference)",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,HQ7F9EKY,conferencePaper,2008,H. Knight; J. -K. Lee; H. Ma,Chair Alarm for patient fall prevention based on Gesture Recognition and Interactivity,2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society,1558-4615,NA,10.1109/IEMBS.2008.4650012,NA,"The Gesture Recognition Interactive Technology (GRiT) Chair Alarm aims to prevent patient falls from chairs and wheelchairs by recognizing the gesture of a patient attempting to stand. Patient falls are one of the greatest causes of injury in hospitals. Current chair and bed exit alarm systems are inadequate because of insufficient notification, high false-alarm rate, and long trigger delays. The GRiT chair alarm uses an array of capacitive proximity sensors and pressure sensors to create a map of the patient's sitting position, which is then processed using gesture recognition algorithms to determine when a patient is attempting to stand and to alarm the care providers. This system also uses a range of voice and light feedback to encourage the patient to remain seated and/or to make use of the system's integrated nurse-call function. This system can be seamlessly integrated into existing hospital WiFi networks to send notifications and approximate patient location through existing nurse call systems.",2008-08-20,2022-09-02T13:30:19Z,2022-09-02T13:30:19Z,NA,3698-3701,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Journal Abbreviation: 2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,P974H388,conferencePaper,2011,T. -Y. Wang; S. -L. Chen; H. -C. Huang; S. -H. Kuo; Y. -J. Shiu,The development of an intelligent monitoring and caution system for pressure ulcer prevention,2011 International Conference on Machine Learning and Cybernetics,2160-1348,NA,10.1109/ICMLC.2011.6016779,NA,"An intelligent remote monitoring and caution system was designed and developed for prevention of pressure ulcer. The developed system uses a ZigBee network infrastructure with pressure sensors to monitor pressured positions for mobility-impaired persons on the bed. The main purpose of this study is intended to increase ulcer prevention awareness, and to facilitate the fulfillment of pressure ulcer management procedures. With the support of the developed system, the incidence of pressure ulcers can be controlled, which will increase both the quality of healthcare and life quality of the patient with impaired mobility who are hospitalized or stay in long-term care facilities.",2011-07-10,2022-09-02T13:30:19Z,2022-09-02T13:30:19Z,NA,566-571,NA,NA,2,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Journal Abbreviation: 2011 International Conference on Machine Learning and Cybernetics,NA,NA,NA,Monitoring; Medical services; Remote monitoring; Biomedical monitoring; Sensor systems; Alarm; Data communication; Position detection; Pressure ulcer prevention; Zigbee,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,2011 International Conference on Machine Learning and Cybernetics,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,B2X268AA,conferencePaper,2018,C. -N. Lee; S. -C. Yang; C. -K. Li; M. -Z. Liu; P. -C. Kuo,Alarm System For Bed Exit And Prolonged Bed Rest,2018 International Conference on Machine Learning and Cybernetics (ICMLC),2160-1348,NA,10.1109/ICMLC.2018.8527027,NA,"In this study, we designed a system that senses bed pressure levels and provides alarms for bed exit and prolonged bed rest; the system uses pressure sensors, a single-chip microcontroller, and a computer. The designed system enables reducing bed exit falls due to muscle weakness among hospitalized patients, preventing pressure injury among patients restricted to prolonged bed rest, preventing wandering behavior among patients with dementia, and reducing the workload of nurses. Furthermore, the system can serve as an adequate substitute in situations in which 24-hours monitoring is impractical; additionally, it is a low-cost alternative to existing alarm systems. Therefore, this alarm system can be adopted as common medical-care equipment for hospitals and nursing homes.",2018-07-15,2022-09-02T13:30:20Z,2022-09-02T13:30:20Z,NA,439-443,NA,NA,2,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Journal Abbreviation: 2018 International Conference on Machine Learning and Cybernetics (ICMLC),NA,NA,NA,Alarm system; Bed exit falls; Pressure injury,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,2018 International Conference on Machine Learning and Cybernetics (ICMLC),NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
ieeex,settembre,NU3MK63K,journalArticle,2014,C. -W. Wang; A. Hunter; N. Gravill; S. Matusiewicz,Unconstrained Video Monitoring of Breathing Behavior and Application to Diagnosis of Sleep Apnea,IEEE Transactions on Biomedical Engineering,NA,1558-2531,10.1109/TBME.2013.2280132,NA,"This paper presents a new real-time automated infrared video monitoring technique for detection of breathing anomalies, and its application in the diagnosis of obstructive sleep apnea. We introduce a novel motion model to detect subtle, cyclical breathing signals from video, a new 3-D unsupervised self-adaptive breathing template to learn individuals' normal breathing patterns online, and a robust action classification method to recognize abnormal breathing activities and limb movements. This technique avoids imposing positional constraints on the patient, allowing patients to sleep on their back or side, with or without facing the camera, fully or partially occluded by the bed clothes. Moreover, shallow and abdominal breathing patterns do not adversely affect the performance of the method, and it is insensitive to environmental settings such as infrared lighting levels and camera view angles. The experimental results show that the technique achieves high accuracy (94% for the clinical data) in recognizing apnea episodes and body movements and is robust to various occlusion levels, body poses, body movements (i.e., minor head movement, limb movement, body rotation, and slight torso movement), and breathing behavior (e.g., shallow versus heavy breathing, mouth breathing, chest breathing, and abdominal breathing).",2014-02,2022-09-02T13:30:21Z,2022-09-02T13:30:21Z,NA,396-404,NA,2,61,NA,IEEE Transactions on Biomedical Engineering,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Monitoring; Sensors; Noise; Sleep apnea; Cameras; Motion detection; Action recognition; Adaptation models; behavior analysis; breathing monitoring; obstructive sleep apnea (OSA),NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
pubmed,settembre,ELNNJZ9L,journalArticle,2022,"Miller, Dean J.; Sargent, Charli; Roach, Gregory D.","A Validation of Six Wearable Devices for Estimating Sleep, Heart Rate and Heart Rate Variability in Healthy Adults.","Sensors (Basel, Switzerland)",NA,1424-8220,10.3390/s22166317,NA,"The primary aim of this study was to examine the validity of six commonly used wearable devices, i.e., Apple Watch S6, Garmin Forerunner 245 Music, Polar  Vantage V, Oura Ring Generation 2, WHOOP 3.0 and Somfit, for assessing sleep. The  secondary aim was to examine the validity of the six devices for assessing heart  rate and heart rate variability during, or just prior to, night-time sleep.  Fifty-three adults (26 F, 27 M, aged 25.4 ± 5.9 years) spent a single night in a  sleep laboratory with 9 h in bed (23:00-08:00 h). Participants were fitted with  all six wearable devices-and with polysomnography and electrocardiography for  gold-standard assessment of sleep and heart rate, respectively. Compared with  polysomnography, agreement (and Cohen's kappa) for two-state categorisation of  sleep periods (as sleep or wake) was 88% (κ = 0.30) for Apple Watch; 89% (κ =  0.35) for Garmin; 87% (κ = 0.44) for Polar; 89% (κ = 0.51) for Oura; 86% (κ =  0.44) for WHOOP and 87% (κ = 0.48) for Somfit. Compared with polysomnography,  agreement (and Cohen's kappa) for multi-state categorisation of sleep periods (as  a specific sleep stage or wake) was 53% (κ = 0.20) for Apple Watch; 50% (κ =  0.25) for Garmin; 51% (κ = 0.28) for Polar; 61% (κ = 0.43) for Oura; 60% (κ =  0.44) for WHOOP and 65% (κ = 0.52) for Somfit. Analyses regarding the two-state  categorisation of sleep indicate that all six devices are valid for the  field-based assessment of the timing and duration of sleep. However, analyses  regarding the multi-state categorisation of sleep indicate that all six devices  require improvement for the assessment of specific sleep stages. As the use of  wearable devices that are valid for the assessment of sleep increases in the  general community, so too does the potential to answer research questions that  were previously impractical or impossible to address-in some way, we could  consider that the whole world is becoming a sleep laboratory.",2022-08-22,2022-09-02T13:08:22Z,2022-09-02T13:08:22Z,NA,NA,NA,16,22,NA,Sensors (Basel),NA,NA,NA,NA,NA,NA,NA,eng,NA,NA,NA,NA,NA,NA,PMID: 36016077  PMCID: PMC9412437,NA,NA,NA,Humans; Adult; sleep quality; Sleep Stages/physiology; Polysomnography; cardiovascular health; Heart Rate/physiology; Sleep/physiology; *Wearable Electronic Devices; consumer sleep technology; sleep quantity; sleep staging; autonomic nervous system; autonomic modulation; photoplethysmography; wearable sleep monitor,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
pubmed,settembre,CFJ9XPB7,journalArticle,2022,"Bitkina, Olga Vl; Park, Jaehyun; Kim, Jungyoon",Modeling Sleep Quality Depending on Objective Actigraphic Indicators Based on Machine Learning Methods.,International journal of environmental research and public health,NA,1660-4601 1661-7827,10.3390/ijerph19169890,NA,"According to data from the World Health Organization and medical research centers, the frequency and severity of various sleep disorders, including  insomnia, are increasing steadily. This dynamic is associated with increased  daily stress, anxiety, and depressive disorders. Poor sleep quality affects  people's productivity and activity and their perception of quality of life in  general. Therefore, predicting and classifying sleep quality is vital to  improving the quality and duration of human life. This study offers a model for  assessing sleep quality based on the indications of an actigraph, which was used  by 22 participants in the experiment for 24 h. Objective indicators of the  actigraph include the amount of time spent in bed, sleep duration, number of  awakenings, and duration of awakenings. The resulting classification model was  evaluated using several machine learning methods and showed a satisfactory  accuracy of approximately 80-86%. The results of this study can be used to treat  sleep disorders, develop and design new systems to assess and track sleep  quality, and improve existing electronic devices and sensors.",2022-08-11,2022-09-02T13:08:22Z,2022-09-02T13:08:22Z,NA,NA,NA,16,19,NA,Int J Environ Res Public Health,NA,NA,NA,NA,NA,NA,NA,eng,NA,NA,NA,NA,NA,NA,PMID: 36011524  PMCID: PMC9408084,NA,NA,NA,machine learning; Machine Learning; Humans; support vector machine; actigraphy; Sleep; sleep quality; Quality of Life; Actigraphy/methods; *Sleep Wake Disorders/epidemiology; Sleep Quality; *Sleep Initiation and Maintenance Disorders; k-nearest neighbors; naïve Bayes,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
pubmed,settembre,9AICWCM9,journalArticle,2022,"Romyn, Georgia; Roach, Gregory D.; Lastella, Michele; Miller, Dean J.; Versey, Nathan G.; Sargent, Charli","The Impact of Sleep Inertia on Physical, Cognitive, and Subjective Performance Following a 1- or 2-Hour Afternoon Nap in Semiprofessional Athletes.",International journal of sports physiology and performance,NA,1555-0273 1555-0265,10.1123/ijspp.2021-0414,NA,"PURPOSE: This study examined the impact of sleep inertia on physical, cognitive, and subjective performance immediately after a 1- or 2-hour afternoon nap  opportunity. METHODS: Twelve well-trained male athletes completed 3 conditions in  a randomized, counterbalanced order-9 hours in bed overnight without a nap  opportunity the next day (9 + 0), 8 hours in bed overnight with a 1-hour nap  opportunity the next day (8 + 1), and 7 hours in bed overnight with a 2-hour nap  opportunity the next day (7 + 2). Nap opportunities ended at 4:00 PM. Sleep was  assessed using polysomnography. Following each condition, participants completed  four 30-minute test batteries beginning at 4:15, 4:45, 5:15, and 5:45 PM. Test  batteries included a warm-up, self-ratings of readiness to perform, motivation to  perform and expected performance, two 10-m sprints, 2 agility tests, a 90-second  response-time task, and 5 minutes of seated rest. RESULTS: Total sleep time was  not different between conditions (P = .920). There was an effect of condition on  readiness (P < .001), motivation (P = .001), and expected performance (P =  .004)-all 3 were lower in the 8 + 1 and 7 + 2 conditions compared with the 9 + 0  condition. There was no effect of condition on response time (P = .958), sprint  time (P = .204), or agility (P = .240), but a large effect size was observed for  agility. CONCLUSIONS: After waking from a nap opportunity, agility may be  reduced, and athletes may feel sleepy and not ready or motivated to perform.  Athletes should schedule sufficient time (∼1 h) after waking from a nap  opportunity to avoid the effects of sleep inertia on performance.",2022-07-01,2022-09-02T13:08:22Z,2022-09-02T13:08:22Z,NA,1140-1150,NA,7,17,NA,Int J Sports Physiol Perform,NA,NA,NA,NA,NA,NA,NA,eng,NA,NA,NA,NA,NA,NA,Place: United States PMID: 35606094,NA,NA,NA,Humans; Male; Cognition; Polysomnography; Athletes; Sleep Deprivation; sleepiness; *Sleep/physiology; motivation; *Wakefulness/physiology; agility; response time; sleep timing; speed,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
pubmed,settembre,7IL87EQP,journalArticle,2022,"Klier, Kristina; Wagner, Matthias",Agreement of Sleep Measures-A Comparison between a Sleep Diary and Three Consumer Wearable Devices.,"Sensors (Basel, Switzerland)",NA,1424-8220,10.3390/s22166189,NA,"Nowadays, self-tracking and optimization are widely spread. As sleep is essential for well-being, health, and peak performance, the number of available consumer  technologies to assess individual sleep behavior is increasing rapidly. However,  little is known about the consumer wearables' usability and reliability for sleep  tracking. Therefore, the aim of the present study was to compare the sleep  measures of wearable devices with a standardized sleep diary in young healthy  adults in free-living conditions. We tracked night sleep from 30 participants (19  females, 11 males; 24.3 ± 4.2 years old). Each wore three wearables and  simultaneously assessed individual sleep patterns for four consecutive nights.  Wearables and diaries correlated substantially regarding time in bed (Range  CCC(Lin): 0.74-0.84) and total sleep time (Range CCC(Lin): 0.76-0.85). There was  no sufficient agreement regarding the measures of sleep efficiency (Range  CCC(Lin): 0.05-0.34) and sleep interruptions (Range CCC(Lin): -0.02-0.10).  Finally, these results show wearables to be an easy-to-handle, time- and  cost-efficient alternative to tracking sleep in healthy populations. Future  research should develop and empirically test the usability of such consumer sleep  technologies.",2022-08-18,2022-09-02T13:08:22Z,2022-09-02T13:08:22Z,NA,NA,NA,16,22,NA,Sensors (Basel),NA,NA,NA,NA,NA,NA,NA,eng,NA,NA,NA,NA,NA,NA,PMID: 36015949  PMCID: PMC9413956,NA,NA,NA,Humans; Female; Male; Adult; Young Adult; wearable devices; Reproducibility of Results; sleep; Sleep; *Wearable Electronic Devices; Polysomnography/methods; self-tracking; concordance; sleep assessment; sleep diaries,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
pubmed,settembre,F4R5VSPW,journalArticle,2022,"Howarth, Timothy P.; Gentin, Natalie; Reyes-Chicuellar, Nayellin; Jonas, Catherine; Williamson, Bruce; Blecher, Greg; Widger, John; Heraganahally, Subash S.",Sleep quality and obstructive sleep apnoea in Indigenous and non-Indigenous Australian children.,Sleep medicine,NA,1878-5506 1389-9457,10.1016/j.sleep.2022.06.014,NA,"BACKGROUND: Literature pertaining to the prevalence of obstructive sleep apnoea (OSA) and sleep quality among Indigenous Australian children is sparse. This  study assessed various sleep related parameters and outcomes between Indigenous  and non-Indigenous Australian children. METHODS: Children referred to the sleep  health service in the Northern Territory of Australia for a clinically suspected  sleep disorder between 2015 and 2021 were included in this study. Self-reported  sleep measures alongside polysomnography data were assessed and compared between  these two diverse ethnic population. RESULTS: Of the 671 sleep studies assessed,  121 (18%) were from Indigenous children. The majority of patients were male  (61%), with a median age of 5.7 (3.5, 8.9) years, and body mass index (BMI) in  the normal range (57%). Indigenous children were significantly older (median 7.2  years (4.5, 11.9), with a higher BMI (p = 0.005) and a greater proportion living  in very remote locality (14% vs. 6% non-Indigenous, p = 0.001). Indigenous  children had higher Paediatric Daytime Sleepiness Scale scores (p = 0.001),  higher screen use before bed (p = 0.005), later bedtimes (p = 0.001) and reduced  total sleep time (p = 0.034) compared to non-Indigenous children. Prevalence of  OSA was higher in Indigenous children (55% vs. 48%) and with greater severity  compared to non-Indigenous children. CONCLUSIONS: In this study, OSA was more  prevalent and more severe in Indigenous children than their non-Indigenous peers.  However, this may not necessarily be extrapolated to the general Indigenous  paediatric population. Sleep hygiene and sleep quantity was also decreased  further impacting adequate sleep. This highlights the importance of identifying  and managing these addressable parameters and for targeted interventions.",2022-10,2022-09-02T13:08:22Z,2022-09-02T13:08:22Z,NA,68-78,NA,NA,98,NA,Sleep Med,NA,NA,NA,NA,NA,NA,NA,eng,Copyright © 2022 Elsevier B.V. All rights reserved.,NA,NA,NA,NA,NA,Place: Netherlands PMID: 35785588,NA,NA,NA,"Humans; Child; Female; Male; Obesity; Polysomnography; Australia/epidemiology; *Disorders of Excessive Somnolence; Sleep Quality; OSA; *Sleep Apnea, Obstructive/epidemiology; Aboriginal; First nations; Paediatric",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
pubmed,settembre,G244RH22,journalArticle,2022,"Kent, Brianne A.; Casciola, Amelia A.; Carlucci, Sebastiano K.; Chen, Meghan; Stager, Sam; Mirian, Maryam S.; Slack, Penelope; Valerio, Jason; McKeown, Martin J.; Feldman, Howard H.; Nygaard, Haakon B.",Home EEG sleep assessment shows reduced slow-wave sleep in mild-moderate Alzheimer's disease.,"Alzheimer's & dementia (New York, N. Y.)",NA,2352-8737,10.1002/trc2.12347,NA,"INTRODUCTION: Sleep disturbances are common in Alzheimer's disease (AD), with estimates of prevalence as high as 65%. Recent work suggests that specific sleep  stages, such as slow-wave sleep (SWS) and rapid eye movement (REM), may directly  impact AD pathophysiology. A major limitation to sleep staging is the requirement  for clinical polysomnography (PSG), which is often not well tolerated in patients  with dementia. We have recently developed a deep learning model to reliably  analyze lower quality electroencephalogram (EEG) data obtained from a simple,  two-lead EEG headband. Here we assessed whether this methodology would allow for  home EEG sleep staging in patients with mild-moderate AD. METHODS: A total of 26  mild-moderate AD patients and 24 age-matched, healthy control participants  underwent home EEG sleep recordings as well as actigraphy and subjective sleep  measures through the Pittsburgh Sleep Quality Index (PSQI). Each participant wore  the EEG headband for up to three nights. Sleep was staged using a deep learning  model previously developed by our group, and sleep stages were correlated with  actigraphy measures as well as PSQI scores. RESULTS: We show that home EEG with a  headband is feasible and well tolerated in patients with AD. Patients with  mild-moderate AD were found to spend less time in SWS compared to healthy control  participants. Other sleep stages were not different between the two groups.  Actigraphy or the PSQI were not found to predict home EEG sleep stages.  DISCUSSION: Our data show that home EEG is well tolerated, and can ascertain  reduced SWS in patients with mild-moderate AD. Similar findings have previously  been reported, but using clinical PSG not suitable for the home environment. Home  EEG will be particularly useful in future clinical trials assessing potential  interventions that may target specific sleep stages to alter the pathogenesis of  AD. HIGHLIGHTS: Home electroencephalogram (EEG) sleep assessments are important  for measuring sleep in patients with dementia because polysomnography is a  limited resource not well tolerated in this patient population.Simplified at-home  EEG for sleep assessment is feasible in patients with mild-moderate Alzheimer's  disease (AD).Patients with mild-moderate AD exhibit less time spent in slow-wave  sleep in the home environment, compared to healthy control participants.Compared  to healthy control participants, patients with mild-moderate AD spend more time  in bed, with decreased sleep efficiency, and more awakenings as measured by  actigraphy, but these measures do not correlate with EEG sleep stages.",2022,2022-09-02T13:08:22Z,2022-09-02T13:08:22Z,NA,e12347,NA,1,8,NA,Alzheimers Dement (N Y),NA,NA,NA,NA,NA,NA,NA,eng,© 2022 The Authors. Alzheimer's & Dementia: Translational Research & Clinical Interventions published by Wiley Periodicals LLC on behalf of Alzheimer's  Association.,NA,NA,NA,NA,NA,PMID: 35992215  PMCID: PMC9381912,NA,NA,NA,deep learning; Alzheimer's disease; actigraphy; polysomnography; Pittsburgh Sleep Quality Index; sleep staging; home electroencephalogram; N3; rapid eye movement; slow‐wave sleep,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
pubmed,settembre,NZWVAUVJ,journalArticle,2022,"Kundel, Vaishnavi; Agyapong, Prince Darko; Parekh, Ankit; Kaali, Seyram; Prah, Rebecca Kyerewaa Dwommoh; Taweesedt, Pahnwat; Tawiah, Theresa; Ayappa, Indu; Mujtaba, Mohammed Nuhu; Agyei, Oscar; Jack, Darby; Osei, Musah; Kwarteng, Adolphine Adofowa; Lee, Alison; Asante, Kwaku Poku",Characterizing sleep-wake patterns in mothers and children in an agrarian community: results from the Ghana Randomized Air Pollution and Health Study.,Sleep,NA,1550-9109 0161-8105,10.1093/sleep/zsac033,NA,"STUDY OBJECTIVES: Several studies have examined sleep patterns in rural/indigenous communities, however little is known about sleep characteristics  in women of reproductive age, and children within these populations. We  investigate sleep-wake patterns in mothers and children (ages 3-5 years)  leveraging data from the Ghana Randomized Air Pollution and Health Study  (GRAPHS). METHODS: The GRAPHS cohort comprises of rural/agrarian communities in  Ghana and collected multiday actigraphy in a subset of women and children to  assess objective sleep-wake patterns. Data were scored using the Cole-Kripke and  Sadeh algorithms for mothers/children. We report descriptive, baseline  characteristics and objective sleep measures, compared by access to  electricity/poverty status. RESULTS: We analyzed data for 58 mothers (mean age 33  ± 6.6) and 64 children (mean age 4 ± 0.4). For mothers, mean bedtime was 9:40 pm  ± 56 min, risetime 5:46 am ± 40 min, and total sleep time (TST) was 6.3 h ± 46  min. For children, median bedtime was 8:07 pm (interquartile range [IQR]:  7:50,8:43), risetime 6:09 am (IQR: 5:50,6:37), and mean 24-h TST 10.44 h ± 78  min. Children with access to electricity had a reduced TST compared to those  without electricity (p = 0.02). Mean bedtime was later for both mothers (p =  0.05) and children (p = 0.08) classified as poor. CONCLUSIONS: Mothers in our  cohort demonstrated a shorter TST, and earlier bed/risetimes compared to adults  in postindustrialized nations. In contrast, children had a higher TST compared to  children in postindustrialized nations, also with earlier sleep-onset and offset  times. Investigating objective sleep-wake patterns in rural/indigenous  communities can highlight important differences in sleep health related to sex,  race/ethnicity, and socioeconomic status, and help estimate the impact of  industrialization on sleep in developed countries.",2022-08-11,2022-09-02T13:08:22Z,2022-09-02T13:08:22Z,NA,NA,NA,8,45,NA,Sleep,NA,NA,NA,NA,NA,NA,NA,eng,"© The Author(s) 2022. Published by Oxford University Press on behalf of Sleep Research Society. All rights reserved. For permissions, please e-mail:  journals.permissions@oup.com.",NA,NA,NA,NA,NA,PMID: 35143676  PMCID: PMC9366631,NA,NA,NA,"Humans; actigraphy; Child, Preschool; Female; Adult; Africa; sleep; children; Ghana; Sleep; women; Actigraphy/methods; *Mothers; *Air Pollution/adverse effects; agrarian; Ghana/epidemiology; indigenous; rural",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
pubmed,settembre,WB5KEG4L,journalArticle,2022,"Govindapala, Dumitha; Senarath, Uththara Sachinthanie; Wijewardena, Dasun; Nakkawita, Dilini; Undugodage, Chandimani",An unusual presentation of anaphylaxis with severe hypertension: a case report.,Journal of medical case reports,NA,1752-1947,10.1186/s13256-022-03528-y,NA,"BACKGROUND: Low blood pressure and associated postural symptoms are well-recognized manifestations of anaphylaxis. Nonetheless, anaphylaxis can  present with high blood pressure and is rarely reported in the literature. We  report an unusual presentation of anaphylaxis with severe supine hypertension and  orthostatic intolerance. CASE PRESENTATION: A 43-year-old Asian female presented  to the emergency department with generalized itching, hives, and postural  dizziness after taking a slow-release diclofenac sodium 100 mg tablet. On  admission, the patient was tachycardic with a supine blood pressure of  200/100 mmHg. She had urticaria and bilateral rhonchi. A clinical diagnosis of  anaphylaxis was made. She was treated with intravenous hydrocortisone and  chlorpheniramine, but intramuscular adrenaline was withheld owing to her high  blood pressure. She was kept in the supine position, and her vital parameters  were closely monitored. Although the respiratory and cutaneous symptoms improved  with treatment, her blood pressure remained elevated. Forty minutes later, the  postural dizziness recurred as she sat up on the bed and her blood pressure  plummeted from 198/100 mmHg to 80/60 mmHg. She was put back in the supine  position immediately, and the blood pressure was restored with three doses of  intramuscular adrenaline and a fluid bolus. Her postural symptoms completely  resolved after adrenaline, but her blood pressure remained elevated. Two weeks  after the initial presentation, a diagnosis of essential hypertension was made,  which probably had been undetected. In anaphylaxis, where the cardiovascular  system is involved, a blood pressure reduction from baseline is expected in  patients with preexisting hypertension. Despite cardiovascular involvement, our  patients' blood pressure on presentation to the emergency department was much  higher than her pretreatment ambulatory blood pressure, thus making this  presentation unusual. CONCLUSIONS: Diagnosis and treatment of anaphylaxis can be  delayed in patients presenting with high blood pressure. Postural symptoms should  alert the clinician to cardiovascular involvement despite elevated supine blood  pressure. Early treatment with adrenaline should be considered in these patients  with extreme caution.",2022-08-26,2022-09-02T13:08:22Z,2022-09-02T13:08:22Z,NA,327,NA,1,16,NA,J Med Case Rep,NA,NA,NA,NA,NA,NA,NA,eng,© 2022. The Author(s).,NA,NA,NA,NA,NA,PMID: 36008817  PMCID: PMC9413925,NA,NA,NA,"Hypertension; Humans; Female; Adult; Anaphylaxis; Blood Pressure Monitoring, Ambulatory; *Anaphylaxis/diagnosis/drug therapy/etiology; *Hypertension/complications/drug therapy; *Hypotension; Case report; Dizziness/etiology; Epinephrine/therapeutic use; Hypertensive anaphylaxis; Orthostatic intolerance",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
scopus,marzo,M8ZXQ4KJ,journalArticle,2022,"Jung, H.; Kimball, J.; Receveur, T.; Gazi, A.H.; Agdeppa, E.; Inan, O.",Estimation of Tidal Volume Using Load Cells on a Hospital Bed,IEEE Journal of Biomedical and Health Informatics,NA,NA,10.1109/JBHI.2022.3141209,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122870410&doi=10.1109%2fJBHI.2022.3141209&partnerID=40&md5=9d5dc8c5223db5ede9d1be3f5b2c1097,NA,2022,2022-08-24T07:40:46Z,2022-08-24T07:40:46Z,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Scopus,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
scopus,marzo,PTX3EKTS,journalArticle,2021,"Rezaei, A.M.; Stevens, M.C.; Argha, A.; Mascheroni, A.; Puiatti, A.; Lovell, N.H.",An Unobtrusive Fall Detection System Using Low Resolution Thermal Sensors and Convolutional Neural Networks,Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference,NA,NA,10.1109/EMBC46164.2021.9631059,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122537725&doi=10.1109%2fEMBC46164.2021.9631059&partnerID=40&md5=c41a2324ef55c398d349b8a7abd1ab81,NA,2021,2022-08-24T07:40:47Z,2022-08-24T07:40:47Z,NA,6949-6952,NA,NA,2021,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Scopus,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
scopus,marzo,H99C2S55,journalArticle,2021,"Son, C.; Kang, W.; Lee, J.; Moon, K.J.",Machine Learning to Identify Psychomotor Behaviors of Delirium for Patients in Long-Term Care Facility,IEEE Journal of Biomedical and Health Informatics,NA,NA,10.1109/JBHI.2021.3116967,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118623135&doi=10.1109%2fJBHI.2021.3116967&partnerID=40&md5=915257a167ab212710cdf2a15424157a,NA,2021,2022-08-24T07:40:50Z,2022-08-24T07:40:50Z,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Scopus,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
scopus,marzo,8A4UAYLC,conferencePaper,2020,"Enayati, M.; Farahani, N.Z.; Skubic, M.",Machine learning approach for motion artifact detection in ballistocardiogram signals,NA,NA,NA,10.1145/3421937.3421970,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100719551&doi=10.1145%2f3421937.3421970&partnerID=40&md5=46d39de2fc1ccefa774a9999e82c99a9,NA,2020,2022-08-24T07:40:53Z,2022-08-24T07:40:53Z,NA,406-410,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Scopus,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,ACM International Conference Proceeding Series,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
scopus,settembre,8FIZMHY9,journalArticle,2022,"Podell, J.; Pergakis, M.; Yang, S.; Felix, R.; Parikh, G.; Chen, H.; Chen, L.; Miller, C.; Hu, P.; Badjatia, N.",Leveraging Continuous Vital Sign Measurements for Real-Time Assessment of Autonomic Nervous System Dysfunction After Brain Injury: A Narrative Review of Current and Future Applications,Neurocritical Care,NA,NA,10.1007/s12028-022-01491-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129094656&doi=10.1007%2fs12028-022-01491-6&partnerID=40&md5=adb32579dae83709c75feb12a1a9fb9a,NA,2022,2022-09-02T13:09:52Z,2022-09-02T13:09:52Z,NA,206-219,NA,NA,37,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Scopus,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
scopus,settembre,5HH9B2ED,journalArticle,2022,"Lin, C.-J.; Wei, T.-S.; Liu, P.-T.; Chen, B.-H.; Shih, C.-H.",Bed-Exit Behavior Recognition for Real-Time Images within Limited Range,"Sensors (Basel, Switzerland)",NA,NA,10.3390/s22155495,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135370627&doi=10.3390%2fs22155495&partnerID=40&md5=233969f2f47d9ddec2ca3f0f9fcca826,NA,2022,2022-09-02T13:09:52Z,2022-09-02T13:09:52Z,NA,NA,NA,15,22,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Scopus,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
scopus,settembre,IYCPZC9K,journalArticle,2022,"Kawazoe, Y.; Shimamoto, K.; Shibata, D.; Shinohara, E.; Kawaguchi, H.; Yamamoto, T.",Impact of a Clinical Text-Based Fall Prediction Model on Preventing Extended Hospital Stays for Elderly Inpatients: Model Development and Performance Evaluation,JMIR Medical Informatics,NA,NA,10.2196/37913,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135942551&doi=10.2196%2f37913&partnerID=40&md5=6034a216ef5a363f2ac5ade160ad429c,NA,2022,2022-09-02T13:09:52Z,2022-09-02T13:09:52Z,NA,NA,NA,7,10,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Scopus,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
scopus,settembre,NQZDYYJU,journalArticle,2022,"Bouchayer, C.; Aiken, J.M.; Thøgersen, K.; Renard, F.; Schuler, T.V.",A Machine Learning Framework to Automate the Classification of Surge-Type Glaciers in Svalbard,Journal of Geophysical Research: Earth Surface,NA,NA,10.1029/2022JF006597,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135127193&doi=10.1029%2f2022JF006597&partnerID=40&md5=f606d0cd43fa1a401504bc9d29c6c861,NA,2022,2022-09-02T13:09:52Z,2022-09-02T13:09:52Z,NA,NA,NA,7,127,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Scopus,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
scopus,settembre,RNJELLCK,journalArticle,2022,"Robertson, F.C.; Wu, K.C.; Sha, R.M.; Amich, J.M.; Lal, A.; Lee, B.H.; Kirollos, R.W.; Chen, M.W.; Gormley, W.B.",Stereotactic Neurosurgical Robotics With Real-Time Patient Tracking: A Cadaveric Study,"Operative neurosurgery (Hagerstown, Md.)",NA,NA,10.1227/ons.0000000000000155,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135202205&doi=10.1227%2fons.0000000000000155&partnerID=40&md5=06bdeb2a59925604fc809e04c80461db,NA,2022,2022-09-02T13:09:53Z,2022-09-02T13:09:53Z,NA,425-432,NA,6,22,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Scopus,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
scopus,settembre,EF9CL6AN,journalArticle,2022,"Cho, S.-W.; Jung, S.J.; Shin, J.H.; Won, T.-B.; Rhee, C.-S.; Kim, J.-W.",Evaluating Prediction Models of Sleep Apnea From Smartphone-Recorded Sleep Breathing Sounds,JAMA Otolaryngology - Head and Neck Surgery,NA,NA,10.1001/jamaoto.2022.0244,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128908780&doi=10.1001%2fjamaoto.2022.0244&partnerID=40&md5=d7a07d4ee222695279de651f21fcc2ac,NA,2022,2022-09-02T13:09:53Z,2022-09-02T13:09:53Z,NA,515-521,NA,6,148,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,Scopus,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
wos,marzo,237H2MT7,journalArticle,2021,"Xiao, Y; Li, WJ; Yang, SF","Hydrodynamic-sediment transport response to waterway depth in the Three Gorges Reservoir, China",ARABIAN JOURNAL OF GEOSCIENCES,NA,1866-7511,10.1007/s12517-021-07090-7,NA,"Since the Three Gorges Dam began operation in 2003, hydrodynamic-sediment conditions changes have occurred not only downstream but also in the Three Gorges Reservoir, contributing to variations in the navigation conditions of the backwater area. Based on the measured channel data from 2003 to 2018, this study investigates changes in the waterway dimension and the factors that impact navigation conditions. The navigation-obstructing channels in the permanent backwater area (PBA) mainly resulted from the occurrence of fine grained sedimentation, which led to a decrease in the effective navigable width. Meanwhile, in the fluctuating backwater area (FBA), bed load behavior during the falling stage from April to June lowered navigation depths. Decreasing sediment supply can alleviate reservoir sedimentation and maintain navigation safety in the PBA, while it is necessary to focus on the waterway depth clearance that is sensitive to temporary deposition during the falling stage of high water-sediment discharge years in the FBA. Water level variation near gravel excavation pits indicates that sediment mining decreases waterway depth, negatively impacting the navigable dimension, especially during low water discharge. These findings provide useful information for assessing the sustainable development of the navigation in the Three Gorges Reservoir, and aid economic development in the Yangtze River.",2021-05,2022-08-24T07:45:34Z,2022-08-24T07:45:34Z,NA,NA,NA,9,14,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,WOS:000681070300002,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
wos,marzo,56Z4EJFU,journalArticle,2022,"Baker, WJ; Bailey, P; Barber, V; Barker, A; Bellot, S; Bishop, D; Botigue, LR; Brewer, G; Carruthers, T; Clarkson, JJ; Cook, J; Cowan, RS; Dodsworth, S; Epitawalage, N; Francoso, E; Gallego, B; Johnson, MG; Kim, JT; Leempoel, K; Maurin, O; Mcginnie, C; Pokorny, L; Roy, S; Stone, M; Toledo, E; Wickett, NJ; Zuntini, AR; Eiserhardt, WL; Kersey, PJ; Leitch, IJ; Forest, F",A Comprehensive Phylogenomic Platform for Exploring the Angiosperm Tree of Life,SYSTEMATIC BIOLOGY,NA,1063-5157,10.1093/sysbio/syab035,NA,"The tree of life is the fundamental biological roadmap for navigating the evolution and properties of life on Earth, and yet remains largely unknown. Even angiosperms (flowering plants) are fraught with data gaps, despite their critical role in sustaining terrestrial life. Today, high-throughput sequencing promises to significantly deepen our understanding of evolutionary relationships. Here, we describe a comprehensive phylogenomic platform for exploring the angiosperm tree of life, comprising a set of open tools and data based on the 353 nuclear genes targeted by the universal Angiosperms353 sequence capture probes. The primary goals of this article are to (i) document our methods, (ii) describe our first data release, and (iii) present a novel open data portal, the Kew Tree of Life Explorer (htips://treeoflife.keworg). We aim to generate novel target sequence capture data for all genera of flowering plants, exploiting natural history collections such as herbarium specimens, and augment it with mined public data. Our first data release, described here, is the most extensive nuclear phylogenomic data set for angiosperms to date, comprising 3099 samples validated by DNA barcode and phylogenetic tests, representing all 64 orders, 404 families (96%) and 2333 genera (17%). A ""first pass"" angiosperm tree of life was inferred from the data, which totaled 824,878 sequences, 489,086,049 base pairs, and 532,260 alignment columns, for interactive presentation in the Kew Tree of Life Explorer. This species tree was generated using methods that were rigorous, yet tractable at our scale of operation. Despite limitations pertaining to taxon and gene sampling, gene recovery, models of sequence evolution and paralogy, the tree strongly supports existing taxonomy, while challenging numerous hypothesized relationships among orders and placing many genera for the first time. The validated data set, species tree and all intermediates are openly accessible via the Kew Tree of Life Explorer and will be updated as further data become available. This major milestone toward a complete tree of life for all flowering plant species opens doors to a highly integrated future for angiosperm phylogenomics through the systematic sequencing of standardized nuclear markers. Our approach has the potential to serve as a much-needed bridge between the growing movement to sequence the genomes of all life on Earth and the vast phylogenomic potential of the world's natural history collections.",2022-02-10,2022-08-24T07:45:38Z,2022-08-24T07:45:38Z,NA,301-319,NA,2,71,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,WOS:000753585400005,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
wos,settembre,M6Q4FWIA,journalArticle,2022,"Kent, BA; Casciola, AA; Carlucci, SK; Chen, M; Stager, S; Mirian, MS; Slack, P; Valerio, J; McKeown, MJ; Feldman, HH; Nygaard, HB",Home EEG sleep assessment shows reduced slow-wave sleep in mild-moderate Alzheimer's disease,ALZHEIMERS & DEMENTIA-TRANSLATIONAL RESEARCH & CLINICAL INTERVENTIONS,NA,2352-8737,10.1002/trc2.12347,NA,"Introduction Sleep disturbances are common in Alzheimer's disease (AD), with estimates of prevalence as high as 65%. Recent work suggests that specific sleep stages, such as slow-wave sleep (SWS) and rapid eye movement (REM), may directly impact AD pathophysiology. A major limitation to sleep staging is the requirement for clinical polysomnography (PSG), which is often not well tolerated in patients with dementia. We have recently developed a deep learning model to reliably analyze lower quality electroencephalogram (EEG) data obtained from a simple, two-lead EEG headband. Here we assessed whether this methodology would allow for home EEG sleep staging in patients with mild-moderate AD. Methods A total of 26 mild-moderate AD patients and 24 age-matched, healthy control participants underwent home EEG sleep recordings as well as actigraphy and subjective sleep measures through the Pittsburgh Sleep Quality Index (PSQI). Each participant wore the EEG headband for up to three nights. Sleep was staged using a deep learning model previously developed by our group, and sleep stages were correlated with actigraphy measures as well as PSQI scores. Results We show that home EEG with a headband is feasible and well tolerated in patients with AD. Patients with mild-moderate AD were found to spend less time in SWS compared to healthy control participants. Other sleep stages were not different between the two groups. Actigraphy or the PSQI were not found to predict home EEG sleep stages. Discussion Our data show that home EEG is well tolerated, and can ascertain reduced SWS in patients with mild-moderate AD. Similar findings have previously been reported, but using clinical PSG not suitable for the home environment. Home EEG will be particularly useful in future clinical trials assessing potential interventions that may target specific sleep stages to alter the pathogenesis of AD. Highlights Home electroencephalogram (EEG) sleep assessments are important for measuring sleep in patients with dementia because polysomnography is a limited resource not well tolerated in this patient population. Simplified at-home EEG for sleep assessment is feasible in patients with mild-moderate Alzheimer's disease (AD). Patients with mild-moderate AD exhibit less time spent in slow-wave sleep in the home environment, compared to healthy control participants. Compared to healthy control participants, patients with mild-moderate AD spend more time in bed, with decreased sleep efficiency, and more awakenings as measured by actigraphy, but these measures do not correlate with EEG sleep stages.",2022,2022-09-02T13:11:23Z,2022-09-02T13:11:23Z,NA,NA,NA,1,8,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,WOS:000840990000001,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
wos,settembre,C4FACCUB,journalArticle,NA,"Sentner, T; Wang, XW; de Groot, ER; van Schaijk, L; Tataranno, ML; Vijlbrief, DC; Benders, MJNL; Bartels, R; Dudink, J",The Sleep Well Baby project: an automated real-time sleep-wake state prediction algorithm in preterm infants,SLEEP,NA,0161-8105,10.1093/sleep/zsac143,NA,"Study Objectives Sleep is an important driver of early brain development. However, sleep is often disturbed in preterm infants admitted to the neonatal intensive care unit (NICU). We aimed to develop an automated algorithm based on routinely measured vital parameters to classify sleep-wake states of preterm infants in real-time at the bedside. Methods In this study, sleep-wake state observations were obtained in 1-minute epochs using a behavioral scale developed in-house while vital signs were recorded simultaneously. Three types of vital parameter data, namely, heart rate, respiratory rate, and oxygen saturation, were collected at a low-frequency sampling rate of 0.4 Hz. A supervised machine learning workflow was used to train a classifier to predict sleep-wake states. Independent training (n = 37) and validation datasets were validation n = 9) datasets were used. Finally, a setup was designed for real-time implementation at the bedside. Results The macro-averaged area-under-the-receiver-operator-characteristic (AUROC) of the automated sleep staging algorithm ranged between 0.69 and 0.82 for the training data, and 0.61 and 0.78 for the validation data. The algorithm provided the most accurate prediction for wake states (AUROC = 0.80). These findings were well validated on an independent sample (AUROC = 0.77). Conclusions With this study, to the best of our knowledge, a reliable, nonobtrusive, and real-time sleep staging algorithm was developed for the first time for preterm infants. Deploying this algorithm in the NICU environment may assist and adapt bedside clinical work based on infants' sleep-wake states, potentially promoting the early brain development and well-being of preterm infants.",NA,2022-09-02T13:11:24Z,2022-09-02T13:11:24Z,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,WOS:000835769500001,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
wos,settembre,C8AHWSPN,conferencePaper,2022,"Mihalik, O; Sykora, T; Husak, M; Fiedler, P",In-BedPostureClssificationBasedon aarse eresenonn eunanSpars Representaton n Redundant S R ttRddt Sparse Represenai on in eunanconars t ti iR d d t Dctonares Dti i i Dictionaries,NA,2405-8963,NA,10.1016/j.ifacol.2022.06.062,NA,"Non-orthogonal signal representation using redundant dictionaries gradually gained popularity over the last decades. Sparse methods find major application in signal denoising, audio declipping, time-frequency analysis, and classification, to name a few. This paper is inspired by the exceptional results of sparse representation classification originally suggested for face recognition. We compare the method to other common classifiers using simulated as well as real datasets. In the latter the proposed method is tested with real pressure data from a bed equipped with a matrix of 30???x???11 pressure sensors. Here the method outperforms standard classification methods (surpassing 91 % accuracy) without need of parameter selection or special user's skills. Furthermore it offers a means of dealing with occlusions, whose results are presented as well.",2022,2022-09-02T13:11:38Z,2022-09-02T13:11:38Z,NA,374-379,NA,NA,55,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,WOS:000836195400021,NA,NA,Issue: 4,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,IFAC PAPERSONLINE,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA
